[{"title":"ext4文件系统","url":"http://fengjianque.github.io/2017/02/07/ext4/","content":"<h1 id=\"ext4文件系统\"><a href=\"#ext4文件系统\" class=\"headerlink\" title=\"ext4文件系统\"></a>ext4文件系统</h1><p>linux的拓展文件系统，从第一代ext为人们所熟知，经过ext2、ext3、ext4发展，逐步成为linux上首选的文件系统，目前比较常用的是ext3和ext4，ext3的用户也将慢慢升级到ext4。本文介绍这两个文件系统的区别，ext4在ext3的基础上做了哪些改进，中间穿插一些文件系统基础知识，希望通过本文大家能对ext4有大致的了解。</p>\n<h2 id=\"磁盘布局\"><a href=\"#磁盘布局\" class=\"headerlink\" title=\"磁盘布局\"></a>磁盘布局</h2><p>在了解文件系统前，先简单了解下磁盘是怎样布局的。磁盘都会进行逻辑空间划分，分为一个个分区，有GPT和MBR划分机制，本文介绍MBR机制，磁盘被分成最多4个分区；下图一个磁盘被分为3个主分区和一个拓展分区，每个分区包含boot block部分；拓展分区拓展了区域，称为逻辑分区；MBR部分是整个系统的开始部分，包括引导程序boot code和分区表信息。</p>\n<p><img src=\"http://g.fp.ps.netease.com/nanny/file/571326f8143cfa8706553e71YAU0RUqA\" alt=\"\"></p>\n<p>MBR引导程序通过分区表找到一个活动的分区表，将活动分区的启动程序从设备加载到RAM并且执行，该程序负责进一步的操作系统的加载和启动。</p>\n<p>一个文件系统使用一个独立的分区，不同的分区可以使用不同的文件系统，linux只有一个根目录「/」，其他分区是需要挂在根目录下面某个目录才能使用。</p>\n<p>磁盘在物理上将一段范围磁柱划分为数据块，一个块究竟多大是在格式化时确定的，例如mke2fs的-b选项可以设定块大小为1024、2048或4096字节，默认为4KB。</p>\n<h3 id=\"ext3-布局\"><a href=\"#ext3-布局\" class=\"headerlink\" title=\"ext3 布局\"></a>ext3 布局</h3><p>磁盘分区好之后，就能在分区上创建文件系统了。一个分区格式化成ext3文件系统，磁盘的布局如下图：</p>\n<p><img src=\"http://g.fp.ps.netease.com/nanny/file/5713315e143cfabdb71b9fa3IYbJE8lV\" alt=\"\"></p>\n<p>文件系统最前面有一个启动扇区(boot block)，这个启动块可以安装启动管理程序，这是个非常重要的设计，因为如此一来我们就能够将不同的启动管理程序安装到个别的文件系统最前端，而不用覆盖唯一的 MBR。</p>\n<ul>\n<li>Super Block： 大小为1k，Superblock 是记录整个 filesystem 相关信息的地方，超级块位于每个块组的最前面，每个块组包含超级块的内容是相同的(超级块在每个块组的开头都有一份拷贝)；下图是super block的内容</li>\n</ul>\n<p><img src=\"http://g.fp.ps.netease.com/nanny/file/57134032143cfaf83b22ee00fxoJGr6L\" alt=\"\"></p>\n<ul>\n<li><p>GDT：块组描述符表，由很多块组描述符组成，Linux组描述符为32字节，整个分区分成多少个块组就对应有多少个块组描述符；和超级块类似，块组描述符表在每个块组的开头也都有一份拷贝，具有相同内容的组描述符表放在每个块组中做为备份，这些信息是非常重要的。</p>\n</li>\n<li><p>Block Bitmap：块位图，用来描述本块组中数据块的使用状况，它本身占一个数据块。</p>\n</li>\n<li>Inode Bitmap：inode位图，和块位图类似，本身占一个块，其中每个bit表示一个inode是否空闲可用。</li>\n<li>Inode Table：inode表，存储本块组的inode序号和inode保存的位置。</li>\n<li>Data block： 存放数据的地方；</li>\n</ul>\n<h3 id=\"ext4磁盘布局\"><a href=\"#ext4磁盘布局\" class=\"headerlink\" title=\"ext4磁盘布局\"></a>ext4磁盘布局</h3><p>ext4基本磁盘布局跟ext3的基本差不多，都是以块组管理，但有增加了一些特性。</p>\n<ol>\n<li><p>Flexible 块组<br>如果开启flex_bg特性，在一个flex_bg中，几个块组在一起组成一个逻辑块组flex_bg。flex_bg的第一个块组中的位图空间和inode表空间扩大为包含了flex_bg中其他块组上位图和inode表。如下图flex_bg包含4个块组，块组0将按序包含超级块、块组描述符表、块组0-3的数据块位图、块组0-3的inode位图、块组0-3的inode表，块组0中的其他空间用于存储文件数据。同时，其他块组上的数据块位图、inode位图、inode表元数据就不存在了，但是Super Block和GDT还是存在的。</p>\n<p> <img src=\"http://g.fp.ps.netease.com/nanny/file/571367c15e60275cb8fa8f20xTS85U8p\" alt=\"\"></p>\n<p> Flexible块组的作用是：<br> (1)  聚集元数据，加速元数据载入；<br> (2)  使得大文件在磁盘上尽量连续；<br> 最终目的都是减少磁盘寻道时间；</p>\n</li>\n<li><p>元块组 Meta Block Groups<br>以ext4为例，一个Block Group的大小为默认大小为127MB，Ext4的块组描述符大小64 Bytes计算，文件系统中最多只能有2^21个块组，也就是文件系统最大为256TB。<br>如果打开META_BG的选项，ext4文件系统将被分成多个metablock groups。每个metablock group是block groups的集合。对于block size 为4KB的ext4文件系统，一个metablock group包含64个block group = 8GB，GDT将存储在medablock group中的第一个block group中，并且在medablock group中第二和最后一个作备份。这种方式即可以实现消除中256T的限制，即2^32 *2^27=512PB。</p>\n</li>\n</ol>\n<h3 id=\"inode\"><a href=\"#inode\" class=\"headerlink\" title=\"inode\"></a>inode</h3><p>一个文件除了自身的数据之外，还有一个附属信息，即文件的元数据(metadata)。这个元数据用于记录文件的许多信息，比如文件大小，拥有人，所属的组，修改日期等等。元数据并不包含在文件的数据中，而是由文件系统维护的，这些数据就保存在inode中，当然inode内容也保存在data block中。我们可以用 <code>ls -l filename</code> 来查看这些元数据。</p>\n<p>inode保存的主要信息：</p>\n<ul>\n<li>该文件的存取模式(read/write/excute)；</li>\n<li>该文件的拥有者与群组(owner/group)；</li>\n<li>该文件的容量；</li>\n<li>该文件创建或状态改变的时间(ctime)；</li>\n<li>最近一次的读取时间(atime)；</li>\n<li>最近修改的时间(mtime)；</li>\n<li>定义文件特性的旗标(flag)，如 SetUID…；</li>\n<li>该文件保存数据块的指针 (pointer)；</li>\n</ul>\n<p>inode节点大小是128字节，每个文件都必须占用一个inode，因此文件系统能够创建的文件数量与 inode 的数量有关， inode表占多少个块在格式化时就要决定并写入块组描述符中，mke2fs格式化工具的默认策略是一个块组有多少个8KB就分配多少个inode。</p>\n<p>inode保存了数据的存放block的指针，是怎么工作的呢，ext3和ext4又有所不同。</p>\n<h3 id=\"ext3文件寻址\"><a href=\"#ext3文件寻址\" class=\"headerlink\" title=\"ext3文件寻址\"></a>ext3文件寻址</h3><p><img src=\"http://g.fp.ps.netease.com/nanny/file/57136c8e143cfa832aab26a5Tphi7qE2\" alt=\"\"></p>\n<p>如上图所示，ext3包含了15个指针，12个直接指针，一个间接指针，一个二次间接指针，一个三次间接指针。</p>\n<p>这样子一个inode能够存多大的文件呢？我们以 4KB block 来说明好了，可以指定的情况如下：</p>\n<ul>\n<li><p>12个直接指向： 12*4K=48K；</p>\n</li>\n<li><p>间接： 1K * 4K = 4M；一个指针占4bytes，因此4KB的大小block能够存1K个指针，因此一个间接可以记录的文件大小为4M；</p>\n</li>\n<li><p>二次间接指针： 1K <em> 1K </em> 4K=4G<br>第一层 block 会指定 1K 个第二层，每个第二层可以指定 1K 个block；</p>\n</li>\n<li><p>三次间接指针： 1K <em> 1K </em> 1K * 4K = 4T；</p>\n</li>\n</ul>\n<h3 id=\"ext4文件寻址\"><a href=\"#ext4文件寻址\" class=\"headerlink\" title=\"ext4文件寻址\"></a>ext4文件寻址</h3><p>Ext3 采用间接索引映射，当操作大文件时，效率极其低下。比如一个 100MB 大小的文件，在 Ext3中要建立 25,600 个数据块（每个数据块大小为 4KB）的映射表。而 Ext4 引入了现代文件系统中流行的区段  <code>extents</code> 概念，每个 extent 为一组连续的数据块，上述文件则表示为“该文件数据保存在接下来的 25,600 个数据块中”，提高了不少效率。</p>\n<p><img src=\"http://g.fp.ps.netease.com/nanny/file/57144dea5e602729d280095cbzGs7h2v\" alt=\"\"></p>\n<p>如上图，区段extents根据内容分为索引节点 <code>extent_idx</code> ,内容叶子节点extent。extent内容包含了起始的block地址和length，length占16个字节，因此对于4KB的block，每个extent能定位128M连续的寻址空间。 inode默认有4个extent，每个extent可以直接指向一段连续的block；如果这4个extent不能满足文件大小，则extent变成<code>extent_idx</code>索引节点 , 像ext3间接索引一样，一级级拓展，形成一个BTree。</p>\n<p>使用区段分配数据块好处显而易见，减少了映射表项，还分配连续的空间，减少磁头的移动，增加效率，同时没有文件大小的限制。</p>\n<h4 id=\"目录索引\"><a href=\"#目录索引\" class=\"headerlink\" title=\"目录索引\"></a>目录索引</h4><p>前面我们说过，创建一个文件需要占用一个inode节点，和至少一个block。inode存元数据，block存文件内容，如果是目录呢？<br>目录也是一个文件，也需要分配一个inode节点，和至少一个block。不过block里面存储的是在这个目录下的文件名与该文件的inode编号。下面是 <code>/</code> 目录的数据块存储的entry项。</p>\n<table>\n<thead>\n<tr>\n<th>inode编号</th>\n<th>文件名</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>2</td>\n<td>.</td>\n</tr>\n<tr>\n<td>2</td>\n<td>..</td>\n</tr>\n<tr>\n<td>655362</td>\n<td>home</td>\n</tr>\n<tr>\n<td>786433</td>\n<td>var</td>\n</tr>\n</tbody>\n</table>\n<p>当我们读取一个文件时/home/aa.txt，先找到 <code>/</code> 的inode，然后读入inode指向的数据块，找到 <code>home</code> entry, 从entry中获得并读入inode，再读入home的block，检索的aa.txt entry的inode编号，最后根据编号，读取aa.txt的文件内容。</p>\n<p>像ext2要检索目录下某个entry，就得顺序读入该目录指向的block，直到读到为止。线性检索时间复杂度为O(n)，在一个目录超过10000文件时，性能就会有影响。</p>\n<p>在ext3中，增加了dir_index特性，为一个目录下面的表项创建索引，提高目录和文件的检索速度，ext3中需要手动开启这个特性，ext4中默认开启这个特性。</p>\n<p>dir_index特性中，将目录下的文件名进行hash计算，以Hash Tree的组织保存在block中。</p>\n<p><img src=\"http://g.fp.ps.netease.com/nanny/file/57148e5a96dee481ca2c0b26ieO8WaAd\" alt=\"\"></p>\n<p>上图中一个目录下面的所有entry被组织成一颗平衡的hash tree。<br>树的根就是存储在目录的第一个数据块，即dx_root，其中叶节点存储的目录项的内容，当前目录项并非按照线性排序了，而是hash值处于某一个范围内的目录项存储在一个目录项块中；中间节点存储的是存储的是索引项，内容和第一个目录数据块块内容基本一致。</p>\n<p>当前每个索引项dx_entry占8个字节，索引树根部dx_root占32个字节，对于一个4KB大小的块，即如图的第一层索引，可以索引508个叶块或节点块，第二层索引可以索引511个块，那么目录索引树支持目录大小为508×511×4KB=1014MB，假定一个目录下文件名平均由22个字符长度，那么一个目录项即30B，那么二级索引树最大支持约34M个文件，即3400万个文件，满足了绝大部分的存储场景需求。</p>\n<p>ext3和ext4中都只支持二层索引，所以要查找一个目录entry，只需要读取3个数据块，速度快了很多。</p>\n<h3 id=\"ext4更多特性\"><a href=\"#ext4更多特性\" class=\"headerlink\" title=\"ext4更多特性\"></a>ext4更多特性</h3><ul>\n<li><p>向后和向前兼容性:可以将 ext3 文件系统挂载为 ext4 文件系统；可以将 ext4 挂载为 ext3（向后兼容），但前提是ext4 文件系统不能使用区段特性；</p>\n</li>\n<li><p>提高时间戳分辨率： ext4的时间戳精确到纳秒，而之前都是以秒来记录；</p>\n</li>\n<li><p>突破文件系统的限制： 从上面的分析可以看到，ext4它支持更大的文件系统、文件和子目录；</p>\n</li>\n<li><p>区段分配：ext3 使用空闲空间位映射来分配文件，这种方式不是很快，并且伸缩性不强。ext3 的格式对小文件而言是很高效的，但对于大文件则恰恰相反。ext4 使用区段取代 ext3 的机制，从而改善了空间的分配，并且支持更加高效的存储结构。ext4从分配上进行很多优化，尽量使文件聚集在相邻的块上。</p>\n<ul>\n<li><p>文件级预分配：<br>某些应用程序，比如数据库或内容流，要求将文件存储在相邻的块上（利用相邻块的读优化和最大化读的命令-块比率）。尽管区段能够将相邻块划分为片段，但另一种更强大的方法是按照所需的大小预分配比较大的相邻块（XFS 以前就是采用这种方法）。ext4 通过一个新的系统调用来实现这个目的，这个调用将按照特定的大小预分配并初始化文件。然后，您就可以写入必要的数据，并为数据提供不错的读性能。</p>\n</li>\n<li><p>延迟块分配：<br>另一个基于文件大小的优化是延迟分配。这种性能优化延迟磁盘上的物理块的分配，直到块被刷入到磁盘时才进行分配。这种优化的关键是延迟物理块的分配，直到需要在磁盘上写这些物理块时才对其进行分配并写到相邻的块。这类似于持久化预分配，惟一的区别是文件系统会自动执行这项任务。不过如果预先知道文件的大小时，持久化预分配是更好的选择。</p>\n</li>\n<li><p>多个块分配：<br>这是最后一个与相邻块相关的优化，即针对 ext4 的块分配器。在 ext3 中，块分配器的工作方式是每次分配一个块。当需要分配多个块时，非相邻块中可能存在相邻的数据。ext4 使用块分配器修复了这个问题，它能够在磁盘上一次分配多个块。与前面其他优化一样，这个优化在磁盘上收集相关的数据，以实现相邻读优化。</p>\n<p>  多个块分配的另一个方面是分配块时需要的处理量。记住，ext3 一次只分配一个块。在最简单的情况下，每个块的分配都要有一个调用。如果一次分配多个块，对块分配器的调用就会大大减少，从而加快分配并减少处理量。</p>\n</li>\n</ul>\n</li>\n<li><p>更加可靠：<br>  日志记录就是通过日记（磁盘上相邻区域的专门循环记录）记录文件系统的变更的过程。因此，根据日志对物理存储执行实际变更更加可靠，并且能够确保一致性，即使在操作期间出现系统崩溃或电源中断。这样做可以减少文件系统损坏的几率。</p>\n<p>  但是即使进行日志记录，如果日志出现错误仍然会导致文件系统损坏。为了解决这个问题，ext4 对日志执行校验和，确保有效变更能够在底层文件系统上正确完成。</p>\n</li>\n<li>在线磁盘碎片整理：<br> 尽管 ext4 添加一些特性来减少文件系统的碎片（比如将相邻块分配为区段），但随着系统使用时间的增加，碎片是难以完全避免的。因此出现了在线碎片整理工具，它们可以对文件系统和单个文件执行碎片整理，从而改善性能。</li>\n</ul>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><p>拓展文件系统发展到第4代，功能和性能优越毋容置疑，还在用ext3的都升级到4来吧~</p>\n","categories":["未分类"],"tags":["技术"]},{"title":"nginx缓存","url":"http://fengjianque.github.io/2017/02/07/nginx-cache/","content":"<h2 id=\"nginx缓存\"><a href=\"#nginx缓存\" class=\"headerlink\" title=\"nginx缓存\"></a>nginx缓存</h2><p>最近调研了目前web的缓存方案，用以减缓瞬间飙升并发访问给后端服务带来的压力。在几个流行的开源的web缓存技术中，发现nginx本来就很好的支持缓存功能，而且在最新的1.9.8版上加强了对Byte-Range特性的支持，nginx是不错的选择。本文就nginx支持的缓存进行使用说明。</p>\n<h3 id=\"缓存方式\"><a href=\"#缓存方式\" class=\"headerlink\" title=\"缓存方式\"></a>缓存方式</h3><p>nginx支持两种缓存方式，一种是文件缓存；一种是内存缓存；<br>其中文件缓存方式依赖于内置的模块proxy cache（uwsgi对应有uwsgi cache）； 另一种是srcache+memcache/redis方案。本文先介绍proxy cache。</p>\n<h4 id=\"1-proxy-cache\"><a href=\"#1-proxy-cache\" class=\"headerlink\" title=\"1 proxy cache\"></a>1 proxy cache</h4><p>proxy cache开启很简单，直接上简单配置文件：</p>\n<pre><code>proxy_cache_path /path/to/cache levels=1:2 keys_zone=my_cache:100m max_size=10g inactive=60m;\n\nserver {\n...\n    location / {\n        proxy_cache my_cache;\n        proxy_pass http://my_upstream;\n    }\n}\n</code></pre><p>参数说明：</p>\n<ul>\n<li><code>proxy_cache_path</code>: 文件保存目录；</li>\n<li><code>levels=1:2</code>: 表示设置两层缓存目录，缓存目录的第一级目录是1个字符，第二级目录是2个字符，即/path/to/cache/a/1b这种形式。一个目录中文件太多，会导致文件的访问性能下降。</li>\n<li><code>keys_zone=my_cache:100m</code>: 表示缓存池的名字为my_cache, 大小为100M，这个缓存池用来缓存文件的key，缓存池是分配在内存的。如果一个文件的key占的空间是100字节，那100M的内存大概可以存1百万个文件的key。</li>\n<li><code>max_size=10g</code>: 缓存文件的总大小不能超过10G；</li>\n<li><code>inactive=60m</code>: 缓存的文件如果超过60分钟没有被访问，那么会被清除；</li>\n</ul>\n<p><code>proxy_cache my_cache</code> 指定了使用哪个缓存空间，可以在location下面配置，仅对当前目录有效；也可以在server下面配置，全局有效。</p>\n<p>上面就是基本的配置，能满足了基本的要求，我们进一步优化场景配置。</p>\n<pre><code>location / {\n       proxy_cache_key $host$uri$args;\n       proxy_cache_revalidate on;\n       proxy_cache_min_uses 3;\n       proxy_cache_lock on;\n       proxy_cache_lock_age 200s;\n         .....\n   }\n</code></pre><ul>\n<li><code>proxy_cache_key</code>: 指定cache缓存的key组成，nginx把这个字符串md5值作为缓存的key。</li>\n<li><code>proxy_cache_revalidate</code>: 开启这个选项，当用户请求一个Cache-Control头已经过期的文件，nginx会携带 If-Modified-Since 头，请求在这个时间更新之后的文件。这个选项有利于减少传输带宽。</li>\n<li><code>proxy_cache_min_uses</code>: 最少访问多少次才进行缓存，该选项帮助nginx判断该文件是否是热点文件。</li>\n<li><code>proxy_cache_lock</code>: 多个请求访问同一个文件时，只允许第一个请求访问，等待第一个请求缓存后，后面的请求从缓存中拉取数据。</li>\n<li><code>proxy_cache_lock_age 200s</code>: 锁的时间，默认为5s，一般要把这个时间设置大于文件读取时间，如果超过这个时间还没缓存好，那么nginx再次发起多个请求后端服务器。</li>\n</ul>\n<h3 id=\"1-1-出错时处理\"><a href=\"#1-1-出错时处理\" class=\"headerlink\" title=\"1.1 出错时处理\"></a>1.1 出错时处理</h3><pre><code>location / {\n    ...\n    proxy_cache_use_stale error timeout updating http_500 http_502 http_503 http_504;\n}\n</code></pre><p>使用该配置当程序中遇到error，超时，500、502、503、504时，返回当前老版本缓存，这样做总比报错强。<br>updating： 当访问一个缓存文件时，恰巧这个文件更新缓存，此时该访问返回旧文件，而不是等待更新完访问新缓存。</p>\n<h3 id=\"1-2-多个缓存目录\"><a href=\"#1-2-多个缓存目录\" class=\"headerlink\" title=\"1.2 多个缓存目录\"></a>1.2 多个缓存目录</h3><p>可以使用多个磁盘增加磁盘的吞吐量。</p>\n<pre><code>proxy_cache_path /path/to/hdd1 levels=1:2 keys_zone=my_cache_hdd1:10m max_size=10g\n                 inactive=60m use_temp_path=off;\nproxy_cache_path /path/to/hdd2 levels=1:2 keys_zone=my_cache_hdd2:10m max_size=10g\n                 inactive=60m use_temp_path=off;\n\nsplit_clients $request_uri $my_cache {\n              50%          “my_cache_hdd1”;\n              50%          “my_cache_hdd2”;\n}\n\nserver {\n    ...\n    location / {\n        proxy_cache $my_cache;\n        proxy_pass http://my_upstream;\n    }\n}\n</code></pre><p>split_clients模块将请求按配置的比例，分发到两个缓存空间。</p>\n<h3 id=\"1-3-忽略Cache-Control\"><a href=\"#1-3-忽略Cache-Control\" class=\"headerlink\" title=\"1.3 忽略Cache-Control\"></a>1.3 忽略Cache-Control</h3><pre><code>location /images/ {\n    proxy_cache my_cache;\n    add_header X-Cache-Status $upstream_cache_status;\n    proxy_ignore_headers Cache-Control;\n    proxy_cache_valid 200 206 30m;\n    ...\n}\n</code></pre><p>如果用户想知道此请求有没有缓存名字，可以添加一个头返回给用户，值为<code>upstream_cache_status</code>。<br>默认情况下，proxy cache只缓存应答中http头 Cache-Control 成立的请求；如果需要缓存所有请求，需要配置忽略Cache-Control头，并配置proxy_cache_valid缓存时间。</p>\n<h3 id=\"1-4-Byte-Range流的支持\"><a href=\"#1-4-Byte-Range流的支持\" class=\"headerlink\" title=\"1.4 Byte-Range流的支持\"></a>1.4 Byte-Range流的支持</h3><p>对于一个大文件，如果用户请求中指定了Byte-Range， 只需要返回文件的某一部分。proxy cache是怎么做的呢？<br>在nginx1.9 以前，nginx会先请求源服务器，把整个文件缓存下来，然后从缓存中读取需要的部分返回给用户，用户在此过程中处于一直挂起状态。</p>\n<p>想象在访问量大的场景下会怎样呢，在读取这个大文件时，会同时有很多的请求发给后端读取这个文件，如果锁相继超时（看下面锁配置的说明）那么一次缓存都没有成功，这将导致越来越多的请求堆积，后果是把服务器给压垮了。</p>\n<p>解决方式有两种：</p>\n<ol>\n<li><p>使用proxy_cache_lock，并合理配置各项锁超时的时间，下面是一个sample：</p>\n<pre><code>location /images/ {\n     proxy_cache_lock on;\n\n    # Immediately forward requests to the origin if we are filling the cache\n    proxy_cache_lock_timeout 0s;\n\n    # Set the &apos;age&apos; to a value larger than the expected fill time\n    proxy_cache_lock_age 200s;\n\n    proxy_cache_use_stale updating;\n}\n</code></pre><ul>\n<li><code>proxy_cache_lock on</code>: 当多个请求访问同一个文件时，只有第一个请求进行访问后端服务器，其他请求阻塞，第一个请求完成并进行缓存后，一并处理后面的请求。</li>\n<li><code>proxy_cache_lock_timeout</code>： 配置为0秒，表示在锁超时后，向源服务器发送原始请求，即带Range头部，结果返回后不进行缓存。</li>\n<li><code>proxy_cache_lock_age</code>：一般设置比缓存填充时间要大，超过这个时间，nginx再次发起多个请求给源服务器。</li>\n</ul>\n</li>\n<li><p>在nginx 1.9.8以上版本，使用slice模块来解决此问题。</p>\n<pre><code>server {\n    ....\n\n    proxy_cache mycache;\n\n    slice              1m;\n    proxy_cache_key    $host$uri$is_args$args$slice_range;\n    proxy_set_header   Range $slice_range;\n    proxy_http_version 1.1;\n    proxy_cache_valid  200 206 1h;\n\n    location / {\n        proxy_pass http://origin:80;\n    }\n}\n</code></pre><ul>\n<li><code>slice</code>: 设置分片的大小；</li>\n<li><code>proxy_cache_key</code>: 需要把$slice_range字段加入到key内容中，不然key就没法区分是哪一段了；</li>\n<li><code>proxy_http_version</code>: Byte-Range只有http 1.1版本才支持；</li>\n<li><p><code>proxy_cache_valid</code>: 使用Byte-Range返回的状态码为206，确定缓存返回为206的请求。</p>\n<p>举例说明，假如存储的文件为500B，slice为100B，用户发起请求Range: bytes=10-50; nginx根据slice的设置，并且10-50在第一个slice内，那么nginx向源服务器发起Range: bytes=0-100获取slice, 源服务器返回后nginx将10-50的范围给用户，并将slice的内容进行缓存，以备下次用。<br>如果用户请求的range跨越了多个slice， nginx发起多个请求请求符合范围的slice，然后将从多个slice中组装内容返回给用户。</p>\n</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"1-5缓存的清除\"><a href=\"#1-5缓存的清除\" class=\"headerlink\" title=\"1.5缓存的清除\"></a>1.5缓存的清除</h3><p>文件缓存了，要如何进行清除呢，nginx也提供了purge模块，不过这个模块不是内置的，需要重新编译的，加入参数–add-module=/usr/local/ngx_cache_purge，我们可以手动进行删除文件，下面是针对两层目录<code>levels=1:2</code>的删除方式：</p>\n<pre><code>先根据proxy_cache_key指定的字段内容计算文件的key\n$ echo -n &quot;http://hostname/path/to/test.html&quot; | md5sum\n48a17b3843b4a5a6314c95d610c5be6d  -\n获取文件路径\n$ echo 48a17b3843b4a5a6314c95d610c5be6d | awk &apos;{print &quot;/path/to/cache/&quot;substr($1,length($1),1)&quot;/&quot;substr($1,length($1)-2,2)&quot;/&quot;$1}&apos;\n/path/to/cache/d/e6/48a17b3843b4a5a6314c95d610c5be6d\n删除文件\n$ rm /path/to/cache/d/e6/48a17b3843b4a5a6314c95d610c5be6d\n\nsubstr($1,length($1),1) -- 获取第一层目录的名字\nsubstr($1,length($1)-2,2) -- 获取第二层目录名字\n</code></pre><p>还有一种方式是遍历文件内容删除的：</p>\n<pre><code>find /path/to/cache -type f -exec grep -l &quot;KEY: http://hostname/path/to/test.html/&quot; {} \\; | xargs rm -f\n遍历缓存目录下的所有文件，查找文件内容包含&quot;KEY: http://hostname/path/to/test.html/&quot;进行删除。\n</code></pre><p>KEY后面的内容就是proxy_cache_key配置的实际内容，而不是md5值。</p>\n<h3 id=\"1-6缓存命中率\"><a href=\"#1-6缓存命中率\" class=\"headerlink\" title=\"1.6缓存命中率\"></a>1.6缓存命中率</h3><p>计算缓存命中率需要根据nginx的access.log进行计算，log格式配置upstream_addr, 如果是命中，upstream_addr的值为<code>-</code>。</p>\n<h3 id=\"1-7-Cache-Loader和Cache-Manager\"><a href=\"#1-7-Cache-Loader和Cache-Manager\" class=\"headerlink\" title=\"1.7 Cache Loader和Cache Manager\"></a>1.7 Cache Loader和Cache Manager</h3><p>如果启用了proxy cache，nginx还会启动Cache Loader和Cache Manager进程。</p>\n<ul>\n<li>Cache Loader： nginx启动后，需要把文件缓存元数据读进内存中，简而言之就是把每个文件的key一个个的读进内存。当这些操作完成后，Cache Loader的使命就结束了，进程也随之关掉。</li>\n<li>Cache Manager： 周期性的检查缓存的目录的大小是否超过了<code>max_size</code>,如果超过了，那么把最久未访问的文件从磁盘中进行删除。</li>\n</ul>\n<h3 id=\"2-注意事项\"><a href=\"#2-注意事项\" class=\"headerlink\" title=\"2 注意事项\"></a>2 注意事项</h3><p>nginx采用了异步、事件驱动的方法来处理连接。这种处理方式无需（像使用传统架构的服务器一样）为每个请求创建额外的专用进程或者线程，而是在一个工作进程中处理多个连接和请求。为此，nginx工作在非阻塞的socket模式下，并使用了epoll 和 kqueue这样有效的方法。nginx从队列中取出一个事件并对其做出响应，比如读写socket。在多数情况下，这种方式是非常快的（也许只需要几个CPU周期，将一些数据复制到内存中），nginx可以在一瞬间处理掉队列中的所有事件。</p>\n<p>但是，如果nginx要处理的操作是一些又长又重的操作，又会发生什么呢？整个事件处理循环将会卡住，直到这个事件操作执行完毕，下个事件才能被处理。</p>\n<p>而在启用proxy cache后，这种又长又重的活很可能就是读写磁盘。在FreeBSD系统中，提供了异步读写文件的接口，可以配置nginx使用，nginx直接管理文件描述符；在Linux中，虽然提供了异步接口，但是需要设置O_DIRECT，这将导致任何对文件的访问都忽略磁盘缓存，直接从磁盘中获取，这增加磁盘的负载。在用<code>dd</code> 来测试磁盘的IO，设置O_DIRECT后，测试数据下降的厉害。</p>\n<p>对于这种情况，nginx提出了线程池进行解决。</p>\n<h4 id=\"2-1-线程池\"><a href=\"#2-1-线程池\" class=\"headerlink\" title=\"2.1 线程池\"></a>2.1 线程池</h4><p>当工作进程需要执行一个潜在的长操作时，工作进程不再自己执行这个操作，而是将任务放到线程池队列中，任何空闲的线程都可以从队列中获取并执行这个任务。</p>\n<p>线程池的配置非常简单、灵活。我们只需要在http、 server，或者location上下文中包含aio threads指令即可：</p>\n<pre><code>thread_pool default threads=32 max_queue=65536;\naio threads=default;\n</code></pre><ul>\n<li>default： 线程池的名字；</li>\n<li>theads=32： 线程池线程数量；</li>\n<li>max_queue： 任务队列最多支持65536个请求；</li>\n</ul>\n<p>在proxy cache中配置为：</p>\n<pre><code>server {\n        ....\n        thread_pool default threads=32 max_queue=65536;\n        aio threads=default;\n        proxy_cache mycache;\n        proxy_cache_key    $host$uri$is_args$args;\n\n        location / {\n            proxy_pass http://origin:80;\n        }\n    }\n</code></pre><p>上面配置使用线程池来处理磁盘的读写操作。</p>\n<h4 id=\"2-2-磁盘页缓存\"><a href=\"#2-2-磁盘页缓存\" class=\"headerlink\" title=\"2.2 磁盘页缓存\"></a>2.2 磁盘页缓存</h4><p>虽然上面介绍了使用线程池优化读写磁盘，但是也不用着急去使用。因为nginx在缓存的时候会主动发一些hint给系统，系统把相关的页进行缓存；就算没有nginx的主动提示，Linux中也会把频繁访问的页缓存下来。这样nginx从磁盘缓存中读取数据也是非常快的。</p>\n<p>所以如果缓存的内容少，没必要使用线程池，毕竟把读写放到连接池中也是需要开销的。</p>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><p>为了获得更好的性能，缓存目录通常配置为单独的磁盘，有条件可以使用性能更好的SSD，nginx对静态文件的读取进行了优化，从文件缓存中读取比请求后端服务器读取，速度快了一个数量级；所以在频繁访问的文件使用文件缓存性能理想。</p>\n","categories":["未分类"],"tags":["技术"]},{"title":"Yeoman前端自动化构建","url":"http://fengjianque.github.io/2017/02/07/yoeman/","content":"<h2 id=\"Yeoman前端自动化构建\"><a href=\"#Yeoman前端自动化构建\" class=\"headerlink\" title=\"Yeoman前端自动化构建\"></a>Yeoman前端自动化构建</h2><p>作为一名长期习惯在后端捣鼓的web开发人员，要兼顾前端的开发时，对于前端组织和优化往往不得要领，需要学习前端的知识来提高开发效率和优化web性能。目前我所接触到的web项目并不能完全前后端分离（后端只提供接口给前端），基本都是后端程序员将数据填进页面模板加以渲染，所以本文着重前端静态资源的自动化构建部分。</p>\n<p>Yeoman是一套针对Web应用开发流程进行管理的工具集，它将前端无序、繁杂的操作组织起来，利用工具简化、规范前端流程，实现项目构建、开发、维护的一体化。用到的工具主要有以下3个：</p>\n<ul>\n<li>yo：脚手架工具；</li>\n<li>bower： 包管理工具；</li>\n<li>glup（grunt升级版）：构建工具；</li>\n</ul>\n<p>这三个工具是分别独立开发的，但是需要配合使用，来实现我们高效的工作流模式。</p>\n<p>Yeoman的项目中工作流程一般是：</p>\n<ol>\n<li>yo创建项目骨架：运行yo工具，通过各种yeoman-generator（模板）创建项目骨架;</li>\n<li>bower下载前端资源：运行bower install，下载项目中依赖的前端资源，比如jQuery、bootstrap、angularjs等；</li>\n<li>gulp运行构建任务：运行grunt跑自动化构建任务等；</li>\n</ol>\n<h3 id=\"nodejs安装\"><a href=\"#nodejs安装\" class=\"headerlink\" title=\"nodejs安装\"></a>nodejs安装</h3><p>在使用yeoman工具之前需要先安装nodejs，nodejs目前没有apt方式安装，需要用源码编译安装。<br>从github上下载源码,根据tag选择需要的版本，我选择的是0.12.0:</p>\n<pre><code>git clone https://github.com/joyent/node.git\ngit checkout v0.12.0\n</code></pre><p>编译安装：</p>\n<pre><code>./configure\nmake\nsudo make install\n</code></pre><p>安装好后，npm包管理工具也在其中了。</p>\n<p><strong>ps</strong>： npm默认的安装源是国外的，下载速度很慢，可以在用户目录下配置国内镜像源：</p>\n<pre><code>registry = http://r.cnpmjs.org/\n</code></pre><p>保存为.npmrc。</p>\n<p>然后安装Yeoman的3个工具：</p>\n<pre><code>sudo npm install -g yo bower gulp\n</code></pre><h3 id=\"yo\"><a href=\"#yo\" class=\"headerlink\" title=\"yo\"></a>yo</h3><p>yo是项目脚手架工具，在创建项目的时候使用，它帮你搭起项目的骨架，比如生成项目的目录结构，配置常用的插件，提供包括代码校验，测试，压缩 的项目流程。这好比IDE工具，eclipse，xcode等，创建一个项目时，帮你生成一些文件和目录，搭起项目雏形，只不过yo没有提供界面。</p>\n<p>yo提供了非常多的模板，用来生成不同类型的 Web 应用。这些模板称为生成器（generator）。这些模板以一个工程化标准方式在项目初期阶段就建立好良好的代码结构和流程习惯，整合了业界的最佳实践。<br>generator-webapp是其中一个最典型的web项目模板，使用前需要npm先安装：</p>\n<pre><code>npm install -g generator-webapp\n</code></pre><p>然后用yo进行安装：</p>\n<pre><code>mkdir mywebapp\ncd mywebapp\nyo webapp   #使用generator-webapp生成器模板\n</code></pre><p>创建过程中会让你选择sass，bootstrap这些组件，根据项目需要选择，我选择了bootstrap，得到目录结构如下：</p>\n<pre><code>.\n|-- app\n|   |-- robots.txt\n|   |-- index.html\n|   |-- styles\n|   |    |\n|   |    `-- main.css\n|   `-- scripts\n|        |\n|        `-- main.js\n|\n|-- bower.json\n|-- bower_components\n|   |-- bootstrap\n|   |-- jquery\n|   `-- ....\n|\n|-- gulpfile.babel.js\n|-- package.json\n|-- node_modules\n|   |-- gulp\n|   |-- gulpuglify\n|   `-- ....\n|\n`-- test\n   |-- index.html\n   `-- spec\n</code></pre><p>下面对目录进行简单介绍：</p>\n<ul>\n<li>app：源文件的存放目录,未压缩的js,css,scss等;</li>\n<li>bower.json：bower的配置文件，根据配置安装第3方组件到bower_components文件夹下;</li>\n<li>bower_components：使用bower安装的第3方组件的源代码,jquery,bootstrap等;</li>\n<li>package.json: gulp的配置文件，根据配置安装gulp的依赖组件到node_modules文件夹下</li>\n<li>node_modules：gulp需要用到的工具模块安装目录;</li>\n<li>gulpfile.babel.js: gulp的任务配置文件，根据任务配置自动化处理css,js等；</li>\n<li>test 单元测试存放目录；</li>\n</ul>\n<p>整个目录都很清晰，大致就是三部分：源文件，bower第三方库，gulp构建部分；</p>\n<h3 id=\"bower\"><a href=\"#bower\" class=\"headerlink\" title=\"bower\"></a>bower</h3><p>bower作为一个前端包依赖管理的工具，它可用于搜索、安装和卸载如JavaScript、HTML、CSS之类的网络资源。类似于java中maven，python中pip工具；<br>使用bower可以让你轻松的引入一个前端所需要的包，帮你解决包之间的依赖关系，比如你项目中会用到了bootstrap, jquery, jquery.ui. 这三个库都用到了jquery，所以你必须要去找到一个合适的jquery版本来让bootstrap和jquery.ui都可以正常工作，使用bower这些都不需要你来操心，一条命令即可。</p>\n<h4 id=\"bower使用\"><a href=\"#bower使用\" class=\"headerlink\" title=\"bower使用\"></a>bower使用</h4><p>bower依赖node，npm，git工具，使用bower需要先安装好这些工具。</p>\n<p>执行命令：</p>\n<pre><code>bower install jquery\n</code></pre><p>在当前目录下自动创建<code>bower_components</code>文件，里面存放了jquery部件。</p>\n<h5 id=\"bower-json\"><a href=\"#bower-json\" class=\"headerlink\" title=\"bower.json\"></a>bower.json</h5><p>还可以通过配置 <code>bower.json</code> 文件，配置需要的安装的库以及版本等，该文件可以通过命令：</p>\n<pre><code>bower init\n</code></pre><p>创建符合bower规范的包配置文件，有了这个文件，直接执行<code>bower install</code>命令，bower自动在当前目录下搜索该文件，并自动安装已经配置的包文件。以后安装其他库加上<code>--save</code>参数，bower安装完该库后，把信息添加到bower.json文件中，然后把这个bower.json文件传给其他人，也是一条命令就搞定的事。</p>\n<h5 id=\"bowerrc\"><a href=\"#bowerrc\" class=\"headerlink\" title=\".bowerrc\"></a>.bowerrc</h5><p>bower 支持一个 <code>.bowerrc</code> 的配置，可以放置在当前目录下。就像yo生成的webapp项目下面就有这个文件。可以配置默认的安装目录directory,下载代理proxy,https-proxy等。<br>详见官方文档<br><a href=\"https://github.com/bower/spec/blob/master/config.md\" target=\"_blank\" rel=\"external\">https://github.com/bower/spec/blob/master/config.md</a> 。</p>\n<h5 id=\"bower其他命令\"><a href=\"#bower其他命令\" class=\"headerlink\" title=\"bower其他命令\"></a>bower其他命令</h5><ul>\n<li><p>bower list 列出当前的安装包，以及包之间的依赖关系；</p>\n<pre><code>bower list\n├─┬ bootstrap#3.3.6 (latest is 4.0.0-alpha.2)\n│ └── jquery#2.2.1 (latest is 3.0.0-beta1)\n├── chai#3.5.0\n└── mocha#2.4.5\n</code></pre></li>\n<li><p>bower uninstall 删除包</p>\n</li>\n<li>bower info 查看包的信息</li>\n</ul>\n<p>yo脚手架已经将bower合进来了，只要在项目目录下进行上面介绍的操作就行了。</p>\n<h3 id=\"gulp\"><a href=\"#gulp\" class=\"headerlink\" title=\"gulp\"></a>gulp</h3><p>最成熟和强大的要数这个gulp工具了，它不仅能对网站资源进行优化，而且能帮我们完成前端开发过程中的很多重复的任务用来运行各种任务，比如文件压缩、合并、打包等；项目生成、预览和自动化测试。</p>\n<p>gulp本身不具备很多功能，主要依赖于一系列的功能插件，是一个基于流的构建工具；gulp构建的任务就是把合适的插件组装起来，像一条自动化的流水线一样，前一级的的输出变成后一级的输入，完成压缩，合并等复杂的功能。</p>\n<p>gulp的全局安装前面介绍过了，需要通过npm包安装（前提是已经安装了nodejs环境 和 npm）。</p>\n<p>####package.json<br>gulp的插件是由npm来管理的，由npm来安装。和bower的bower.json文件一样，npm使用<code>package.json</code>配置和管理所需的插件。实际上bower也是npm的一个模块。<br>npm安装的插件放置在当前目录的node-moduels目录中，package.json可以由命令：</p>\n<pre><code>npm init\n</code></pre><p>创建，可以在该文件中配置依赖的插件和版本，运行「npm install」命令，自动在当前目录下寻找package.json文件安装插件。<br>此外，安装其他插件加上<code>--save-dev</code>, npm安装完后将插件信息添加到package.json中。</p>\n<h4 id=\"gulpfile-js\"><a href=\"#gulpfile-js\" class=\"headerlink\" title=\"gulpfile.js\"></a>gulpfile.js</h4><p>gulp任务的构建需要依赖一个js文件<code>gulpfile.js</code>，而我们的项目中的却是gulpfile.babel.js，这是因为这个文件中用了<code>ES6</code>的语法，gulp会自动调用babel插件转成<code>ES5</code>语法。在这个文件中，定义我们的各种需求任务。</p>\n<pre><code>import gulp from &apos;gulp&apos;;\ngulp.task(&apos;default&apos;,function() =&gt; {\n    console.log(&apos;hello world&apos;);\n});\n</code></pre><p>上面我们定义的一个最简单的任务, 名字为default, 就是打印一个hello;  这个任务没有用到其他插件，还没体现流的概念。</p>\n<p>要运行gulp任务，只需切换到存放gulpfile.js文件的目录，然后在命令行中执行gulp命令就行了，gulp后面可以加上要执行的任务名，例如gulp task1，如果没有指定任务名，则会执行任务名为<code>default</code>的默认任务。</p>\n<h4 id=\"gulp-API\"><a href=\"#gulp-API\" class=\"headerlink\" title=\"gulp API\"></a>gulp API</h4><p>要掌握gulp 的使用一点不难，我认为只要记住下面的几个API差不多了：</p>\n<ul>\n<li><p>gulp.task(name[, deps], fn)用来定义任务</p>\n<ul>\n<li>name：任务名</li>\n<li>deps：是当前定义的任务需要依赖的其他任务，为一个数组。当前定义的任务会在所有依赖的任务执行完毕后才开始执行。如果没有依赖，则可省略这个参数；</li>\n<li>fn 为任务函数，我们把任务要执行的代码都写在里面。该参数也是可选的。</li>\n</ul>\n</li>\n<li><p>gulp.src(globs[, options])定义所要读取的原文件路径，然后返回一个可以传递给插件的数据流。</p>\n<ul>\n<li>globs：文件匹配模式，string或者array类型</li>\n<li>options为可选参数；</li>\n</ul>\n</li>\n</ul>\n<p>举例：</p>\n<pre><code>gulp.src(&quot;js/a.js&quot;);              //指定js目录下a.js文件\ngulp.src(&quot;js/*.js&quot;);              //指定js目录下任意js文件\ngulp.src(&quot;js/**/*.js&quot;);           //指定js目录下所有js文件,包括任意子目录\ngulp.src([&quot;js/**/*.js&quot;,&quot;!js/**/*.min.js&quot;])   //指定js目录下所有非压缩js文件\n</code></pre><ul>\n<li><p>.pipe()管道命令，用来链接gulp插件的，可以理解为将操作加入执行队列。所谓管道，就是将上一个命令的输出重定向到下一个命令的输入，一个插件处理完传到下一个插件</p>\n</li>\n<li><p>gulp.dest(path[,options])定义用来指明处理完以后的文件存放路径，它将前面管道的输出写入文件，同时将这些输出继续输出下一级。</p>\n<ul>\n<li>path 写入文件的路径；</li>\n<li>options 可选参数，如指定options.mode（文件的权限值）</li>\n</ul>\n</li>\n<li><p>gulp.watch(glob[, opts], tasks)监视文件的变化，并且运行相应的tasks</p>\n<ul>\n<li>glob 为要监视的文件匹配模式，规则和用法与gulp.src()方法中的glob相同；</li>\n<li>opts 为一个可选的配置对象，通常不需要用到。</li>\n<li>tasks 为文件变化后要执行的任务，为一个数组。</li>\n</ul>\n</li>\n<li>gulp.watch(glob[, opts, cb])，watch另外一种方式，传人回调函数function（event）作为参数</li>\n<li>gulp.run(tasks)使用代码执行任务。任务是并发执行的。</li>\n</ul>\n<p>我们摒弃yo生成的gulpfile.babel.js帮我们生成的任务，而创建几个入门task，在这之前得先介绍几个任务中需要的插件：</p>\n<ul>\n<li>gulp-load-plugins自动帮你加载package.json文件里的gulp插件</li>\n<li>main-bower-files 读取bower安装的文件</li>\n<li>gulp-minify-css 压缩css</li>\n<li>gulp-minify-html 压缩html</li>\n<li>gulp-uglify 压缩js</li>\n<li>gulp-jshint(需要同时安装jshint) js语法静态检查</li>\n<li>gulp-concat 合并多个文件</li>\n<li>gulp-imagemin 压缩图片</li>\n<li>gulp-rename 重命名文件,通常压缩后的带.min后缀</li>\n<li>gulp-flatern 改变文件的路径层级</li>\n<li>del 清理文件或目录</li>\n</ul>\n<p>可以通过<code>npm install --save-dev [插件名称]</code>来安装。</p>\n<h3 id=\"构建任务\"><a href=\"#构建任务\" class=\"headerlink\" title=\"构建任务\"></a>构建任务</h3><p>我们对项目中的js,css,html文件进行压缩，开启一个静态server服务，监听源文件的变化，安装项目。</p>\n<ol>\n<li><p>加载插件<br>引入插件有3步，安装-加载-使用，加载方式如下：<br>在ES6语法里面可以使用</p>\n<pre><code>import gulp from &apos;gulp&apos;;\nimport gulpLoadPlugins from &apos;gulp-load-plugins&apos;;\n</code></pre><p> 而在ES5中的方式是这样的</p>\n<pre><code>var gulp=require(&apos;gulp&apos;);\nvar gulpLoadPlugins=require(&apos;gulp-load-plugins&apos;);\n</code></pre><p> 一个个插件很麻烦，于是就有gulp-load-plugins插件（上面引入的），可以加载package.json文件中所有的gulp模块。gulp-load-plugins加载后执行：</p>\n<pre><code>var $ = gulpLoadPlugins({pattern: &quot;*&quot;})；\n</code></pre><p>就加载了所有的插件。<code>$</code>可以用其它变量名表示。然后我们要使用gulp-rename和gulp-minify-html这两个插件的时候，就可以使用$.rename和$.minifyHtml来代替了,也就是原始插件名去掉gulp-前缀，之后再转换为驼峰命名。但是要注意 <strong>pattern默认值是[‘gulp-<em>‘, ‘gulp.</em>‘]</strong>，如果gulpLoadPlugins不修改pattern参数，只加载名字是gulp开头的插件。</p>\n</li>\n<li><p>压缩css</p>\n<pre><code>gulp.task(&quot;styles&quot;,function() {\n    return gulp.src(&quot;app/styles/*.css&quot;)\n    .pipe($.minifyCss())\n    .pipe($.rename({suffix:&quot;.min&quot;}))\n    .pipe(gulp.dest(&quot;dist/styles&quot;));\n});\n</code></pre><p>上面的任务流程一目了然，gulp.src读入源文件的所有css文件变成一个对象流，用pipe管道传入到gulp-minify-css插件，由它进行css压缩，完成后传入下一级的插件gulp-rename将文件名添加一个min的后缀，最后把文件保存到dist/styles目录下。</p>\n</li>\n<li><p>js语法检查、合并、压缩</p>\n<pre><code>gulp.task(&quot;scripts&quot;,function() {\n    return gulp.src(&quot;app/scripts/**/*.js&quot;) //读取js文件\n    .pipe($.jshint())  //js语法检查\n    .pipe($.jshint.reporter(&apos;default&apos;))  //检查结果输出\n    .pipe($.concat(&apos;main.js&apos;))   //合并所有js文件到main.js\n    .pipe($.uglify())   // 压缩js\n    .pipe($.rename({suffix:&quot;.min&quot;}))  //重命名\n    .pipe(gulp.dest(&quot;dist/scripts&quot;));  //输出\n});\n</code></pre><p>这个任务把app源码目录下的所有js文件合并成一个main.js，然后对main.js进行压缩输出。</p>\n</li>\n<li><p>读取bower_components<br>通过bower安装的第三方库，除了js,css文件外，往往有很多其他目录和文件，如何读取主要的css,jss到安装目录呢，我们借助glup-flatern, main-bower-files这两个插件。</p>\n<p> <code>main-bower-files</code>这个插件会读取bower.json的<code>dependencies</code>, 读取每个package的<code>main</code>属性，根据这些属性读取对应的文件。</p>\n<p> <code>gulp-flatern</code>这个插件可以把文件的路径根据需要变短，如a/b/c/jquery.js, 可以变为jquery.js, b/jquery.js, c/jquery.js, b/c/jquery.js。</p>\n<pre><code>gulp.task(&apos;bowerfiles&apos;, function() {\n    return gulp.src($.mainBowerFiles(),{ base: &apos;./bower_components&apos; })\n        .pipe($.flatten({ includeParents: 1})) //保留一层路径\n        .pipe(gulp.dest(&quot;dist/bower_components&quot;))\n</code></pre><p> });<br>执行后得到的路径类似如下：</p>\n<pre><code>dist── bower_components\n        ├── bootstrap\n        │   ├── bootstrap.js\n        │   ├── bootstrap.min.js\n        │   ├── bootstrap.css\n        │   └── bootstrap.min.css\n        └── jquery\n            └── jquery.js\n</code></pre></li>\n</ol>\n<ol>\n<li><p>图片压缩<br>图片压缩使用了gulp-imagemin插件和gulp-cache插件，鉴于压缩图片时比较耗时，而且不常修改，我们使用”gulp-cache插件加快构建过程，只压缩修改的图片，没有修改的图片直接从缓存文件读取。</p>\n<pre><code>gulp.task(&apos;images&apos;, function() {\n  return gulp.src(&apos;app/images/**/*&apos;)\n    .pipe($.cache($.imagemin({\n      progressive: true,\n      interlaced: true,\n      // don&apos;t remove IDs from SVGs, they are often used\n      // as hooks for embedding and styling\n      svgoPlugins: [{cleanupIDs: false}]\n    })))\n    .pipe(gulp.dest(&apos;dist/images&apos;));\n});\n</code></pre></li>\n<li><p>清理任务<br>构建一个任务，用来清理临时文件，安装目录，使用了gulp-del插件：</p>\n<pre><code>var del = require(&apos;del&apos;);\ngulp.task(&apos;clean&apos;, function() {\n  del(&apos;dist&apos;);\n});\n</code></pre></li>\n<li><p>默认任务<br>默认任务可以简单的执行已存在的任务</p>\n<pre><code>gulp.task(&quot;default&quot;, [&quot;styles&quot;,&quot;scripts&quot;,&quot;bowerfiles&quot;,&quot;images&quot;],function() {\n    console.log(&quot;gulp task finished!&quot;);\n});\n</code></pre></li>\n<li><p>监控任务<br>监控任务一般配合一个静态服务执行，也就是说要一个常驻进程才能有效果。执行gulp watch任务，当配置的目录发生变化时，执行相应的任务。</p>\n<pre><code>gulp.task(&quot;watch&quot;,function() {\n    gulp.watch(&quot;app/**/*.css&quot;,[&quot;styles&quot;]);\n    gulp.watch(&quot;app/**/*.js&quot;,[&quot;scripts&quot;]);\n    gulp.watch(&quot;app/images/*.&quot;,[&quot;images&quot;]);\n    gulp.watch(&quot;bowerfiles/**/.*&quot;, [&quot;bowerfiles&quot;]);\n});\n</code></pre></li>\n</ol>\n<p>gulpfile.js编辑完成后，只要输入<code>gulp 『任务名』</code>就可以执行任务了，如果执行过程中遇到莫名其妙的错误，可能是node-modules有些插件没安装成功，把node-modules目录删除，执行<code>npm install</code>重新安装，然后执行任务即可。</p>\n<p>上面介绍的都是gulp入门级的任务，gulp的功能远不止这些，当然需要你了解更多插件的功能，甚至还可以自己开发所需的插件，组合运用起来完成更复杂的需求。</p>\n<p>###和后端程序的结合实践<br>总的来说，一个web项目简单分为前端静态资源和后端服务程序，下面是我常用的project目录，结构清晰的表明这两部分。app后端业务程序将数据填入templates的页面中，返回给客户端, 完成动态交互部分；app这部分一般是打包然后安装到运行环境中，以模块的方式调用执行，static这部分其实就是yo产生的webapp部分，由gulp进行构建。整个project可以写个Makefile文件集合打包、构建、部署的命令，方便我们一键部署。</p>\n<pre><code>project\n|-- app\n|   |-- __init__.py\n|   |-- templates\n|   |   |-- home.html\n|   |   |-- user.html\n|   |   `-- ....\n|   |-- model\n|   |   |-- __init__.py\n|   |   `-- ....\n|   |-- views\n|   |   |-- __init__.py\n|   |   `-- ....\n|   |-- urls.py\n|   `-- wsgi.py\n|\n|\n|-- static\n|   |-- src\n|   |     |-- robots.txt\n|   |     |-- index.html\n|   |     |-- styles\n|   |     |    |\n|   |     |    `-- *.css\n|   |     `-- scripts\n|   |         |\n|   |         `-- *.js\n|   |\n|   |-- bower.json\n|   |-- bower_components\n|   |     |-- bootstrap\n|   |     |-- jquery\n|   |     `-- ....\n|   |\n|   |-- gulpfile.babel.js\n|   |-- package.json\n|   |-- node_modules\n|   |-- gulp\n|   |-- gulpuglify\n|   `-- ....\n|\n|-- setup.py\n|-- Makefile\n`-- ...\n</code></pre><p>部署后运行环境目录变成：</p>\n<pre><code>project\n|-- var\n|   |-- www\n|   |   |-- index.html\n|   |   |-- js\n|   |   |-- css\n|   |   |-- images\n|   |   `-- ...\n|   |-- logs\n|   `-- ...\n|-- etc\n`-- ...\n</code></pre><p>在web服务器中，对于访问静态资源的请求配置直接指向项目var/www的路径。要注意的后端程序中templates中使用到静态资源的路径必须为web服务器中的虚拟路径，这样才能正确找到对应的文件。</p>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><p>本文只阐述了Yeoman自动化构建的内容，其他与异步加载的结合，ES6规范使用等并未过多叙述。前端的技术发展越来越成熟了，汲取一点已够我受用，还有更强大的功能等待我发掘和引用，进一步整合工程的最佳实践，优化web性能。前端发展太快了，至于本文先所阐述的前端构建和优化技术，或许已经有了更好的替代方案，anyway，欢迎大家来指正。</p>\n<h3 id=\"参考：\"><a href=\"#参考：\" class=\"headerlink\" title=\"参考：\"></a>参考：</h3><p><a href=\"http://yeoman.io/authoring/index.html\" target=\"_blank\" rel=\"external\">http://yeoman.io/authoring/index.html</a><br><a href=\"https://www.smashingmagazine.com/2014/06/building-with-gulp/\" target=\"_blank\" rel=\"external\">https://www.smashingmagazine.com/2014/06/building-with-gulp/</a><br><a href=\"http://www.w3ctrain.com/2015/12/22/gulp-for-beginners/\" target=\"_blank\" rel=\"external\">http://www.w3ctrain.com/2015/12/22/gulp-for-beginners/</a><br><a href=\"http://www.eguneys.com/blog/2014/09/17/lets-build-a-yeoman-generator-project-template-slash-w-gulp\" target=\"_blank\" rel=\"external\">http://www.eguneys.com/blog/2014/09/17/lets-build-a-yeoman-generator-project-template-slash-w-gulp</a><br><a href=\"http://gulpjs.com/plugins/\" target=\"_blank\" rel=\"external\">http://gulpjs.com/plugins/</a></p>\n","categories":["未分类"],"tags":["技术"]},{"title":"crush算法","url":"http://fengjianque.github.io/2017/02/07/crush/","content":"<h1 id=\"crush算法\"><a href=\"#crush算法\" class=\"headerlink\" title=\"crush算法\"></a>crush算法</h1><p>分布式存储元数据在实现过程中主要有两类设计：中心化和去中心化。<br>中心化：元数据存储在一个中心的服务器中，客户端增加数据时，中心服务器进行分布数据和记录数据的信息，查询数据时，从中心服务器获取位置信息，读取内容；<br>去中心化：中心服务器存储少量的元数据，某个数据的分布由客户端通过一个分布算法计算得到；</p>\n<p>中心化的设计的优点就是管理简单，缺点是中心节点容易成为瓶颈；去中心化刚好相反，优点是将压力分散到各存储节点，无单点故障，缺点是管理复杂，存储结构变化时数据迁移困难；</p>\n<p>ceph是一个开源的分布式存储系统，具有高性能，高可靠性、可扩展性，使用crush数据分布算法去中心化，在客户端计算数据位置，可以具体到某个磁盘，某个机器，某个机架，甚至是某个数据中心，这样就可以考虑到机房、机架、机器这样的存储层次，在每层设置不同的存储策略，从而达到较好的分布效果。而且使用该算法在存储设备增加删除时，只有小部分的数据需要移动，减少迁移成本。</p>\n<p>本文将介绍ceph的核心数据分布算法-crush。</p>\n<h2 id=\"一致性哈希\"><a href=\"#一致性哈希\" class=\"headerlink\" title=\"一致性哈希\"></a>一致性哈希</h2><p>一致性哈希算法是分布式系统中常用的算法。比如，一个分布式的存储系统，要将数据存储到具体的节点上，如果采用普通的hash方法，将数据映射到具体的节点上，如key%N，key是数据的key，N是机器节点数，如果有一个机器加入或退出这个集群，则所有的数据映射都无效了，如果是持久化存储所有的数据都要迁移，如果是分布式缓存，则其他缓存就失效了。一致性哈希算法将存储对象映射到一个环上，当存储服务器数量发生变化时，只影响相邻的服务器，规避了大规模的数据震荡和存储映射失效。crush算法有点类似一致性哈希，但是一致性哈希没有考虑的存储设备的层次性，不能对存储设备进行加权控制。</p>\n<p>crush算法目的是使数据能够根据设备的存储能力加权控制并保持一个相对的概率平衡地分布，并且在设备增加或退出集群时，较优的使迁移的数据量少。副本放置在具有层次结构的存储设备中，这对数据安全也有重要影响。crush算法通过集群的拓扑信息，副本放置策略可以将数据对象独立在不同故障域，同时仍然保持所需的分布。例如，为了防止可能的并发故障，应该确保设备上的数据副本放置在不同的机架、主机、电源、控制器、或其他的物理位置。</p>\n<h2 id=\"crush算法描述\"><a href=\"#crush算法描述\" class=\"headerlink\" title=\"crush算法描述\"></a>crush算法描述</h2><p>crush需要输入key值X、cluster map(描述存储集群的层级结构)、和数据分布规则(rule)。分布算法由描述存储集群的层级结构cluster map控制。这个map可以这样描述：集群有多个数据中心，每个数据中心有不同机房构成，机房又有机架，机架装满服务器，服务器装满磁盘。数据分配的策略是由定位规则来定义的，定位规则指定了集群中将保存多少个副本，以及数据副本的放置有什么限制。例如，可以指定数据有三个副本，这三个副本必须放置在不同的机柜中，使得三个数据副本不公用一个物理电路。每一层的设备还可以分配一个权重，crush算法根据种每个设备的权重尽可能概率平均地分配数据。</p>\n<p>下图为存储拓扑结构：<br><img src=\"http://iamsummer-wordpress.stor.sinaapp.com/uploads/2016/02/Snip20160216_2.png\" alt=\"\"></p>\n<p>给定一个输入x，crush算法将输出一个确定的有序的储存目标向量R。当输入x，crush利用多重整数hash函数根据集群map、分配规则（rule）、以及x计算出独立的完全确定可靠的映射关系。crush分配算法是伪随机算法，并且输入的内容和输出的储存位置之间是没有显式相关的。我们可以说crush算法在集群设备中生成了“伪集群”的数据副本。调用过程描述如下：</p>\n<figure class=\"highlight livescript\"><table><tr><td class=\"code\"><pre><div class=\"line\">• CRUSH<span class=\"function\"><span class=\"params\">(X)</span>  -&gt;</span>  R(osdn1, osdn2, osdn2)</div><div class=\"line\">• 参数</div><div class=\"line\">    – X input key</div><div class=\"line\">    – Hierachical Cluster map：可用存储资源层级结构（有多少机架，每个机架上有多少服务器）</div><div class=\"line\">    – Placement rules：每个对象有多少个副本，副本分配限制条件，比如<span class=\"number\">3</span>个副本在不同的机架上</div><div class=\"line\">• 输出一组存储目标集合</div></pre></td></tr></table></figure>\n<h2 id=\"Cluster-map\"><a href=\"#Cluster-map\" class=\"headerlink\" title=\"Cluster map\"></a>Cluster map</h2><p>Ceph将系统的所有硬件资源描述成一个树状结构，由device和bucket组成，它们都有id和权重值。bucket是每层存储的抽象，可以是（机房，机架），device是叶子节点。Bucket可以包含任意数量item，表示子节点。item可以都是的devices或者都是buckets。管理员控制存储设备的权重。权重和存储设备的容量有关。Bucket的权重被定义为它所包含所有item的权重之和。crush基于4种不同的bucket选择类型，每种有不同的选择算法。<br>bucket的描述如下：</p>\n<figure class=\"highlight clojure\"><table><tr><td class=\"code\"><pre><div class=\"line\">[bucket-type] [bucket-name] &#123;</div><div class=\"line\">    id [a unique negative numeric ID]</div><div class=\"line\">    weight [the relative capacity/capability of the item(<span class=\"name\">s</span>)]</div><div class=\"line\">    alg [the bucket type: uniform | list | tree | straw ]</div><div class=\"line\">    hash [the hash type: <span class=\"number\">0</span> by default]</div><div class=\"line\">    item [item-name] weight [weight]</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<figure class=\"highlight lsl\"><table><tr><td class=\"code\"><pre><div class=\"line\">rack rack0 &#123;</div><div class=\"line\">        id <span class=\"number\">-5</span>           # do not change unnecessarily</div><div class=\"line\">        weight <span class=\"number\">8.000</span></div><div class=\"line\">        alg uniform     # do not change bucket size (<span class=\"number\">4</span>) unnecessarily</div><div class=\"line\">        hash <span class=\"number\">0</span>  # rjenkins1</div><div class=\"line\">        item host0 weight <span class=\"number\">2.000</span> pos <span class=\"number\">0</span></div><div class=\"line\">        item host1 weight <span class=\"number\">2.000</span> pos <span class=\"number\">1</span></div><div class=\"line\">        item host2 weight <span class=\"number\">2.000</span> pos <span class=\"number\">2</span></div><div class=\"line\">        item host3 weight <span class=\"number\">2.000</span> pos <span class=\"number\">3</span></div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>id为负数，以便与device区分;<br>weight：bucket的权重，为子节点权重之和;<br>alg：bucket的算法类型(uniform, list, tree, straw),选择子节点的方式；<br>hash：bucket中使用到的hash算法；<br>item：bucket里包含哪些元素，即子节点；</p>\n<h2 id=\"rule\"><a href=\"#rule\" class=\"headerlink\" title=\"rule\"></a>rule</h2><p>有了crush map之后，如何一步一步从bucket中选出元素，这个就是有rule来定义的。一个rule就是一系列的操作。<br>一个rule的定义是这样的：</p>\n<figure class=\"highlight sqf\"><table><tr><td class=\"code\"><pre><div class=\"line\">rule &lt;rulename&gt; &#123;</div><div class=\"line\">    ruleset &lt;ruleset&gt;     <span class=\"comment\">//rule id</span></div><div class=\"line\">    <span class=\"built_in\">type</span> [ replicated | raid4 ]</div><div class=\"line\">    min_size &lt;<span class=\"built_in\">min</span>-<span class=\"built_in\">size</span>&gt;   <span class=\"comment\">//备份最小数</span></div><div class=\"line\">    max_size &lt;<span class=\"built_in\">max</span>-<span class=\"built_in\">size</span>&gt;     <span class=\"comment\">//备份最大数</span></div><div class=\"line\">    <span class=\"built_in\">step</span> take &lt;bucket-<span class=\"built_in\">type</span>&gt;     <span class=\"comment\">//从bucket-type开始挑选</span></div><div class=\"line\">    <span class=\"built_in\">step</span> [choose|chooseleaf] [firstn|indep] &lt;N&gt; &lt;bucket-<span class=\"built_in\">type</span>&gt;   <span class=\"comment\">//挑选规则</span></div><div class=\"line\">    <span class=\"built_in\">step</span> emit</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<figure class=\"highlight haskell\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"title\">rule</span>  replicated_ruleset &#123;</div><div class=\"line\">    ruleset <span class=\"number\">1</span></div><div class=\"line\">    <span class=\"class\"><span class=\"keyword\">type</span> replicated</span></div><div class=\"line\">    min_size <span class=\"number\">1</span></div><div class=\"line\">    max_size <span class=\"number\">10</span></div><div class=\"line\">    step take <span class=\"keyword\">default</span></div><div class=\"line\">    step choose firstn <span class=\"number\">2</span> <span class=\"class\"><span class=\"keyword\">type</span> rack</span></div><div class=\"line\">    step chooseleaf firstn <span class=\"number\">0</span> <span class=\"class\"><span class=\"keyword\">type</span> host</span></div><div class=\"line\">    step emit</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>ruleset：id，表明这个rule是属于这个ruleset的。<br>type：表明这个rule在哪使用，storage drive (replicated) or a RAID。<br>min_size和max_size用来限定这个rule的使用范围，当指定副本数小于min_size或者大于max_size的时候，不使用此条rule。<br>step take <bucket-name>：从这个bucket开始往下遍历挑选；<br>step choose firstn {num} type {bucket-type}：选择n个指定类型的bucket，num通常是副本的数量。 此条语句可以有多个；</bucket-name></p>\n<ul>\n<li>num==0，表示选择副本数量的bucket；</li>\n<li>num&gt;0, 表示选择num个bucket；</li>\n<li>num&lt;0, 表示选择r-num个bucket；</li>\n</ul>\n<p>step chooseleaf firstn {num} type {bucket-type}： 表示选择指定数量的指定类型的bucket，从这些bucket中往下遍历获取一个叶子节点；数量的指定同上；<br>step emit： 输出当前选择的值；</p>\n<h2 id=\"crush算法原理\"><a href=\"#crush算法原理\" class=\"headerlink\" title=\"crush算法原理\"></a>crush算法原理</h2><p>crush通过配置的map和rule，进行数据对象及其副本的分配放置。算法的伪代码如下图：<br><img src=\"http://iamsummer-wordpress.stor.sinaapp.com/uploads/2016/02/crush_alg.jpg\" alt=\"\"></p>\n<p>每个rule都包含上述伪代码的操作。crush函数的整型输入参数就是一个典型的存储对象名或者标示符。</p>\n<ul>\n<li>操作take(a)选择了一个在存储层次的bucket并把这个bucket的子item赋值向量i，这是为后面的操作做准备。</li>\n<li>操作select(n,t)，迭代操作每个item(向量i中的item)，对于每个item(向量i中的item)向下遍历(遍历这个item所包含的子item)，都返回n个不同的item(type为t的item)，存储设备有一个绑定类型（例如rows，cabinets）。并把这些item都放到向量i中。作为随后被调用的select(n,t)操作的输入参数或者进行输出。select函数会调用c(r, x)函数，这个函数会在每个bucket中伪随机选择一个item。</li>\n<li>emit：把向量i放到result中。</li>\n</ul>\n<p>例如下图，有4层存储结构的图，存储3个副本；存储策略为从4个机排中随机选择一排，再从这排中选择出3个机柜，从机柜中选择其中一台主机下面的某个盘进行存储。<br><img src=\"http://iamsummer-wordpress.stor.sinaapp.com/uploads/2016/02/Snip20160216_3.png\" alt=\"\"></p>\n<p>对应关系如下：</p>\n<table>\n<thead>\n<tr>\n<th>rule</th>\n<th>Action</th>\n<th>result</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>step take root</td>\n<td>take(root)</td>\n<td>root</td>\n</tr>\n<tr>\n<td>step choose firstn 1 type row</td>\n<td>select(1, row)</td>\n<td>row2</td>\n</tr>\n<tr>\n<td>step choose firstn 3 type cabinet</td>\n<td>select(3, cabinet)</td>\n<td>cab21 cab23 cab24</td>\n</tr>\n<tr>\n<td>step choose firstn 1 type disk</td>\n<td>select(1, disk)</td>\n<td>disk2107 disk2313 disk2437</td>\n</tr>\n</tbody>\n</table>\n<p>###冲突故障过载<br>select(n, t)操作会循环选择第 r=1,…,n 个副本，r作为选择参数。在这个过程中，假如选择到的item遇到三种情况(冲突，故障，超载)时，crush会拒绝选择这个item。</p>\n<ul>\n<li>冲突：这个item已经在向量i中，已被选择。</li>\n<li>故障：设备发生故障，不能被选择。</li>\n<li>超载：设备使用容量超过警戒线，没有剩余空间保存数据对象。</li>\n</ul>\n<p>对于故障和超载，ceph会进行标记，并重启select重新选择；对于冲突情况，算法先在Local域（目标type的父节点孩子节点）内重新选择，尝试有限次数后，如果仍然找不到满足条件的Bucket，那就回到Descent域（当前bucket的子树）重新选择。</p>\n<h3 id=\"bucket算法类型\"><a href=\"#bucket算法类型\" class=\"headerlink\" title=\"bucket算法类型\"></a>bucket算法类型</h3><p>crush映射算法解决了效率和扩展性这两个矛盾的目标。而且当存储集群发生变化时，可以最小化数据迁移，并重新恢复平衡分布。crush定义了四种具有不同算法的的buckets。每种bucket基于不同的数据结构，并有不同的c(r,x)伪随机选择函数。</p>\n<p>不同的bucket有不同的性能和特性：</p>\n<ul>\n<li><p>Uniform Buckets：适用于具有相同权重的item，而且bucket很少添加删除item。增加删除机器后所有数据需要重新分布，但是它的查找速度是最快的。</p>\n</li>\n<li><p>List Buckets：它的结构是链表结构，所包含的item可以具有任意的权重。crush从表头开始查找副本的位置，它先得到表头item的权重Wh、剩余链表中所有item的权重之和Ws，然后根据hash(x, r, i)得到一个[0~1]的值v，假如这个值v在 [0~Wh/Ws)之中，则副本在表头item中，并返回表头item的id，i是item的id号。否者继续遍历剩余的链表。 这类bucket增加机器时移动的数据是最优的，减少机器时需要数据重新分布。</p>\n</li>\n<li><p>Tree Buckets：链表的查找复杂度是O(n)，决策树的查找复杂度是O(log n)。item是决策树的叶子节点，决策树中的其他节点知道它左右子树的权重，节点的权重等于左右子树的权重之和。crush从root节点开始查找副本的位置，它先得到节点的左子树的权重Wl，得到节点的权重Wn，然后根据hash(x, r, node_id)得到一个[0~1]的值v，假如这个值v在[0~Wl/Wn)中，则副本在左子树中，否者在右子树中。继续遍历节点，直到到达叶子节点。Tree Bucket的关键是当添加删除叶子节点时，决策树中的其他节点的node_id不变。决策树中节点的node_id的标识是根据对二叉树的中序遍历来决定的(node_id不等于item的id，也不等于节点的权重)。</p>\n</li>\n<li><p>Straw Buckets：这种类型让bucket所包含的所有item公平的竞争(不像list和tree一样需要遍历)。这种算法就像抽签一样，所有的item都有机会被抽中(只有最长的签才能被抽中)。每个签的长度是由length = f(Wi)<em>hash(x, r, i) 决定的，f(Wi)和item的权重有关，i是item的id号。c(r, x) = MAX(f(Wi) </em> hash(x, r, i))。这种bucket增加删除机器时的数据移动量都是最优的。</p>\n</li>\n</ul>\n<p>各bucket算法比较：</p>\n<table>\n<thead>\n<tr>\n<th>Action</th>\n<th>Uniform</th>\n<th>List</th>\n<th>Tree</th>\n<th>Straw</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>时间复杂度</td>\n<td>O(1)</td>\n<td>O(n)</td>\n<td>O(lgn)</td>\n<td>O(n)</td>\n</tr>\n<tr>\n<td>增加节点</td>\n<td>差</td>\n<td>优</td>\n<td>好</td>\n<td>优</td>\n</tr>\n<tr>\n<td>删除节点</td>\n<td>差</td>\n<td>差</td>\n<td>好</td>\n<td>优</td>\n</tr>\n</tbody>\n</table>\n<p>ceph默认是使用straw类型的bucket，可以根据实际情况进行选择。</p>\n<h2 id=\"crushtool\"><a href=\"#crushtool\" class=\"headerlink\" title=\"crushtool\"></a>crushtool</h2><p>安装ceph系统后，就自带了一个工具crushtool用来测试crush算法，可以创建存储结构map、测试规则rule，模拟数据输入。</p>\n<h3 id=\"创建crushmap\"><a href=\"#创建crushmap\" class=\"headerlink\" title=\"创建crushmap\"></a>创建crushmap</h3><p>我们组建一个存储结构，假如有有2个机架rack， 每个rack下面有2台host， 每个host有2块磁盘，则一共有8个磁盘。<br>我们的bucket有三种: root、rack、host。root包含的item是rack，root选择rack的算法是straw。rack包含的item是host，rack选择host的算法是tree。host包括的item是device，host的选择device的算法uniform。这是因为每个host包括的device的数量和权重是一定的，不会改变，因此要为host选择uniform结构，这样计算速度最快。<br>执行命令：</p>\n<figure class=\"highlight lsl\"><table><tr><td class=\"code\"><pre><div class=\"line\">crushtool --num_osds <span class=\"number\">8</span> -o crushmap --build host uniform <span class=\"number\">2</span> rack tree <span class=\"number\">2</span> root straw <span class=\"number\">0</span></div><div class=\"line\">结果显示：</div><div class=\"line\"># id    weight  type name   reweight</div><div class=\"line\"><span class=\"number\">-7</span>  <span class=\"number\">8</span>   root root</div><div class=\"line\"><span class=\"number\">-5</span>  <span class=\"number\">4</span>       rack rack0</div><div class=\"line\"><span class=\"number\">-1</span>  <span class=\"number\">2</span>           host host0</div><div class=\"line\"><span class=\"number\">0</span>   <span class=\"number\">1</span>               osd<span class=\"number\">.0</span>   <span class=\"number\">1</span></div><div class=\"line\"><span class=\"number\">1</span>   <span class=\"number\">1</span>               osd<span class=\"number\">.1</span>   <span class=\"number\">1</span></div><div class=\"line\"><span class=\"number\">-2</span>  <span class=\"number\">2</span>           host host1</div><div class=\"line\"><span class=\"number\">2</span>   <span class=\"number\">1</span>               osd<span class=\"number\">.2</span>   <span class=\"number\">1</span></div><div class=\"line\"><span class=\"number\">3</span>   <span class=\"number\">1</span>               osd<span class=\"number\">.3</span>   <span class=\"number\">1</span></div><div class=\"line\"><span class=\"number\">-6</span>  <span class=\"number\">4</span>       rack rack1</div><div class=\"line\"><span class=\"number\">-3</span>  <span class=\"number\">2</span>           host host2</div><div class=\"line\"><span class=\"number\">4</span>   <span class=\"number\">1</span>               osd<span class=\"number\">.4</span>   <span class=\"number\">1</span></div><div class=\"line\"><span class=\"number\">5</span>   <span class=\"number\">1</span>               osd<span class=\"number\">.5</span>   <span class=\"number\">1</span></div><div class=\"line\"><span class=\"number\">-4</span>  <span class=\"number\">2</span>           host host3</div><div class=\"line\"><span class=\"number\">6</span>   <span class=\"number\">1</span>               osd<span class=\"number\">.6</span>   <span class=\"number\">1</span></div><div class=\"line\"><span class=\"number\">7</span>   <span class=\"number\">1</span>               osd<span class=\"number\">.7</span>   <span class=\"number\">1</span></div></pre></td></tr></table></figure>\n<h3 id=\"编辑-crush-map\"><a href=\"#编辑-crush-map\" class=\"headerlink\" title=\"编辑 crush map\"></a>编辑 crush map</h3><p>创建之后会在本地目录生成一个crush map的二进制文件，我们可以通过crushtool工具进行反编译。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"code\"><pre><div class=\"line\">crushtool -d crushmap -o <span class=\"built_in\">map</span>.txt</div></pre></td></tr></table></figure>\n<p>打开map.txt得到：</p>\n<figure class=\"highlight lsl\"><table><tr><td class=\"code\"><pre><div class=\"line\"># begin crush map</div><div class=\"line\">tunable choose_local_tries <span class=\"number\">0</span></div><div class=\"line\">tunable choose_local_fallback_tries <span class=\"number\">0</span></div><div class=\"line\">tunable choose_total_tries <span class=\"number\">50</span></div><div class=\"line\">tunable chooseleaf_descend_once <span class=\"number\">1</span></div><div class=\"line\"></div><div class=\"line\"># devices</div><div class=\"line\">device <span class=\"number\">0</span> device0</div><div class=\"line\">device <span class=\"number\">1</span> device1</div><div class=\"line\">device <span class=\"number\">2</span> device2</div><div class=\"line\">device <span class=\"number\">3</span> device3</div><div class=\"line\">device <span class=\"number\">4</span> device4</div><div class=\"line\">device <span class=\"number\">5</span> device5</div><div class=\"line\">device <span class=\"number\">6</span> device6</div><div class=\"line\">device <span class=\"number\">7</span> device7</div><div class=\"line\"></div><div class=\"line\"># types</div><div class=\"line\">type <span class=\"number\">0</span> device</div><div class=\"line\">type <span class=\"number\">1</span> host</div><div class=\"line\">type <span class=\"number\">2</span> rack</div><div class=\"line\">type <span class=\"number\">3</span> root</div><div class=\"line\"></div><div class=\"line\"># buckets</div><div class=\"line\">host host0 &#123;</div><div class=\"line\">        id <span class=\"number\">-1</span>           # do not change unnecessarily</div><div class=\"line\">        # weight <span class=\"number\">2.000</span></div><div class=\"line\">        alg uniform     # do not change bucket size (<span class=\"number\">2</span>) unnecessarily</div><div class=\"line\">        hash <span class=\"number\">0</span>  # rjenkins1</div><div class=\"line\">        item device0 weight <span class=\"number\">1.000</span> pos <span class=\"number\">0</span></div><div class=\"line\">        item device1 weight <span class=\"number\">1.000</span> pos <span class=\"number\">1</span></div><div class=\"line\">&#125;</div><div class=\"line\">host host1 &#123;</div><div class=\"line\">        id <span class=\"number\">-2</span>           # do not change unnecessarily</div><div class=\"line\">        # weight <span class=\"number\">2.000</span></div><div class=\"line\">        alg uniform     # do not change bucket size (<span class=\"number\">2</span>) unnecessarily</div><div class=\"line\">        hash <span class=\"number\">0</span>  # rjenkins1</div><div class=\"line\">        item device2 weight <span class=\"number\">1.000</span> pos <span class=\"number\">0</span></div><div class=\"line\">        item device3 weight <span class=\"number\">1.000</span> pos <span class=\"number\">1</span></div><div class=\"line\">&#125;</div><div class=\"line\">host host2 &#123;</div><div class=\"line\">        id <span class=\"number\">-3</span>           # do not change unnecessarily</div><div class=\"line\">        # weight <span class=\"number\">2.000</span></div><div class=\"line\">        alg uniform     # do not change bucket size (<span class=\"number\">2</span>) unnecessarily</div><div class=\"line\">        hash <span class=\"number\">0</span>  # rjenkins1</div><div class=\"line\">        item device4 weight <span class=\"number\">1.000</span> pos <span class=\"number\">0</span></div><div class=\"line\">        item device5 weight <span class=\"number\">1.000</span> pos <span class=\"number\">1</span></div><div class=\"line\">&#125;</div><div class=\"line\">host host3 &#123;</div><div class=\"line\">        id <span class=\"number\">-4</span>           # do not change unnecessarily</div><div class=\"line\">        # weight <span class=\"number\">2.000</span></div><div class=\"line\">        alg uniform     # do not change bucket size (<span class=\"number\">2</span>) unnecessarily</div><div class=\"line\">        hash <span class=\"number\">0</span>  # rjenkins1</div><div class=\"line\">        item device6 weight <span class=\"number\">1.000</span> pos <span class=\"number\">0</span></div><div class=\"line\">        item device7 weight <span class=\"number\">1.000</span> pos <span class=\"number\">1</span></div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">rack rack0 &#123;</div><div class=\"line\">        id <span class=\"number\">-5</span>           # do not change unnecessarily</div><div class=\"line\">        # weight <span class=\"number\">4.000</span></div><div class=\"line\">        alg tree        # do not change pos for existing items unnecessarily</div><div class=\"line\">        hash <span class=\"number\">0</span>  # rjenkins1</div><div class=\"line\">        item host0 weight <span class=\"number\">2.000</span> pos <span class=\"number\">0</span></div><div class=\"line\">        item host1 weight <span class=\"number\">2.000</span> pos <span class=\"number\">1</span></div><div class=\"line\">&#125;</div><div class=\"line\">rack rack1 &#123;</div><div class=\"line\">        id <span class=\"number\">-6</span>           # do not change unnecessarily</div><div class=\"line\">        # weight <span class=\"number\">4.000</span></div><div class=\"line\">        alg tree        # do not change pos for existing items unnecessarily</div><div class=\"line\">        hash <span class=\"number\">0</span>  # rjenkins1</div><div class=\"line\">        item host2 weight <span class=\"number\">2.000</span> pos <span class=\"number\">0</span></div><div class=\"line\">        item host3 weight <span class=\"number\">2.000</span> pos <span class=\"number\">1</span></div><div class=\"line\">&#125;</div><div class=\"line\">root root &#123;</div><div class=\"line\">        id <span class=\"number\">-7</span>           # do not change unnecessarily</div><div class=\"line\">        # weight <span class=\"number\">8.000</span></div><div class=\"line\">        alg straw</div><div class=\"line\">        hash <span class=\"number\">0</span>  # rjenkins1</div><div class=\"line\">        item rack0 weight <span class=\"number\">4.000</span></div><div class=\"line\">        item rack1 weight <span class=\"number\">4.000</span></div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"># rules</div><div class=\"line\">rule replicated_ruleset &#123;</div><div class=\"line\">        ruleset <span class=\"number\">0</span></div><div class=\"line\">        type replicated</div><div class=\"line\">        min_size <span class=\"number\">1</span></div><div class=\"line\">        max_size <span class=\"number\">10</span></div><div class=\"line\">        step take root</div><div class=\"line\">        step chooseleaf firstn <span class=\"number\">0</span> type host</div><div class=\"line\">        step emit</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"># end crush map</div></pre></td></tr></table></figure>\n<p>通过这个文件可以修改设备的权重值，alg的类型等；</p>\n<h4 id=\"编辑数据分配rule\"><a href=\"#编辑数据分配rule\" class=\"headerlink\" title=\"编辑数据分配rule\"></a>编辑数据分配rule</h4><p>在map.txt中可以看到默认生成一条replicated_ruleset规则。</p>\n<figure class=\"highlight oxygene\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">step</span> <span class=\"keyword\">take</span> root</div><div class=\"line\"><span class=\"keyword\">step</span> chooseleaf firstn <span class=\"number\">0</span> <span class=\"keyword\">type</span> host</div><div class=\"line\"><span class=\"keyword\">step</span> emit</div></pre></td></tr></table></figure>\n<p>这3条step表明从root开始，在不同的主机上分配指定数量的副本。<br>我们将机架考虑进去，将数据分配到不同的机架上面，将规则进行改写：</p>\n<figure class=\"highlight oxygene\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">step</span> <span class=\"keyword\">take</span> root</div><div class=\"line\"><span class=\"keyword\">step</span> choose firstn <span class=\"number\">0</span> <span class=\"keyword\">type</span> rack</div><div class=\"line\"><span class=\"keyword\">step</span> chooseleaf firstn <span class=\"number\">1</span> <span class=\"keyword\">type</span> host</div><div class=\"line\"><span class=\"keyword\">step</span> emit</div></pre></td></tr></table></figure>\n<h4 id=\"编译map\"><a href=\"#编译map\" class=\"headerlink\" title=\"编译map\"></a>编译map</h4><p>将编辑后的map.txt进行编译程二进制文件。</p>\n<figure class=\"highlight swift\"><table><tr><td class=\"code\"><pre><div class=\"line\">crushtool  -<span class=\"built_in\">c</span> <span class=\"built_in\">map</span>.txt  -o <span class=\"built_in\">map</span>.bin</div></pre></td></tr></table></figure>\n<h4 id=\"模拟测试\"><a href=\"#模拟测试\" class=\"headerlink\" title=\"模拟测试\"></a>模拟测试</h4><figure class=\"highlight tap\"><table><tr><td class=\"code\"><pre><div class=\"line\">crushtool -i map.bin  --test --show-statistics --rule<span class=\"number\"> 0 </span>--min-x<span class=\"number\"> 1 </span>--max-x<span class=\"number\"> 5 </span>--num-rep 2</div><div class=\"line\"></div><div class=\"line\">rule<span class=\"number\"> 0 </span>(replicated_ruleset), x = 1..5, numrep = 2..2</div><div class=\"line\">CRUSH rule<span class=\"number\"> 0 </span>x<span class=\"number\"> 1 </span>[4,0]</div><div class=\"line\">CRUSH rule<span class=\"number\"> 0 </span>x<span class=\"number\"> 2 </span>[5,0]</div><div class=\"line\">CRUSH rule<span class=\"number\"> 0 </span>x<span class=\"number\"> 3 </span>[7,3]</div><div class=\"line\">CRUSH rule<span class=\"number\"> 0 </span>x<span class=\"number\"> 4 </span>[6,1]</div><div class=\"line\">CRUSH rule<span class=\"number\"> 0 </span>x<span class=\"number\"> 5 </span>[4,0]</div><div class=\"line\">rule<span class=\"number\"> 0 </span>(replicated_ruleset) num_rep<span class=\"number\"> 2 </span>result size == 2: 5/5</div></pre></td></tr></table></figure>\n<ul>\n<li>–test: 表明调用crushtool的模拟输入功能测试；</li>\n<li>–rule： 使用那条规则；</li>\n<li>–min-x： 输入的X的起始值；</li>\n<li>–max-x：输入的X的终点值；</li>\n<li>–num-rep： 需要的副本数量；</li>\n<li>-i： 二进制的map文件</li>\n<li>–show-statistics： 显示结果</li>\n</ul>\n<p>上面的测试中输入X为1到5， 指定备份数量为2， 对应不同的X值得到分配结果。<br>从结果可以看出，两个副本落在不同的机架的不同主机上面。</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>本文简单的解释了ceph分布式文件存储系统中的核心-数据分配选择算法crush，此算法对传统的算法进行改进，而且适用性比较广，实用性强，可以用在生产环境中。</p>\n<h2 id=\"相关资料：\"><a href=\"#相关资料：\" class=\"headerlink\" title=\"相关资料：\"></a>相关资料：</h2><p><a href=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-1.2.3-Storage_Strategies-en-US/Red_Hat_Ceph_Storage-1.2.3-Storage_Strategies-en-US.pdf\" target=\"_blank\" rel=\"external\">https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-1.2.3-Storage_Strategies-en-US/Red_Hat_Ceph_Storage-1.2.3-Storage_Strategies-en-US.pdf</a><br><a href=\"http://www.crss.ucsc.edu/media/papers/weil-sc06.pdf\" target=\"_blank\" rel=\"external\">http://www.crss.ucsc.edu/media/papers/weil-sc06.pdf</a><br><a href=\"http://www.wzxue.com/ceph-storage/\" target=\"_blank\" rel=\"external\">http://www.wzxue.com/ceph-storage/</a><br><a href=\"https://github.com/ceph/ceph/tree/master/src/crush\" target=\"_blank\" rel=\"external\">https://github.com/ceph/ceph/tree/master/src/crush</a></p>\n","categories":["未分类"],"tags":["技术"]},{"title":"debian8之systemd","url":"http://fengjianque.github.io/2017/02/07/debian8/","content":"<h2 id=\"debian8之systemd\"><a href=\"#debian8之systemd\" class=\"headerlink\" title=\"debian8之systemd\"></a>debian8之systemd</h2><p>2015年4月25日，debian项目组宣布了debian8的正式稳定版本，代号为<strong>Jessie</strong>，该版本将在接下来的5年内获得支持。Jessie一个重大的特性就是之前倍受争议的systemd成为了默认的init系统，而sysv init在此版本依然可用，以实现版本的平滑过度。</p>\n<h3 id=\"1-systemd新特性\"><a href=\"#1-systemd新特性\" class=\"headerlink\" title=\"1 systemd新特性\"></a>1 systemd新特性</h3><p>systemd能取代sysv init系统，它有几大特点：</p>\n<ul>\n<li><p>支持并行化启动服务：<br>sysinit启动服务是一项一项依序启动的，因此没有依赖关系的服务也是要一个个的等待的。systemd就是可以让服务同时并发启动，同时采用socket式与D-Bus总线式激活服务，因此你会发现系統启动的速度变快了。</p>\n</li>\n<li><p>按需启动守护进程（daemon）：<br>当sysv init系统初始化时，它会将所有可能用到的后台服务进程全部启动运行，并且系统必须等待所有的服务都启动就绪后，才允许用户登录。这种做法有两个缺点：首先是启动时间过长；其次是浪费了系统资源。某些服务很可能在很长一段时间内，甚至整个服务器运行期间都没有被使用过。花费在启动这些服务上的时间是不必要的；同样，花费在这些服务上的系统资源也是浪费的。systemd可以提供按需启动能力，只有在某个服务被真正请求时才启动它。当该服务结束后，systemd可以关闭它，等待下次需要时再次启动它。</p>\n</li>\n<li><p>利用cgroups监视进程：<br>用cgroups代替PID来追踪进程，以此即使是两次fork之后生成的守护进程也不会脱离systemd的控制。当进程创建子进程时，子进程会继承父进程的Cgroup。因此无论服务如何启动新的子进程，所有的这些相关进程都会属于同一个Cgroup，systemd只需要简单地遍历指定的Cgroup，即可正确地找到所有的相关进程，将它们一一停止。</p>\n</li>\n<li><p>支持快照和系统恢复：<br>Systemd 快照提供了一种将当前系统运行状态保存并恢复的能力。<br>比如系统当前正运行服务 A 和 B，可以用 systemd 命令行对当前系统运行状况创建快照。然后将进程 A 停止，或者做其他的任意的对系统的改变，比如启动新的进程 C。在这些改变之后，运行 systemd 的快照恢复命令，就可立即将系统恢复到快照时刻的状态，即只有服务 A，B 在运行。一个可能的应用场景是调试：比如服务器出现一些异常，为了调试用户将当前状态保存为快照，然后可以进行任意的操作，比如停止服务等等。等调试结束，恢复快照即可。</p>\n</li>\n<li><p>维护挂载点和自动挂载点： systemd 监视所有的挂载点的进出情况，也可以用来挂载或卸载挂载点。</p>\n</li>\n<li><p>各服务间基于依赖关系进行精密控制：<br>由于systemd可以进行定义服务依赖性，因此如果B服务是依赖A服务的，那当你没有启动A服务的情况下手动启动B服务， systemd会自动帮你启动A服务。这样免去管理员一项一项分析服务的麻烦。</p>\n</li>\n<li><p>提供日志服务：<br>systemd提供了自己日志系统称为 journal。 使用 systemd 日志，无需额外安装日志服务（syslog）。systemd journal 用二进制格式保存所有日志信息，用户使用 journalctl 命令来查看日志信息，无需自己编写复杂脆弱的字符串分析处理程序。</p>\n</li>\n<li><p>和system init向后兼容：<br>systemd 提供了和 sysvinit 以及 LSB initscripts 兼容的特性。系统中已经存在的服务和进程无需修改也能正常运行。这降低了系统向 systemd 迁移的成本，使得 systemd 替换现有初始化系统成为可能。</p>\n</li>\n</ul>\n<p>如何知道自己的init系统是否是systemd？</p>\n<ul>\n<li><p>init系统作为第一个进程启动，指定PID为1，/proc文件系统可以获得程序的启动路径。</p>\n<p>  ls -al /proc/1/exe<br>  rwxrwxrwx 1 root root 0 Jan 10 00:25 /proc/1/exe -&gt; /lib/systemd/systemd</p>\n</li>\n<li><p>运行<code>ls -al /sbin/init</code></p>\n<p>  ls -al /sbin/init<br>  rwxrwxrwx 1 root root 20 Apr 16  2015 /sbin/init -&gt; /lib/systemd/systemd</p>\n</li>\n</ul>\n<p>从上面看到init系统是systemd。</p>\n<h3 id=\"2-systemd约定\"><a href=\"#2-systemd约定\" class=\"headerlink\" title=\"2 systemd约定\"></a>2 systemd约定</h3><p>systemd将以前的服务启动脚本都当成<strong>unit</strong>单元，每种服务依据功能来分，可以分为不同的类型。可以认为一个服务是一个配置单元；一个挂载点是一个配置单元；一个交换分区的配置是一个配置单元。 基本的类型有：系统服务（.service）、挂载点（.mount）、sockets（.sockets ）、系统设备、交换分区/文件(.device)、启动目标（.target）、文件系统路径（.path）、由systemd管理的计时器(.timer)。详情参阅 man 5 systemd.unit。unit文件统一了过去各种不同的系统资源配置格式，通过文件的后缀名来区分这些配置文件。这些unit文件通常放在下面几个目录中。</p>\n<ul>\n<li>/usr/lib/systemd/system/：安装软件时主要使用的保存目录，重新安装软件会覆盖。有点类似以前的 /etc/init.d 底下的启动脚本；</li>\n<li>/run/systemd/system/：系统执行过程中产生的服务unit，这些脚本优先级比/usr/lib/systemd/system/目录高！</li>\n<li>/etc/systemd/system/：管理员根据系统需求所建立的执行脚本，其实这个目录有点类似/etc/rc.d/rc5.d/Sxx 功能，执行优先级比 /run/systemd/system/ 高！<br>也就是说，系统开机启动服务是看 /etc/systemd/system/ 底下的文件，该目录下面就是-大堆的连接文件，而实际执行的脚本大都放置在 /usr/lib/systemd/system/ 底下。</li>\n</ul>\n<p>unit文件按照systemd约定，应该被放置在指定的3个系统目录之一。我们实际用到大多数情况下都是service，一般都会在/etc/systemd/system目录下面创建自己的unit文件。</p>\n<h3 id=\"2-1-target的概念\"><a href=\"#2-1-target的概念\" class=\"headerlink\" title=\"2.1 target的概念\"></a>2.1 target的概念</h3><p>此类 unit 为其他 unit 进行逻辑分组。它们本身实际上并不做什么，只是引用其他 unit 而已。这样便可以对 unit 做一个统一的控制。(例如：bluetooth.target 只有在蓝牙适配器可用的情况下才调用与蓝牙相关的服务，如：bluetooth 守护进程、obex 守护进程等）；<br>在systemd的管理体系里面，以前的运行级别（runlevel）的概念被新的运行目标（target）所取代。每次系统启动的时候都会运行与当前系统相同级别target关联的所有服务，如果服务不需要跟随系统自动启动，则完全可以忽略这个Target的内容。通常来说我们大多数的Linux用户平时使用的都是“多用户模式”这个级别，对应的target值为“multi-user.target”。</p>\n<table>\n<thead>\n<tr>\n<th>Sysvinit 运行级别</th>\n<th>Systemd 目标</th>\n<th>注释</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>0</td>\n<td>runlevel0.target, poweroff.target</td>\n<td>关闭系统。</td>\n</tr>\n<tr>\n<td>1, s, single</td>\n<td>runlevel1.target, rescue.target</td>\n<td>单用户模式。</td>\n</tr>\n<tr>\n<td>2, 4</td>\n<td>runlevel2.target, runlevel4.target, multi-user.target</td>\n<td>用户定义/域特定运行级别。默认等同于 3。</td>\n</tr>\n<tr>\n<td>3</td>\n<td>runlevel3.target, multi-user.target</td>\n<td>多用户，非图形化。用户可以通过多个控制台或网络登录。</td>\n</tr>\n<tr>\n<td>5</td>\n<td>runlevel5.target, graphical.target</td>\n<td>多用户，图形化。通常为所有运行级别 3 的服务外加图形化登录。</td>\n</tr>\n<tr>\n<td>6</td>\n<td>runlevel6.target, reboot.target</td>\n<td>重启</td>\n</tr>\n<tr>\n<td>emergency</td>\n<td>emergency.target</td>\n<td>紧急 Shell</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"2-2-service-unit文件\"><a href=\"#2-2-service-unit文件\" class=\"headerlink\" title=\"2.2 service unit文件\"></a>2.2 service unit文件</h3><p>一个unit文件是长啥样子的呢，我们以最常用到的.service文件来说明，以sshd.service文件为例子：</p>\n<pre><code>[Unit]\nDescription=OpenBSD Secure Shell server\nAfter=network.target auditd.service\nConditionPathExists=!/etc/ssh/sshd_not_to_be_run\n\n[Service]\nEnvironmentFile=-/etc/default/ssh\nExecStart=/usr/sbin/sshd -D $SSHD_OPTS\nExecReload=/bin/kill -HUP $MAINPID\nKillMode=process\nRestart=on-failure\n\n[Install]\nWantedBy=multi-user.target\nAlias=sshd.service\n</code></pre><p>可以看到unit文件就是一堆的配置项，比起之前的脚本编写是不是简易很多。一般情况下配置文件有三个段:分别是Unit,Service,Install。</p>\n<ol>\n<li>Unit：一般写入该服务的基本信息，服务依赖关系；比如：description等等</li>\n<li>Service：一般写入该服务运行的命令，运行用户，运行优先级等；</li>\n<li>Install： 服务安装信息，它不在 systemd 的运行期间使用。只在使用 systemctl enable 和 systemctl disable 命令启用/禁用服务时有用。</li>\n</ol>\n<h4 id=\"2-2-1-Unit字段\"><a href=\"#2-2-1-Unit字段\" class=\"headerlink\" title=\"2.2.1 Unit字段\"></a>2.2.1 Unit字段</h4><p>Unit配置部分，主要包含以下字段：</p>\n<ul>\n<li><p>Description：一段描述这个 Unit 文件的文字。</p>\n</li>\n<li><p>Documentation：指定服务的文档，可以是一个或多个文档的URL路径。</p>\n</li>\n<li><p>Requires：依赖的其他 Unit 列表，列在其中的 Unit 模块会在这个服务启动的同时被启动，并且如果其中有任意一个服务启动失败，这个服务也会被终止。</p>\n</li>\n<li><p>Wants：与 Requires 相似，但只是在被配置的这个 Unit 启动时，触发启动列出的每个 Unit 模块，而不去考虑这些模块启动是否成功。</p>\n</li>\n<li><p>After：与 Requires 相似，但会在后面列出的所有模块全部启动完成以后，才会启动当前的服务。</p>\n</li>\n<li><p>Before：与 After 相反，在启动指定的任一个模块之前，都会首先确保当前服务已经运行。</p>\n</li>\n<li><p>BindsTo：与 Requires 相似，但是一种更强的关联。启动这个服务时会同时启动列出的所有模块，当有模块启动失败时终止当前服务。反之，只要列出的模块全部启动以后，也会自动启动当前服务。并且这些模块中有任意一个出现意外结束或重启，这个服务会跟着终止或重启。</p>\n</li>\n<li><p>PartOf：这是一个 BindTo 作用的子集，仅在列出的任何模块失败或重启时，终止或重启当前服务，而不会随列出模块的启动而启动。</p>\n</li>\n<li><p>OnFailure：当这个模块启动失败时，就自动启动列出的每个模块。</p>\n</li>\n<li><p>Conflicts：与这个模块有冲突的模块，如果列出模块中有已经在运行的，这个服务就不能启动，反之亦然。</p>\n</li>\n</ul>\n<p>上面这些配置中，除了 Description 外，都能够被添加多次。比如前面第一个例子中的After参数在一行中使用空格分隔指定所有值，也可以像第二个例子中那样使用多个After参数，在每行参数中指定一个值。</p>\n<h4 id=\"2-2-2-Service字段\"><a href=\"#2-2-2-Service字段\" class=\"headerlink\" title=\"2.2.2 Service字段\"></a>2.2.2 Service字段</h4><p>这个部分的配置是最重要的，描述整个服务的核心。常用的配置项有：</p>\n<ul>\n<li><p>Type：服务的类型，常用的有 simple（默认类型） 和 forking。默认的 simple 类型可以适应于绝大多数的场景，因此一般可以忽略这个参数的配置。而如果服务程序启动后会通过 fork 系统调用创建子进程，然后关闭应用程序本身进程的情况，则应该将 Type 的值设置为 forking，否则 systemd 将不会跟踪子进程的行为，而认为服务已经退出。</p>\n</li>\n<li><p>RemainAfterExit：值为 true 或 false（也可以写 yes 或 no），默认为 false。当配置值为 true 时，systemd 只会负责启动服务进程，之后即便服务进程退出了，systemd 仍然会认为这个服务是在运行中的。这个配置主要是提供给一些并非常驻内存，而是启动注册后立即退出然后等待消息按需启动的特殊类型服务使用</p>\n</li>\n<li><p>ExecStart：这个参数是几乎每个 .service 文件都会有的，指定服务启动的主要命令，在每个配置文件中只能使用一次。</p>\n</li>\n<li><p>ExecStartPre：指定在启动执行 ExecStart 的命令前的准备工作，可以有多个，所有命令会按照文件中书写的顺序依次被执行。</p>\n</li>\n<li><p>ExecStartPost：指定在启动执行 ExecStart 的命令后的收尾工作，也可以有多个。</p>\n</li>\n<li><p>TimeoutStartSec：启动服务时的等待的秒数，如果超过这个时间服务任然没有执行完所有的启动命令，则 systemd 会认为服务自动失败。这一配置对于使用 Docker 容器托管的应用十分重要，由于 Docker 第一次运行时可以能会需要从网络下载服务的镜像文件，因此造成比较严重的延时，容易被 systemd 误判为启动失败而杀死。通常对于这种服务，需要将 TimeoutStartSec 的值指定为 0，从而关闭超时检测，如前面的第二个例子。</p>\n</li>\n<li><p>ExecStop：停止服务所需要执行的主要命令。</p>\n</li>\n<li><p>ExecStopPost：指定在 ExecStop 命令执行后的收尾工作，也可以有多个。</p>\n</li>\n<li><p>TimeoutStopSec：停止服务时的等待的秒数，如果超过这个时间服务仍然没有停止，systemd 会使用 SIGKILL 信号强行杀死服务的进程。</p>\n</li>\n<li><p>Restart：这个值用于指定在什么情况下需要重启服务进程。常用的值有 no，on-success，on-failure，on-abnormal，on-abort 和 always。默认值为 no，即不会自动重启服务。这些不同的值分别表示了在哪些情况下，服务会被重新启动，参见下表。</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>服务退出原因</th>\n<th>no</th>\n<th>always</th>\n<th>on-failure</th>\n<th>on-abnormal</th>\n<th>on-abort</th>\n<th>on-success</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>正常退出</td>\n<td></td>\n<td>√</td>\n<td></td>\n<td></td>\n<td></td>\n<td>√</td>\n</tr>\n<tr>\n<td>异常退出</td>\n<td></td>\n<td>√</td>\n<td>√</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>启动/停止超时</td>\n<td></td>\n<td>√</td>\n<td>√</td>\n<td>√</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>被异常KILL</td>\n<td></td>\n<td>√</td>\n<td>√</td>\n<td>√</td>\n<td>√</td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<ul>\n<li><p>RestartSec：如果服务需要被重启，这个参数的值为服务被重启前的等待秒数。</p>\n</li>\n<li><p>ExecReload：重新加载服务所需执行的主要命令。</p>\n</li>\n</ul>\n<h4 id=\"2-2-3-Install字段\"><a href=\"#2-2-3-Install字段\" class=\"headerlink\" title=\"2.2.3 Install字段\"></a>2.2.3 Install字段</h4><p>这个段中的配置与 Unit 有几分相似，但是这部分配置需要通过 systemctl enable 命令来激活，并且可以通过 systemctl disable 命令禁用。另外这部分配置的目标模块通常是指定启动级别的.target文件，用来使得服务在系统启动时自动运行。</p>\n<ul>\n<li><p>WantedBy：和前面的 Wants 作用相似，被哪些模块需要到，这样做的效果是当列表中的服务启动，本服务也会启动；</p>\n</li>\n<li><p>RequiredBy：和前面的 Requires 作用相似，同样后面列出的不是服务所依赖的模块，而是依赖当前服务的模块。</p>\n</li>\n<li><p>Also：当这个服务被 enable/disable 时，将自动 enable/disable 后面列出的每个模块。</p>\n</li>\n<li><p>Alias： 可以指定一个服务的别名，这样 systemctl command xxx.service 的时候就可以不输入完整的单元名称。</p>\n</li>\n</ul>\n<p>上面的sshd.service例子中使用的都是 “WantedBy=multi-user.target” 表明当系统以多用户方式（默认的运行级别）启动时，这个服务需要被自动运行。当然还需要 systemctl enable 激活这个服务以后自动运行才会生效。</p>\n<h3 id=\"2-3-systemd主要命令\"><a href=\"#2-3-systemd主要命令\" class=\"headerlink\" title=\"2.3 systemd主要命令\"></a>2.3 systemd主要命令</h3><p>检视和控制systemd的主要命令是systemctl。该命令可用于查看系统状态和管理系统及服务。</p>\n<pre><code>systemctl list-units 列出激活的单元\nsystemctl list-unit-files 查看所有已安装服务\nsystemctl --failed 输出运行失败的单元\n</code></pre><p>启动、结束、强制终止、重新启动和运行状态，分别对应以下几个命令。</p>\n<pre><code>systemctl start &lt;Unit名称&gt;\nsystemctl stop &lt;Unit名称&gt;\nsystemctl kill &lt;Unit名称&gt;\nsystemctl restart &lt;Unit名称&gt;\nsystemctl status &lt;Unit名称&gt;\n</code></pre><p>服务的开机自动启动的启用和取消，分别对应下面两个。</p>\n<pre><code>systemctl enable &lt;Unit名称&gt;\nsystemctl disable &lt;Unit名称&gt;\n</code></pre><p>检查单元是否配置为自动启动：</p>\n<pre><code>systemctl is-enabled &lt;Unit名称&gt;\n</code></pre><h2 id=\"3-systemd如何兼容sysv-init\"><a href=\"#3-systemd如何兼容sysv-init\" class=\"headerlink\" title=\"3 systemd如何兼容sysv init\"></a>3 systemd如何兼容sysv init</h2><p>之前的启动系统通过/etc/init.d目录下面的脚本管理服务，在debian8上是如何把这些script接管过来的呢？<br>比如我们通过执行/etc/monit/monit启动monit服务：</p>\n<pre><code># /etc/init.d/monit stop\n[ ok ] Starting monit (via systemctl): monit.service.\n</code></pre><p>服务成功启动，而且提示是通过systemctl来启动的（via systemclt）， /etc/init.d/monit status得到下面内容：</p>\n<pre><code>#  /etc/init.d/monit status\n● monit.service - LSB: service and resource monitoring daemon\n   Loaded: loaded (/etc/init.d/monit)\n   Active: active (running) since Sun 2016-01-10 06:02:22 PST; 4s ago\n</code></pre><p>上面提示Loaded: loaded (/etc/init.d/monit)，说明我们使用的是/etc/init.d的脚本。</p>\n<p>而我们并没有创建monit.service文件，通过执行<code>systemctl start monit.service</code>和<code>systemctl status monit.service</code>也是得到同样的结果。</p>\n<p>我们来研究下这一神奇的过程。</p>\n<p>我们看到monit脚本中有这么一个语句：</p>\n<pre><code>. /lib/lsb/init-functions\n</code></pre><p>这一行会调用<code>/lib/lsb/init-functions.d/40-systemd</code>脚本，接下来脚本的执行都是由systemd来操作。<br>所以，执行<code>/etc/init.d/monit start</code>实际上就是执行<code>sysctemctl start monit.service</code><br>但是monit.server文件并不存在，该怎么办呢？</p>\n<p>当一个需要启动一个service时，如果找不到unit配置文件，systemd会查找一个同名的sysV init脚本，然后动态的创建一个service unit的文件。创建的依据就是该启动脚本，systemd解析标准的LSB脚本头部注释，然后组装一个unit，最后通过systemctl运行。</p>\n<p>LSB脚本标准头部注释是被systemd的解析的，以monit的脚本来说明下：</p>\n<pre><code>#!/bin/sh\n\n### BEGIN INIT INFO\n# Provides:          monit\n# Required-Start:    $remote_fs\n# Required-Stop:     $remote_fs\n# Should-Start:      $all\n# Should-Stop:       $all\n# Default-Start:     2 3 4 5\n# Default-Stop:      0 1 6\n# Short-Description: service and resource monitoring daemon\n# Description:       monit is a utility for managing and monitoring\n#                    processes, programs, files, directories and filesystems\n#                    on a Unix system. Monit conducts automatic maintenance\n#                    and repair and can execute meaningful causal actions\n#                    in error situations.\n### END INIT INFO\n</code></pre><p>其脚本描述信息用### BEGIN INIT INFO 和 ### INIT INFO来分隔，systemd完全解析这里面的信息，Required-Start关键字来申明在运行该脚本之前应该需要先运行哪些脚本；<br>类似的Required-Stop里定义的启动服务应该在先停止哪些脚本；<br>Should-Start关键字和Should-Stop关键字的概念和Required-Start及Required-Stop类似,只是对其后面定义的行为是希望而不是必须；<br>Default-Start和Default-Stop 定义了缺省情况下该脚本在哪些运行级别下启动和停止。</p>\n<p>systemd启动monit时调用<code>/lib/systemd/system-generators/systemd-sysv-generator</code>，解析init脚本，并动态组装一个monit.service文件，放置在<code>/run/systemd/generator.late/</code>目录下面。</p>\n<p>在<code>/run/systemd/generator.late</code>目录下，我们找到生成的monit.service文件，内容如下：</p>\n<pre><code># Automatically generated by systemd-sysv-generator\n\n[Unit]\nSourcePath=/etc/init.d/monit\nDescription=LSB: service and resource monitoring daemon\nBefore=runlevel2.target runlevel3.target runlevel4.target runlevel5.target shutdown.target\nAfter=remote-fs.target all.target\nConflicts=shutdown.target\n\n[Service]\nType=forking\nRestart=no\nTimeoutSec=5min\nIgnoreSIGPIPE=no\nKillMode=process\nGuessMainPID=no\nRemainAfterExit=yes\nSysVStartPriority=4\nExecStart=/etc/init.d/monit start\nExecStop=/etc/init.d/monit stop\nExecReload=/etc/init.d/monit reload\n</code></pre><p>这个文件第一行就告诉我们是由systemd-sysv-generator自动生成的。</p>\n<p>如果不想monit脚本定向到systemd，可以通过设置环境变量</p>\n<pre><code>export _SYSTEMCTL_SKIP_REDIRECT=1\n</code></pre><p>这样如果运行/etc/init.d/monit start, 就脱离systemd的管理了。</p>\n<p>systemd也不是100%与sysv兼容的，比如systemctl只提供有限的操作，也不提供参数支持，而init脚本可以多样性定制；systemctl也不支持交互式启动服务等，更多不兼容可以查看<a href=\"http://www.freedesktop.org/wiki/Software/systemd/Incompatibilities/\" target=\"_blank\" rel=\"external\">Compatibility with SysV</a>。</p>\n<h2 id=\"4编写一个service文件\"><a href=\"#4编写一个service文件\" class=\"headerlink\" title=\"4编写一个service文件\"></a>4编写一个service文件</h2><p>有了前面的了解，写一个unit服务文件，小菜一碟啦。<br>以写nginx.service为例子，并加入到开机启动流程中。<br>第一步在/etc/systemd/system目录下面，新建一个nginx.service文件。</p>\n<h3 id=\"4-1-配置Unit字段\"><a href=\"#4-1-配置Unit字段\" class=\"headerlink\" title=\"4.1 配置Unit字段\"></a>4.1 配置Unit字段</h3><pre><code>[Unit]\nDescription=The NGINX HTTP and reverse proxy server\nAfter=network.target remote-fs.target nss-lookup.target\n</code></pre><p>这里我们只需配置两项，Description和After，After表示nginx需要在网络相关服务、远程文件系统挂载点服务、主机和网络名字查找服务这些服务启动后，本服务才执行启动；</p>\n<h3 id=\"4-2-编写Service字段配置\"><a href=\"#4-2-编写Service字段配置\" class=\"headerlink\" title=\"4.2 编写Service字段配置\"></a>4.2 编写Service字段配置</h3><pre><code>[Service]\nType=forking\nPIDFile=/run/nginx.pid\nExecStartPre=/usr/sbin/nginx -t\nExecStart=/usr/sbin/nginx\nExecReload=/bin/kill -s HUP $MAINPID\nExecStop=/bin/kill -s QUIT $MAINPID\nRestart=on-failure\nUser=nginx\nGroup=nginx\n</code></pre><p>设置Type=forking，是因为nginx是父进程调用fork()创建子进程，然后父进程退出，子进程继续服务的形式；<br>同时设置 PIDFile= 选项，以帮助 systemd 准确定位该服务的主进程，进而加快后继单元的启动速度。<br>ExecStartPre：配置在启动进程前运行<code>/usr/sbin/nginx -t</code>来检查下配置语法是否正确；<br>ExecStart：启动nginx命令；<br>ExecReload：reload命令，这里是用发送信号的方式，也可以是<code>/usr/sbin/nginx -s reload</code>命令；<br>ExecStop：停止命令，这里也是处理信号的方式，同样可用<code>/usr/sbin/nginx -s stop</code>命令；<br>Restart：on-failure表示在异常退出时重启服务；<br>User、Group：指定运行服务用户和用户组；</p>\n<h3 id=\"4-3-配置Install字段\"><a href=\"#4-3-配置Install字段\" class=\"headerlink\" title=\"4.3 配置Install字段\"></a>4.3 配置Install字段</h3><p>这部分是安装的相关信息，运行systemctl enable时用到。</p>\n<pre><code>[Install]\nWantedBy=multi-user.target\n</code></pre><p>上面的配置表示nginx服务安装在多用户模式下，当系统运行在多用户模式时，nginx服务启动。</p>\n<p>###4.4 加载服务<br>当我们增加或者修改一个unit文件时，需要重新加载告知systemd。</p>\n<pre><code>systemctl daemon-reload\n</code></pre><p>执行这步后就可以用systemctl操作服务了。</p>\n<pre><code>systemctl start nginx.service   ##启动服务\nsystemctl status nginx.service  ##查看服务状态\njournal -b -u nginx.service     ##查看当次启动服务日志\n</code></pre><p>使用<code>systemctl enable nginx.service</code>命令实现开机启动。</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>systemd是一个先进的init系统，统一了系统各资源启动管理，有一种兼容并包，大统一体，化繁为简的哲学思想，值得大家用起来。</p>\n<h2 id=\"参考文献：\"><a href=\"#参考文献：\" class=\"headerlink\" title=\"参考文献：\"></a>参考文献：</h2><p><a href=\"http://www.nljb.net/default/Linux%E5%B7%A8%E5%A4%A7%E5%8F%98%E9%9D%A9%E4%B9%8BSystemd%E5%8F%96%E4%BB%A3SysV%E7%9A%84Init/\" target=\"_blank\" rel=\"external\">http://www.nljb.net/default/Linux%E5%B7%A8%E5%A4%A7%E5%8F%98%E9%9D%A9%E4%B9%8BSystemd%E5%8F%96%E4%BB%A3SysV%E7%9A%84Init/</a><br><a href=\"http://www.ibm.com/developerworks/cn/linux/1407_liuming_init3/\" target=\"_blank\" rel=\"external\">http://www.ibm.com/developerworks/cn/linux/1407_liuming_init3/</a><br><a href=\"http://www.freedesktop.org/wiki/Software/systemd/Incompatibilities/\" target=\"_blank\" rel=\"external\">http://www.freedesktop.org/wiki/Software/systemd/Incompatibilities/</a><br><a href=\"http://blog.csdn.net/institute/article/details/20152317\" target=\"_blank\" rel=\"external\">http://blog.csdn.net/institute/article/details/20152317</a></p>\n","categories":["未分类"],"tags":["技术"]},{"title":"Storm学习","url":"http://fengjianque.github.io/2017/02/07/storm-learn/","content":"<h1 id=\"Storm学习\"><a href=\"#Storm学习\" class=\"headerlink\" title=\"Storm学习\"></a>Storm学习</h1><h2 id=\"背景\"><a href=\"#背景\" class=\"headerlink\" title=\"背景\"></a>背景</h2><p>在处理海量数据时，Hadoop是标配的技术框架，Hadoop以批处理的方式处理<strong>离线的数据</strong>，将数据切片计算，使用磁盘作为中间交换的介质。Hadoop不是一个实时计算的框架，不能计算源源不断实时输入的海量数据，并实时给出计算结果。所以在Hadoop之后出现S4，Storm，Spark，Puma等这些实时计算系统，弥补了这个缺陷。这些实时系统框架各有特点，本文介绍近来最流行的Storm框架。</p>\n<p>Storm是一个免费开源、分布式、高容错的实时计算系统。Storm令持续不断的流计算变得容易，弥补了Hadoop批处理所不能满足的实时要求。Storm常见的使用场景：</p>\n<ul>\n<li>流数据处理：Storm可以用来处理源源不断流进来的消息，对这些数据进行实时分析、持续计算，处理之后将结果写入到某个存储中去（Storm不负责存储）。</li>\n<li>分布式rpc：由于Storm的处理组件是分布式的，而且处理延迟极低，所以可以作为一个通用的分布式rpc框架实现实时业务查询。</li>\n</ul>\n<p>比如你需要从日志数据中统计一个论坛过去5分钟讨论最热的帖子，Hadoop计算只能从已经保存在数据库里面日志里面统计，跑个job任务计算结果；如果是Storm，只需把实时的日志流输入到Storm框架中，就能获取统计结果。<br>你也许有疑问，<code>消息队列+worker</code>形式不就可以达到同样的要求么？事实上有很多时候实时统计都是采用这种简便的方式来实现的。但你会发现，如果实时统计需求比较多，处理比较复杂的场景下，系统需要维护一堆消息队列和消费者worker，这构成了非常复杂的系统结构。消费者worker从队列里取消息，处理完成后，去更新数据库，或者给其他队列发新消息。<br>这样进行实时处理是非常痛苦的。我们主要的精力都花在关注往哪里发消息，从哪里接收消息，消息如何序列化，真正的业务逻辑只占了一小部分。一个应用程序的逻辑运行在很多worker上，但这些worker需要各自单独部署，还需要部署消息队列。最大问题是系统很脆弱，而且不是容错的：需要自己保证消息队列和worker进程工作正常。<br>Storm完整地解决了这些问题。它是为分布式场景而生的，抽象了消息传递，会自动地在集群机器上并发地处理流式计算，让你专注于实时处理的业务逻辑。</p>\n<h2 id=\"Storm集群框架\"><a href=\"#Storm集群框架\" class=\"headerlink\" title=\"Storm集群框架\"></a>Storm集群框架</h2><p>Storm和Hadoop的MapReduce一样，有很好的水平扩展能力，伸缩性很强。它可以像Hadoop那样被部署在多台机器上，实现集群架构。下面是Storm集群的部件图：</p>\n<p><img src=\"http://iamsummer-wordpress.stor.sinaapp.com/uploads/2015/09/Snip20150913_2.png\" alt=\"\"></p>\n<p>Storm和Hadoop有很多的相像之处，下面是他们之间的角色对应：</p>\n<table>\n<thead>\n<tr>\n<th>对应关系</th>\n<th>Hadoop</th>\n<th>Storm</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>系统角色</td>\n<td>JobTracker</td>\n<td>Nimbus</td>\n</tr>\n<tr>\n<td>系统角色</td>\n<td>TaskTracker</td>\n<td>Supervisor</td>\n</tr>\n<tr>\n<td>系统角色</td>\n<td>Child</td>\n<td>Worker</td>\n</tr>\n<tr>\n<td>应用名称</td>\n<td>Job</td>\n<td>Topology</td>\n</tr>\n<tr>\n<td>组件接口</td>\n<td>Mapper/Reducer</td>\n<td>Spout/Bolt</td>\n</tr>\n</tbody>\n</table>\n<p>在Storm的集群里面有两种节点：控制节点和工作节点；Zookeeper起协调作用，下面是集群中角色的描述：</p>\n<ul>\n<li>Nimbus： 控制节点上面运行一个叫Nimbus进程，Nimbus负责在集群里面分发代码，分配计算任务，并且监控状态。 全局只有一个。</li>\n<li>Supervisor： 每一个工作节点上面运行一个叫做Supervisor进程。Supervisor负责监听从Nimbus分配给它执行的任务，据此启动或停止执行任务的工作进程Worker;</li>\n<li>Zookeeper： Nimbus和Supervisor之间的所有协调工作都是通过Zookeeper集群完成。</li>\n<li>Topology：在Hadoop上面你运行的是MapReduce的Job, 而在Storm上面你运行的是Topology。</li>\n<li>Spout/Bolt: Topology的主要构成，是数据输入，处理的部件。</li>\n</ul>\n<p>Nimbus 后台程序和 Supervisor 后台程序都是快速失败(fail-fast)和无状态的，所有状态保存在Zookeeper 或本地磁盘中。<br>在这种设计中,控制节点并没有直接和工作节点通信,而是借助中介 Zookeeper, 这样一来可以分离<strong>控制节点</strong>和<strong>工作节点</strong>的依赖，将状态信息存放在Zookeeper集群内以快速恢复任何失败的一方。<br>这意味着你可以 kill 杀掉 Nimbus 进程和 Supervisor 进程，然后重启，它们将恢复状态并继续工作，这种设计使得Storm极其稳定。</p>\n<h2 id=\"Topology\"><a href=\"#Topology\" class=\"headerlink\" title=\"Topology\"></a>Topology</h2><p>本章主要介绍Storm中任务的设计思想，各组成部件。<br><img src=\"http://iamsummer-wordpress.stor.sinaapp.com/uploads/2015/09/Snip20150913_9.png\" alt=\"\"></p>\n<h3 id=\"Tuple\"><a href=\"#Tuple\" class=\"headerlink\" title=\"Tuple\"></a>Tuple</h3><p>Tuple是Storm提供的一个轻量级的数据格式，可以用来包装你需要实际处理的数据。Tuple是一次消息传递的基本单元。一个Tuple是一个命名的值列表，其中的每个值都可以是任意类型的。Tuple本来应该是一个Key-Value的Map，由于各个组件间传递的tuple的字段名称已经事先定义好了，所以Tuple只需要按序填入各个Value，所以就是一个Value List。<br>一个没有边界的、源源不断的、连续的Tuple序列就组成了Stream。</p>\n<h3 id=\"Spout\"><a href=\"#Spout\" class=\"headerlink\" title=\"Spout\"></a>Spout</h3><p>Storm为每个Stream都有一个源头，Spout会从外部读取流数据并发出Tuple。比如Spout可以从消息队列或者数据库中读取消息。Spout可以一次给多个Stream发出数据。</p>\n<h3 id=\"Bolt\"><a href=\"#Bolt\" class=\"headerlink\" title=\"Bolt\"></a>Bolt</h3><p>Storm 将流的中间状态转换抽象为Bolt，Bolt可以处理Tuple，同时它也可以发送新的流给其他Bolt使用。一个Bolt可以处理任意数量的输入流，产生任意数量新的输出流。Bolt可以做函数处理，过滤，流的合并，聚合，存储到数据库等操作。Bolt就是流水线上的一个处理单元，把数据的计算处理过程合理的拆分到多个Bolt、合理设置Bolt的task数量，能够提高Bolt的处理能力，提升流水线的并发度。</p>\n<h3 id=\"Stream-Grouping\"><a href=\"#Stream-Grouping\" class=\"headerlink\" title=\"Stream Grouping\"></a>Stream Grouping</h3><p>消息分发策略，即定义一个Stream应该如何分配给Bolt。目前有下面几种分发策略：</p>\n<ul>\n<li>洗牌分组(Shuffle grouping): 随机分配元组到Bolt的某个任务上，这样保证同一个Bolt的每个任务都能够得到相同数量的元组。</li>\n<li>字段分组(Fields grouping): 按照指定的分组字段来进行流的分组。例如，流是用字段“user-id”来分组的，那有着相同“user-id”的元组就会分到同一个任务里，但是有不同“user-id”的元组就会分到不同的任务里。</li>\n<li>Partial Key grouping: 跟字段分组一样，流也是用指定的分组字段进行分组的，但是在多个下游Bolt之间是有负载均衡的，这样当输入数据有倾斜时可以更好的利用资源。</li>\n<li>All grouping: 流会复制给Bolt的所有任务。小心使用这种分组方式。</li>\n<li>Global grouping: 整个流会分配给Bolt的一个任务。具体一点，会分配给有最小ID的任务。</li>\n<li>不分组(None grouping): 说明不关心流是如何分组的。目前，None grouping等价于洗牌分组。</li>\n<li>Direct grouping：直接分组,由Tuple的生产者来定义接收者。</li>\n<li>Local or shuffle grouping：如果目标Bolt在同一个worker进程里有一个或多个任务，元组就会通过洗牌的方式分配到这些同一个进程内的任务里。否则，就跟普通的洗牌分组一样。</li>\n</ul>\n<p>通过这些消息分发策略，Storm 解决了组件Spout和Bolt， Bolt和Bolt之间如何发送Tuple的问题。</p>\n<h3 id=\"Topology-1\"><a href=\"#Topology-1\" class=\"headerlink\" title=\"Topology\"></a>Topology</h3><p>Topology是Storm中最高层次的抽象概念，一个拓扑就是一个流转换图。一个拓扑是一个通过流分组(stream grouping)把Spout和Bolt连接到一起的拓扑结构。图的每条边代表一个Bolt订阅了其他Spout或者Bolt的输出流。一个拓扑就是一个复杂的多阶段的流计算。<br>一个Storm拓扑跟一个MapReduce的任务(job)概念是类似的。主要区别是：一个MapReduce Job最终会结束， 而一个Topology运永远运行（除非你显式的kill）。</p>\n<h2 id=\"Storm并发模型\"><a href=\"#Storm并发模型\" class=\"headerlink\" title=\"Storm并发模型\"></a>Storm并发模型</h2><p>上面介绍了控制节点Nimbus、工作节点Supervisor，工作进程Worker。一个Topology由Nimbus分发到Supervisor，Supervisor<strong>根据这个Topology里面的配置开启数量的Worker进程</strong>，这些Worker进程专门跑这个Topology。Topology里面有部件Spout，Bolt，这些部件可以配置<br>Executor和Task数量。Executor对应线程，Task对应部件的实例数量。 <strong>Executor的数量平均到每个Worker上，Task的数量平均分到Executor上</strong>。 下面图说明Worker、Executor、Task之间的关系。<br><img src=\"http://iamsummer-wordpress.stor.sinaapp.com/uploads/2015/09/Snip20150914_15.png\" alt=\"\"></p>\n<p>下面用一个例子说明。</p>\n<pre><code>Config conf = new Config();\nconf.setNumWorkers(2); // use two worker processes\n\ntopologyBuilder.setSpout(&quot;blue-spout&quot;, new BlueSpout(), 2); // set parallelism hint to 2\n\ntopologyBuilder.setBolt(&quot;green-bolt&quot;, new GreenBolt(), 2)  // set parallelism hint to 2\n               .setNumTasks(4)\n               .shuffleGrouping(&quot;blue-spout&quot;);\n\ntopologyBuilder.setBolt(&quot;yellow-bolt&quot;, new YellowBolt(), 6)\n               .shuffleGrouping(&quot;green-bolt&quot;);\n\nStormSubmitter.submitTopology(\n        &quot;mytopology&quot;,\n        conf,\n        topologyBuilder.createTopology()\n    );\n</code></pre><p>上面代码配置后，得到的拓扑图如下：</p>\n<p><img src=\"http://iamsummer-wordpress.stor.sinaapp.com/uploads/2015/09/Snip20150913_13.png\" alt=\"\"></p>\n<p>上面例子中，整个拓扑配置2个Worker进程，那么各个部件并发情况如下：</p>\n<ul>\n<li>Blue Spout：配置parallelism为2，Task数量默认跟parallelism一致，所以2个Task分配到2个Executor，2个Executor分配到2各Worker上。那就是一个Worker运行一个Executor；</li>\n<li>Green Bolt： 设置parallelism为2，Task为4，那么一个Worker运行一个Executor，一个Executor运行2个Task(Bolt的实例)；</li>\n<li>Yellow Bolt：设置parallelism为6，那么一个Worker运行3个Executor，每个Executor运行一个Task。</li>\n</ul>\n<p>每个Worker会运行5个Task。</p>\n<p>Storm一个灵巧的功能是可以增减worker进程或者executor的数量而不需要重启集群或者拓扑。这种做法叫做rebalancing。有两种方法可以用来做拓扑的rebalance:</p>\n<ul>\n<li>使用Storm web UI来做</li>\n<li>使用命令行工具storm rebalance</li>\n</ul>\n<h3 id=\"Storm单机模式搭建\"><a href=\"#Storm单机模式搭建\" class=\"headerlink\" title=\"Storm单机模式搭建\"></a>Storm单机模式搭建</h3><p>Storm可以运行在单机上，作为集群模式的一个特例。Storm集群搭建主要包括以下步骤：</p>\n<p>1、搭建一个Zookeeper集群</p>\n<p>2、在nimbus、supervisor节点安装依赖包</p>\n<p>3、在nimbus、supervisor节点下载并解压缩Storm包</p>\n<p>4、修改nimbus、supervisor节点的配置文件（storm.yaml）</p>\n<p>5、使用storm脚本启动守护进程（包括nimbus、supervisor、ui）</p>\n<h5 id=\"搭建Zookeeper集群\"><a href=\"#搭建Zookeeper集群\" class=\"headerlink\" title=\"搭建Zookeeper集群\"></a>搭建Zookeeper集群</h5><p>从<a href=\"https://zookeeper.apache.org/releases.html#download\" target=\"_blank\" rel=\"external\">Zookeeper官网</a>下载最新版Zookeeper。本文用的是3.4.6版本，zookeeper单机模式非常简单。</p>\n<pre><code>tar zxvf zookeeper-3.4.6.tar.gz\ncd zookeeper-3.4.6\nmv conf/zoo_sample.cfg conf/zoo.cfg\nbin/kServer.sh start\n</code></pre><p>这样就启动了Zookeeper服务。</p>\n<h4 id=\"安装依赖包\"><a href=\"#安装依赖包\" class=\"headerlink\" title=\"安装依赖包\"></a>安装依赖包</h4><p>本文安装的Storm版本是0.10.0，从0.9版本开始，Storm就支持用netty作为传输信息，默认是zeromq，需要在配置中说明。所以本文不用安装ZeroMQ、JZMQ依赖包。只需要安装java，并且要保证版本大于1.7。否则在启动Storm相关服务，会报错：<code>Unsupported major.minor version 51.0</code>，这表示你java的版本过低。<br>在linux中，可以用apt快捷安装。</p>\n<pre><code>sudo apt-get install openjdk-7-jre\n</code></pre><h4 id=\"下载并解压缩Storm包\"><a href=\"#下载并解压缩Storm包\" class=\"headerlink\" title=\"下载并解压缩Storm包\"></a>下载并解压缩Storm包</h4><p>从官网下载稳定发行版，本文为0.10.0.</p>\n<h4 id=\"修改storm-yaml配置\"><a href=\"#修改storm-yaml配置\" class=\"headerlink\" title=\"修改storm.yaml配置\"></a>修改storm.yaml配置</h4><p>本文修改的配置如下：</p>\n<pre><code>#配置zookeeper\nstorm.zookeeper.servers:\n    - 127.0.0.1\nstorm.zookeeper.port: 2181\n\nnimbus.host: &quot;127.0.0.1&quot;\nstorm.local.dir: &quot;/tmp/storm&quot;\nsupervisor.slots.ports:\n   - 6700\n   - 6701\n   - 6702\n   - 6703\n\n#配置ui访问端口\nui.port: 8080\n\n#配置netty相关\nstorm.messaging.transport: &quot;backtype.storm.messaging.netty.Context&quot;\nstorm.messaging.netty.server_worker_threads: 1\nstorm.messaging.netty.client_worker_threads: 1\nstorm.messaging.netty.buffer_size: 5242880\nstorm.messaging.netty.max_retries: 100\nstorm.messaging.netty.max_wait_ms: 1000\nstorm.messaging.netty.min_wait_ms: 100\n</code></pre><h4 id=\"启动storm\"><a href=\"#启动storm\" class=\"headerlink\" title=\"启动storm\"></a>启动storm</h4><p>进入storm的目录，启动下面的进程。</p>\n<pre><code>bin/storm nimbus\nbin/storm supervisor\nbin/storm ui\n</code></pre><p>通过ui查看storm运行状态，在浏览器中输入<a href=\"http://localhost:8080，可以在界面上观察。\" target=\"_blank\" rel=\"external\">http://localhost:8080，可以在界面上观察。</a></p>\n<h3 id=\"WordCount实例\"><a href=\"#WordCount实例\" class=\"headerlink\" title=\"WordCount实例\"></a>WordCount实例</h3><p>现在跑一下官方的例子，学习怎么提交Topology。</p>\n<p>####安装maven<br>我们需要用maven进行编译打包，安装maven。</p>\n<pre><code>sudo apt-get install maven\n</code></pre><h4 id=\"打包Topology例子\"><a href=\"#打包Topology例子\" class=\"headerlink\" title=\"打包Topology例子\"></a>打包Topology例子</h4><pre><code>git clone git://github.com/apache/storm.git &amp;&amp; cd storm/examples/storm-starter\nmvn package\n</code></pre><p> 这里面我用的是master分支，里面的storm-core版本，在maven的仓库上还没有最新的库，有可能报错：</p>\n<pre><code> [ERROR] Failed to execute goal on project storm-starter: Could not resolve depen\ndencies for project org.apache.storm:storm-starter:jar:0.10.0-SNAPSHOT: Could no\nt find artifact org.apache.storm:storm-core:jar:0.10.0-SNAPSHOT in clojars (http\ns://clojars.org/repo/) -&gt; [Help 1]\n</code></pre><p>checkout 到0.9.3版本的标签即可解决问题。</p>\n<h4 id=\"提交Topology到Storm\"><a href=\"#提交Topology到Storm\" class=\"headerlink\" title=\"提交Topology到Storm\"></a>提交Topology到Storm</h4><p>在控制节点nimbus上执行</p>\n<p>bin/storm jartorm-starter-0.9.3-jar-with-dependencies.jar storm.starter.WordCountTopology test</p>\n<p>可以看到console的输出，也可以到ui上看，在Topology栏里面点击test进去查看提交的Topology信息。</p>\n<p><img src=\"http://iamsummer-wordpress.stor.sinaapp.com/uploads/2015/09/Snip20150913_14.png\" alt=\"\"></p>\n<p>这个例子是Spout不断的发射英文句子到Bolt，Bolt分解句子，将单词发射到下一个Bolt中处理，最后一个Bolt统计各单词的次数，保存在map里面。</p>\n<h3 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h3><p><a href=\"https://storm.apache.org/documentation/Tutorial.html\" target=\"_blank\" rel=\"external\">https://storm.apache.org/documentation/Tutorial.html</a><br><a href=\"http://cloud.berkeley.edu/data/storm-berkeley.pdf\" target=\"_blank\" rel=\"external\">http://cloud.berkeley.edu/data/storm-berkeley.pdf</a><br><a href=\"http://www.searchtb.com/2012/09/introduction-to-storm.html\" target=\"_blank\" rel=\"external\">http://www.searchtb.com/2012/09/introduction-to-storm.html</a><br><a href=\"http://blog.jobbole.com/48595/\" target=\"_blank\" rel=\"external\">http://blog.jobbole.com/48595/</a><br><a href=\"https://xumingming.sinaapp.com/category/storm/\" target=\"_blank\" rel=\"external\">https://xumingming.sinaapp.com/category/storm/</a><br><a href=\"http://www.michael-noll.com/blog/2012/10/16/understanding-the-parallelism-of-a-storm-topology/\" target=\"_blank\" rel=\"external\">http://www.michael-noll.com/blog/2012/10/16/understanding-the-parallelism-of-a-storm-topology/</a><br><a href=\"http://blog.csdn.net/tntzbzc/article/details/19974515\" target=\"_blank\" rel=\"external\">http://blog.csdn.net/tntzbzc/article/details/19974515</a></p>\n","categories":["未分类"],"tags":["技术"]},{"title":"Kafka消息中间件介绍","url":"http://fengjianque.github.io/2017/02/07/kafka/","content":"<h1 id=\"Kafka消息中间件介绍\"><a href=\"#Kafka消息中间件介绍\" class=\"headerlink\" title=\"Kafka消息中间件介绍\"></a>Kafka消息中间件介绍</h1><p>Kafka是由LinkedIn开发的，分区的、多副本的、多订阅者，基于zookeeper协调的分布式日志系统，作为消息的中间件，它以<code>水平拓展</code>、<code>高可用性</code>和<code>高吞吐量</code>著称，在同类的消息中间件中独树一帜。目前越来越多的开源分布式处理系统如ClouderaApache Storm、Spark都支持与Kafka集成。</p>\n<h4 id=\"Kafka设计特点：\"><a href=\"#Kafka设计特点：\" class=\"headerlink\" title=\"Kafka设计特点：\"></a>Kafka设计特点：</h4><ol>\n<li>以时间复杂度为O(1)的方式提供消息持久化能力，即使对TB级以上数据也能保证常数时间的访问性能；</li>\n<li>高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒100K条消息的传输；</li>\n<li>支持Kafka Server间的消息分区，及分布式消费，同时保证每个partition内的消息顺序传输；</li>\n<li>同时支持离线数据处理和实时数据处理；</li>\n<li>Scale out：支持<code>在线</code>水平扩展。</li>\n</ol>\n<p>Kafka优秀的设计理念和突出的性能，被称为下一代分布式消息系统，淘宝消息中间件团队完全借鉴了Kafka的设计，用java实现了meta消息中间件，并广泛用于淘宝的业务中。</p>\n<h3 id=\"Kafka架构\"><a href=\"#Kafka架构\" class=\"headerlink\" title=\"Kafka架构\"></a>Kafka架构</h3><p>下图是Kafka的主要架构图：<br><img src=\"http://iamsummer-wordpress.stor.sinaapp.com/uploads/2015/08/Snip20150817_1.png\" alt=\"\"></p>\n<p>组成部件：</p>\n<ul>\n<li>broker：Kafka消息中间件处理结点，一个Kafka节点就是一个broker，多个broker可以组成一个Kafka集群。</li>\n<li>topic：每个消息都属于一个topic，可以看作一个queue，Kafka集群能够同时负责多个topic的分发；</li>\n<li>partition：topic物理上的分组，一个topic可以分为多个partition，每个partition是一个有序的队列；</li>\n<li>producer：负责发布消息到Kafka broker；</li>\n<li>consumer ：负责从Broker pull消息；</li>\n<li>consumer group：每个consumer属于一个特定的consumer group（可为每个consumer指定group name，若不指定group name则属于默认的group）；</li>\n<li>zookeeper：协调服务，用于管理broker服务、分区信息、消费者服务、消费者消费状态等。</li>\n</ul>\n<p>下面分别介绍各个部件。</p>\n<h3 id=\"Kafka存储\"><a href=\"#Kafka存储\" class=\"headerlink\" title=\"Kafka存储\"></a>Kafka存储</h3><h4 id=\"文件结构\"><a href=\"#文件结构\" class=\"headerlink\" title=\"文件结构\"></a><em>文件结构</em></h4><p>再介绍两个名词：</p>\n<ul>\n<li>segment：partition物理上由多个segment组成；</li>\n<li>offset：每个partition都由一系列有序的、不可变的消息组成，这些消息被连续的追加到partition中。partition中的每个消息都有一个连续的序列号叫做offset，用于partition中唯一标识的这条消息。</li>\n</ul>\n<p>一个topic可以认为是一类消息，在Kafka文件存储中，同一个topic下有多个不同partition，每个partition为一个目录，partiton命名规则为topic名称+有序序号，第一个partiton序号从0开始，序号最大值为partitions数量减1。</p>\n<p>每个partion(目录)相当于一个大文件被平均分配到多个大小相等segment(段)数据文件中。但每个段segment file消息数量不一定相等，这种特性方便old segment file快速被删除，可以在配置中指定删除策略。</p>\n<p>segment file组成：由2大部分组成，分别为index file和data file，此2个文件一一对应，成对出现，后缀”.index”和“.log”分别表示为segment索引文件、数据文件。</p>\n<p>segment文件命名规则：partion全局的第一个segment从0开始，后续每个segment文件名为上一个segment文件最后一条消息的offset值。数值最大为64位long大小，19位数字字符长度，没有数字用0填充。</p>\n<p>下面是名字为topicName，分区为2的文件存储结构。<br><img src=\"http://iamsummer-wordpress.stor.sinaapp.com/uploads/2015/08/Snip20150817_2.png\" alt=\"\"></p>\n<p>topicName-0和topicName-1这两个目录为两个分区，每个分区下面都有两个segment文件组成，文件以上个文件最后一条信息的offset命名。</p>\n<h4 id=\"顺序读写\"><a href=\"#顺序读写\" class=\"headerlink\" title=\"顺序读写\"></a><em>顺序读写</em></h4><p>Kafka的开发者们认为不需要在内存里缓存什么数据，操作系统的文件缓存已经足够完善和强大，只要你不搞随机写，顺序读写的性能是非常高效的（经验证，顺序写磁盘效率比随机写内存还要高，这是Kafka高吞吐率的一个很重要的保证）。Kafka的数据只会顺序append，数据累积到一定程度或者超过一定时间会被删除。</p>\n<p><img src=\"http://iamsummer-wordpress.stor.sinaapp.com/uploads/2015/08/Snip20150817_4.png\" alt=\"\"><br>上图是写消息的示意图，每个分区独立append消息。</p>\n<p>Kafka读的时候，需要根据offset先找到对应的消息所在的segment，即.index和.log文件，通过索引文件，快速定位到.log文件的文件，然后顺序读到offset消息即可。Kafka读取特定消息的时间复杂度为O(1)，即与文件大小无关，保证了效率。</p>\n<h3 id=\"producer\"><a href=\"#producer\" class=\"headerlink\" title=\"producer\"></a>producer</h3><p>producer发送消息到broker时，会根据paritition机制选择将其存储到哪一个partition。如果partition机制设置合理，所有消息可以均匀分布到不同的partition里，这样就实现了负载均衡。如果一个topic对应一个文件，那这个文件所在的机器I/O将会成为这个topic的性能瓶颈，而有了partition后，不同的消息可以并行写入不同broker的不同partition里，极大的提高了吞吐率。可以在$Kafka_HOME/config/server.properties中通过配置项num.partitions来指定新建topic的默认partition数量，也可在创建topic时通过参数指定，同时也可以在topic创建之后通过Kafka提供的工具修改。</p>\n<p>在发送一条消息时，可以指定这条消息的key，Producer根据这个key和partition机制来判断应该将这条消息发送到哪个Parition。Paritition机制可以通过指定Producer的paritition. class这一参数来指定，该class必须实现Kafka.producer.partitioner接口。</p>\n<h3 id=\"consumer\"><a href=\"#consumer\" class=\"headerlink\" title=\"consumer\"></a>consumer</h3><p>####push和pull<br>在JMS实现中，topic模型基于push模式，即broker将消息推送给consumer端。不过在Kafka中，采用了pull 模式，即consumer在和broker建立连接之后，主动去pull(或者说fetch)消息； 事实上，push模式和pull模式各有优劣。</p>\n<ul>\n<li><code>push模式</code>很难适应消费速率不同的消费者，因为消息发送速率是由broker决定的。push模式的目标是尽可能以最快速度传递消息，但是这样很容易造成consumer来不及处理消息。</li>\n<li><code>pull模式</code>有它的优点，consumer端可以根据自己的消费能力适时的去fetch消息并处理，且可以控制消息消费的进度(offset)；</li>\n</ul>\n<p>Kafka另一个独特的地方是将消费者消费进度保存在客户端而不是服务器，这样服务器就不用记录消息的投递过程，每个客户端都自己知道自己下一次应该从什么地方什么位置读取消息。Kafka还强调减少数据的序列化和拷贝开销，它会将一些消息组织成Message Set做批量存储和发送，并且客户端在pull数据的时候，尽量以zero-copy的方式传输，利用sendfile（对应java里的 FileChannel.transferTo/transferFrom）这样的高级IO函数来减少拷贝开销。</p>\n<h4 id=\"consumer-group\"><a href=\"#consumer-group\" class=\"headerlink\" title=\"consumer group\"></a>consumer group</h4><p>同一分区的消费是有序的，但跨分区消息的消费不保证顺序性。Kafka为消费者提供了GroupID功能，拥有同样GroupID的消费者，消费不同的分区。上文提过，JMS规范提供了点对点和发布/订阅两种消费模式。如果每个消费者拥有同样的GroupID，那么这个主题就是被当做点对点模式消费；如果拥有不同的GroupID，这个主题就是被当做发布订阅者模式消费。<br><img src=\"http://iamsummer-wordpress.stor.sinaapp.com/uploads/2015/08/Snip20150817_7.png\" alt=\"\"><br>如上图所示，消费者C1和C2在同一个消费组，C1消费P0和P3分区，C2消费P1和P2分区，C1和C2不会相互消费相同的分区。但是C3~C6属于两外一个消费组。那么，C3也可消费P0。如果只有Group A，那么可认为是点对点消费模式。如果有Group A和Group B同时订阅P0，就是发布订阅模式。</p>\n<h3 id=\"备份-和-主从分区\"><a href=\"#备份-和-主从分区\" class=\"headerlink\" title=\"备份 和 主从分区\"></a>备份 和 主从分区</h3><p>Kafka从0.8开始提供partition级别的replication，将分区复制多份，放在不同节点，这就实现了数据的高可用。replication的数量可在$Kafka_HOME/config/server.properties中配置。</p>\n<pre><code>default.replication.factor = 1 默认值为1，不备份\n</code></pre><p>Kafka将每个partition数据复制到多个server节点上，任何一个partition有一个leader和多个follower；leader处理所有的read-write请求，follower需要和leader保持同步。follower和consumer一样，消费消息并保存在本地日志中；leader负责跟踪所有的follower状态，如果follower”落后”太多或者失效，leader将会把它从replicas同步列表中删除。当所有的follower都将一条消息保存成功，此消息才被认为是”committed”，那么此时consumer才能消费它。即使只有一个replicas实例存活，仍然可以保证消息的正常发送和接收，只要zookeeper集群存活即可。(不同于其他分布式存储，比如hbase需要”多数”存活才行)<br>    当leader失效时，需在followers中选取出新的leader，可能此时follower落后于leader，因此需要选择一个”up-to-date”的follower。在这种模式下，对于f+1个Replica，一个partition能在保证不丢失已经commit的消息的前提下容忍f个Replica的失败。<br>    作为leader的server节点承载了全部的请求压力，有多少个partitions就意味着有多少个”leader”，Kafka会将”leader”均衡的分散在每个实例上，来确保整体的性能稳定.</p>\n<p>回到Kafka架构图中，Kafka集群有两个服务节点，broker1和broker2，topicA有4个分区，分区0、1、2、3，分区0和分区1的leader在broker1上，备份在broker2上，分区2和分区3的leader在broker2上，备份在broker1，producer和consumer的读写都是从leader分区上操作。</p>\n<h3 id=\"Message-Delivery-Semantics\"><a href=\"#Message-Delivery-Semantics\" class=\"headerlink\" title=\"Message Delivery Semantics\"></a>Message Delivery Semantics</h3><p>对于JMS实现，消息传输担保非常直接：有且只有一次(exactly once)。在Kafka中稍有不同,对于consumer而言：<br>1) at most once: 消息可能会丢，但绝不会重复传输；<br>2) at least once: 消息至少发送一次，如果消息未能接受成功，可能会重发，直到接收成功；<br>3) exactly once: 消息只会发送一次；</p>\n<ul>\n<li><em>at most once</em> : 消费者fetch消息，然后保存offset，然后处理消息；当client保存offset之后，但是在消息处理过程中consumer进程失效(crash)，导致部分消息未能继续处理。那么此后可能其他consumer会接管，但是因为offset已经提前保存，那么新的consumer将不能fetch到offset之前的消息(尽管它们尚没有被处理)，这就是”at most once”。</li>\n<li><em>at least once</em> : 消费者fetch消息，然后处理消息，然后保存offset。如果消息处理成功之后,但是在保存offset阶段zookeeper异常或者consumer失效，导致保存offset操作未能执行成功，这就导致接下来再次fetch时可能获得上次已经处理过的消息，这就是”at least once”。</li>\n<li><em>exactly once</em> : Kafka中并没有严格的去实现(需要基于2阶段提交事务，协调offset和实际操作的输出)。</li>\n</ul>\n<p>因为”消息消费”和”保存offset”这两个操作的先后时机不同，导致了上述3种情况。Kafka默认保证At least once，并且允许通过设置producer异步提交来实现At most once。而Exactly once要求与目标存储系统协作，Kafka提供的offset可以使用这种方式非常直接非常容易。</p>\n<h3 id=\"Zookeeper\"><a href=\"#Zookeeper\" class=\"headerlink\" title=\"Zookeeper\"></a>Zookeeper</h3><p>Kafka使用zookeeper来发现服务，负载均衡，leader选举等。</p>\n<ol>\n<li>producer端使用zookeeper用来”发现”broker列表，以及和topic下每个partition leader建立socket连接并发送消息；</li>\n<li>broker端使用zookeeper用来注册broker信息，监测partition leader存活性；</li>\n<li>consumer端使用zookeeper用来注册consumer信息，其中包括consumer消费的partition列表等，同时也用来发现broker列表，并和partition leader建立socket连接，并获取消息；</li>\n<li>维护offset信息和topic分区信息；</li>\n</ol>\n<h3 id=\"Kafka性能\"><a href=\"#Kafka性能\" class=\"headerlink\" title=\"Kafka性能\"></a>Kafka性能</h3><p>LinkedIn团队的性能测试，对比Kafka与Apache ActiveMQ V5.4和RabbitMQ V2.4的性能。ActiveMQ使用默认的消息持久化库Kahadb。LinkedIn在两台Linux机器上实验，每台机器的配置为8核2GHz、16GB内存、6个磁盘使用RAID10。两台机器通过1GB网络连接。一台机器作为代理，另一台作为生产者或者消费者。<br>在 <em>生产者测试</em> 中，对每个系统，运行一个生产者，总共发布1000万条消息，每条消息200字节。 Kafka生产者以1和50批量方式发送消息。ActiveMQ和RabbitMQ似乎没有简单的办法来批量发送消息，LinkedIn每次发送一条消息测试。<br>在 <em>消费者测试</em> 中，LinkedIn使用一个消费者获取总共1000万条消息。LinkedIn让所有系统每次拉请求都预获取大约相同数量的数据，最多1000条消息或者200KB。对ActiveMQ和RabbitMQ，LinkedIn设置消费者确认方式为自动确认。<br>测试结果如下：<br><img src=\"http://iamsummer-wordpress.stor.sinaapp.com/uploads/2015/08/Snip20150817_10.png\" alt=\"\"></p>\n<p>从上图可以看到，Kafka如果是批量发送，速率可以到达将近50万条每秒，单条发送也比另外的消息队列高；<br>消费速率可以达到20万条每秒，远超出其他两个消息队列。</p>\n<h3 id=\"Kafka适合场景\"><a href=\"#Kafka适合场景\" class=\"headerlink\" title=\"Kafka适合场景\"></a>Kafka适合场景</h3><ul>\n<li><em>网站活动跟踪</em>：Web应用发送事件如页浏览量或搜索到Kafka，这样这些事件能够被hadoop实时处理和分析。</li>\n<li><em>监控</em>：实现操作监控的警报和报表，实时的检查日志，发现异常；</li>\n<li><em>日志聚合</em>：Kafka能够用于从多个服务收集日志，然后以一种标准格式提供给多个消费者，包括Hadoop 和Apache Solr；</li>\n<li><em>流处理</em>：类似Spark Streaming能从一个主题读取数据处理然后写入数据到一个新的主题，这样被其他应用再次利用，Kafka的durability（不丢失 持久性）对流处理是非常有用的。</li>\n</ul>\n","categories":["未分类"],"tags":["技术"]},{"title":"MongoDB：锁和并发控制","url":"http://fengjianque.github.io/2017/02/06/mongodb-lock/","content":"<h1 id=\"MongoDB：锁和并发控制\"><a href=\"#MongoDB：锁和并发控制\" class=\"headerlink\" title=\"MongoDB：锁和并发控制\"></a>MongoDB：锁和并发控制</h1><p>本文主要介绍两部分内容，第一部分是MongoDB的锁，第二部分是MongoDB的并发控制。这都跟MongoDB性能和效率相关的，有助于在使用MongoDB过程中，知道哪些操作会带来怎样效率的影响。第二部分从业务层面出发介绍并发控制的方法,基本上都是开发中碰到的常见场景。</p>\n<h2 id=\"MongoDB锁\"><a href=\"#MongoDB锁\" class=\"headerlink\" title=\"MongoDB锁\"></a>MongoDB锁</h2><p>###锁类型<br>Mongodb使用的是read-write读写锁，允许多个读者并发的加共享锁访问同一资源，而同一时间只允许一个写者加排它锁改变资源，此时不允许其它的读和写。<br>在mongodb中，还使用了意向锁（IS、IX）提高加锁性能。为了提高吞吐率，在等待排队的锁中，排在最前面的如果是共享锁，会一次把队列中所有的共享锁都加上，释放之后就处理排他锁。而不是当前是共享锁，后面一来共享锁请求都加上去，后面的请求是要排队的，避免写锁的饥饿。</p>\n<h3 id=\"锁的粒度\"><a href=\"#锁的粒度\" class=\"headerlink\" title=\"锁的粒度\"></a>锁的粒度</h3><p>mongodb普遍使用全局锁、数据库锁。还允许自己使用不同存储引擎，实现更细粒度的锁控制。比如MMAPv1存储引擎支持表锁，WiredTiger存储引擎，支持文档级别的锁。</p>\n<p>在 2.2 版本以前，mongodb只有<strong>全局锁</strong>；也就是对整个mongodb实例加锁，这个粒度是很大的。</p>\n<p>从 2.2 版本开始，大部分读写操作只锁一个库，库级别锁相对之前版本，这个粒度已经下降。对于一些涉及到多个数据库操作，还需要加全局锁。目前MongoDB常见的版本是2.6、2.7，锁粒度只到collection。</p>\n<p>从 3.0 开始，如果使用MMAPv1存储引擎，最细粒度支持 <strong>collection级别的锁</strong> ，对于一个数据库里面的collection，对一个collection的加锁操作，不影响其他collection的操作。</p>\n<h3 id=\"查看锁的状态\"><a href=\"#查看锁的状态\" class=\"headerlink\" title=\"查看锁的状态\"></a>查看锁的状态</h3><ul>\n<li><a href=\"http://docs.mongodb.org/v2.6/reference/command/serverStatus/\" target=\"_blank\" rel=\"external\">db.serverStatus()</a></li>\n<li><a href=\"http://docs.mongodb.org/v2.6/reference/method/db.currentOp/#db.currentOp\" target=\"_blank\" rel=\"external\">db.currentOp()</a></li>\n<li>mongotop</li>\n<li>mongostat</li>\n</ul>\n<h3 id=\"产生加锁的操作\"><a href=\"#产生加锁的操作\" class=\"headerlink\" title=\"产生加锁的操作\"></a>产生加锁的操作</h3><table>\n<thead>\n<tr>\n<th>操作</th>\n<th>锁类型</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>query</td>\n<td>读锁</td>\n</tr>\n<tr>\n<td>cursor get more</td>\n<td>读锁</td>\n</tr>\n<tr>\n<td>insert</td>\n<td>写锁</td>\n</tr>\n<tr>\n<td>remove</td>\n<td>写锁</td>\n</tr>\n<tr>\n<td>update</td>\n<td>写锁</td>\n</tr>\n<tr>\n<td>Map-reduce</td>\n<td>读锁和写锁，除非Map-reduce操作被声明为非原子性的。部分map-reduce任务能够并发的执行。</td>\n</tr>\n<tr>\n<td>createIndex</td>\n<td>创建索引操作默认在前台执行，会长时间锁住数据库。</td>\n</tr>\n<tr>\n<td>db.eval()</td>\n<td>写锁 db.eval()会加全局写锁，会阻塞其他的读写操作。加上参数nolock: true，表示不加锁。</td>\n</tr>\n<tr>\n<td>eval</td>\n<td>写锁. 同db.eval()</td>\n</tr>\n<tr>\n<td>aggregate()</td>\n<td>读锁</td>\n</tr>\n</tbody>\n</table>\n<p>###读和写操作让出锁<br>在需要长时间读和非原子写的操作，在一些条件下会让出所占的锁。比如update更新多个文档时候，就有可能在中间让出锁。Mongodb使用一种自适应的算法基于预测磁盘访问（比如缺页中断）方式决定是否让出锁。Monodb在读之前预测所需要的数据是否在内存中，如果预测不在内存中则让出锁，等数据加载后，重新请求上锁来完成操作。在2.6版本以后，对于索引，就算不在内存中，也不让出锁。</p>\n<h3 id=\"管理命令数据库锁\"><a href=\"#管理命令数据库锁\" class=\"headerlink\" title=\"管理命令数据库锁\"></a>管理命令数据库锁</h3><p>在运行下面的管理命令，需要长时间占锁进行操作：</p>\n<ul>\n<li>db.collection.createIndex(), 如果没有设置background:true参数,长时间锁住数据库。</li>\n<li>reIndex；</li>\n<li>compact；</li>\n<li>db.repairDatabase(),</li>\n<li>db.createCollection(), 比如要创建很大的固定空间capped collection时候；</li>\n<li>db.collection.validate(), 返回磁盘信息；</li>\n<li>db.copyDatabase(). 会锁住多个数据库。</li>\n</ul>\n<p>对于上面的操作如果有副本集，建议将其中的一个副本下线后进行操作，这样就不会影响上线服务。</p>\n<p>下面的管理命令只占短时间锁数据库：</p>\n<ul>\n<li>db.collection.dropIndex(),</li>\n<li>db.getLastError(),</li>\n<li>db.isMaster(),</li>\n<li>rs.status()，</li>\n<li>db.serverStatus(),</li>\n<li>db.auth(),</li>\n<li>db.addUser()</li>\n</ul>\n<h3 id=\"锁多个数据库的全局锁\"><a href=\"#锁多个数据库的全局锁\" class=\"headerlink\" title=\"锁多个数据库的全局锁\"></a>锁多个数据库的全局锁</h3><ul>\n<li>db.copyDatabase() 全局锁，锁整个monogdb的实例，不允许读写。</li>\n<li>db.repairDatabase() 全局写锁。</li>\n<li>Journaling，如果开启了Journaling功能，在记录日志时会很短时间锁住所有的数据库。所有的数据库共享一个journaling。<br>对副本集主节点的所有写操作不仅会锁住目标库，也会锁住local库很小一段时间。通过Local库上的锁， mongod进程可以往主节点的oplog 表写数据，以及一些认证操作，不过这些都只占整个写操作时间的很少一部分。</li>\n</ul>\n<h3 id=\"分片上锁和并发\"><a href=\"#分片上锁和并发\" class=\"headerlink\" title=\"分片上锁和并发\"></a>分片上锁和并发</h3><p>分片通过在多个mongod实例部署分布式集合来提高并发的性能，允许分片服务器(比如mongos进程)访问多个mongd实例执行任意数量的并发操作。</p>\n<p>mongod实例之间是相互独立的，并且使用的是MongoDB多读单写锁。mongod实例上的操作不会阻塞其它实例。</p>\n<h3 id=\"副本集主节点上的锁和并发\"><a href=\"#副本集主节点上的锁和并发\" class=\"headerlink\" title=\"副本集主节点上的锁和并发\"></a>副本集主节点上的锁和并发</h3><p>在副本集中，当往主节点上某个表写入时，MongoDB也会对主节点的oplog进行写入，这是local库上一个特殊的表。因此，MongoDB会锁住目标表的库和local库。mongod进程会锁住这两个库来保证数据一致性，让这两个库的写操作要么全执行要么全不执行。</p>\n<h3 id=\"副本集次级节点上的锁和并发\"><a href=\"#副本集次级节点上的锁和并发\" class=\"headerlink\" title=\"副本集次级节点上的锁和并发\"></a>副本集次级节点上的锁和并发</h3><p>在副本集中，次级节点会分批的收集oplog信息，这些批次的回写是并行执行的。当在进行写操作时，次级节点上的数据是不可读的，回写操作会按照oplog记录的顺序执行。</p>\n<p>MongoDB允许副本集次级节点上的几个写操作并行执行，分两个阶段：<br>第一个阶段，通过一个读锁，mongod确保所有与写操作有关数据都存在于内存中。在这个阶段，其它客户端可以在这个节点上做查询操作。<br>第二阶段Mongodb会使用一个线程池使用写锁允许所有的写操作相互协调的成批写入。</p>\n<h2 id=\"MongoDB并发控制方法\"><a href=\"#MongoDB并发控制方法\" class=\"headerlink\" title=\"MongoDB并发控制方法\"></a>MongoDB并发控制方法</h2><p>Mongodb不支持事务，这是Mongodb的缺陷，要达到业务方面实现并发，保证数据的一致性，要使用一些并发的控制方法。</p>\n<h3 id=\"原子操作\"><a href=\"#原子操作\" class=\"headerlink\" title=\"原子操作\"></a>原子操作</h3><p>mongodb对单个文档的写都是原子操作，就算修改一个文档里面的多个内嵌文档也算修改一个文档，也是原子操作。<br>当一次写操作中要修改多个文档，每个文档的写操作是原子的，但整个操作不是原子的，期间会让出锁，允许其他线程操作。<br>使用update和findAndModify方法，如果都只对一个文档进行操作，那么都是原子的。区别是返回的内容不一样，findAndModify还可以返回当前改完之后的文档，这个在很多场景很有用，比如实现一个自动增长的id。如果用update，然后findOne就不能保证返回的结果是刚刚更新后的记录，可能别的线程又修改了。</p>\n<h3 id=\"isolated\"><a href=\"#isolated\" class=\"headerlink\" title=\"$isolated\"></a>$isolated</h3><p>Mongodb中有个$isolated操作符，可以隔离其他的线程。 使用$isolate操作符时，可以阻止一次写多个文档中让出锁，直到操作完成或者出错。<br>但是$isolate也无法保证多个文档修改的原子性(all-or-nothing），$isolate操作如果在写过程中出错，是不会回滚的，也就是存在只修改部分文档的情况。可以这么说$isolated操作符只提供隔离性，但不保证原子性。<br><strong>操作符$isolated不能在分片上工作。</strong><br>下面是使用$isolated操作符进行update的例子：</p>\n<pre><code>db.test.update(\n    { age : {$gt:30} , $isolated : 1 },\n    { $inc : { score : 1 } },\n    { multi: true }\n)\n</code></pre><p>当执行此操作时，其他线程就阻塞了，直到把所有操作更新完。这个操作会锁数据库比较长的时间，影响并发的效率，注意进行权衡。</p>\n<h4 id=\"使用唯一性索引\"><a href=\"#使用唯一性索引\" class=\"headerlink\" title=\"使用唯一性索引\"></a>使用唯一性索引</h4><p>当你想要创建某个字段唯一的文档时候，在多线程环境下，使用先查询为空再插入的方法，仍会导致相同的字段记录产生。解决的方法是在这个字段上建一个唯一的索引，在插入相同的字段时，会raise duplicate index key error。</p>\n<pre><code>db.members.createIndex( { &quot;name&quot;: 1 }, { unique: true } )\n</code></pre><p>上面创建了一个name字段的唯一索引。<br>然后使用操作insert或者update方法增加和修改文档，捕捉raise的duplicate index key错误，判断是否操作成功。比如使用update操作：</p>\n<pre><code>db.people.update(\n   { name: &quot;cf&quot; },\n   {\n      name: &quot;cf&quot;,\n      age: 18,\n      score: 100,\n   },\n   { upsert: true }\n)\n</code></pre><p>用upsert参数表明如果不存在则进行插入操作，这样做能保证name字段的值是唯一的，即便在多线程环境中。</p>\n<h3 id=\"事务\"><a href=\"#事务\" class=\"headerlink\" title=\"事务\"></a>事务</h3><p>如果文档的内容有两个field，A和B，现在想根据B的值进行修改A的值，比如（A=B+N），也就是需要知道field B的内容，才能进行A修改。这时候使用update和findAndiModify就做不到了。<br>有两种方法。<br>一种是两阶段提交事务语义(two-phase commit)方法，另外一种是update if current。</p>\n<h4 id=\"update-if-current\"><a href=\"#update-if-current\" class=\"headerlink\" title=\"update if current\"></a>update if current</h4><p>update if current是用手动的方式保证原子性，类似于CPU中常见的同步原语:比较和交换cas（Compare &amp; Swap）操作，原理如下：<br>1、获取需要更新的记录，并记录A字段的值，oldvalue；<br>2、本地修改好要更新的字段A；<br>3、使用update操作修改A字段值，但是查询条件必须是A字段的值==oldvalue。<br>下面举例说明：</p>\n<pre><code>var myDocument = db.test.findOne( { name: &apos;cf&apos; } );\n\nif (myDocument) {\n\n  var oldValue = myDocument.score;\n  var age = myDocument.age\n\n  if (myDocument.score &lt; 10) {\n          myDocument.score *= 5;\n  } else {\n      myDocument.score = age * 1.5;\n  }\n\n  var results = db.test.update(\n     {\n       name: myDocument.name,\n       score: oldValue\n     },\n     {\n       $set: { score: myDocument.score }\n     }\n  );\n\n  if ( results.hasWriteError() ) {\n      print(&quot;unexpected error updating document: &quot; + tojson( results ));\n  } else if ( results.nMatched == 0 ) {\n      print(&quot;No update: no matching document for { name: &quot; + myDocument.name + &quot;, score: &quot; + oldValue + &quot; }&quot;)\n  }\n</code></pre><p>上面的例子，score的值修改，跟score本身、age值相关，这就需要先获取score、age的值，再进行修改。<br>你可以发现，这需要自己手动去检查有没有修改成功，如果不成功还需自己去控制再次尝试更新。</p>\n<h4 id=\"两阶段提交事务\"><a href=\"#两阶段提交事务\" class=\"headerlink\" title=\"两阶段提交事务\"></a>两阶段提交事务</h4><p>第一个阶段尝试进行提交，第二个阶段正式提交。这样，即使更新数据时发生故障，我们也能知道数据都处于什么状态，总是能够把数据恢复到更新之前的状态。原理是使用一个表来记录事务transaction，保存可能的状态inital、pending、applied、done、canceling、canceled；要进行更新的collection的记录中增加一个类型为列表pendingTransactions字段，用来绑定正在执行的transaction id。通过修改transaction里面记录的状态，确保事务执行的阶段，这样在发生故障时就知道transaction处于哪个阶段，从而resume或者rollback。<br>具体例子可以看文档：<a href=\"http://docs.mongodb.org/manual/tutorial/perform-two-phase-commits/\" target=\"_blank\" rel=\"external\">Two Phase Commits\n</a><br>两阶段提交方法达到事务一致性，我个人觉的还是比较麻烦，这也是mongodb的缺陷所在。</p>\n<p>参考文档：<br><a href=\"http://askasya.com/post/findandmodify\" target=\"_blank\" rel=\"external\">http://askasya.com/post/findandmodify</a><br><a href=\"http://docs.mongodb.org/v2.6/faq/concurrency/\" target=\"_blank\" rel=\"external\">http://docs.mongodb.org/v2.6/faq/concurrency/</a><br><a href=\"http://docs.mongodb.org/manual/core/write-operations-atomicity/\" target=\"_blank\" rel=\"external\">http://docs.mongodb.org/manual/core/write-operations-atomicity/</a></p>\n","categories":["未分类"],"tags":["技术"]},{"title":"Mongdb：索引优化和工具","url":"http://fengjianque.github.io/2017/02/06/mongodb-index/","content":"<h1 id=\"Mongdb：索引优化和工具\"><a href=\"#Mongdb：索引优化和工具\" class=\"headerlink\" title=\"Mongdb：索引优化和工具\"></a>Mongdb：索引优化和工具</h1><p>索引能帮助我们快速的找到我们的记录，在数据量庞大的情况下，显得尤其重要。不用索引的查询称为“全表扫描”，对大集合来说，效率非常低。<br>在Mongodb中增加索引可以：</p>\n<ul>\n<li>把一个线性查询时间复杂度O(n)变为b树查询时间复杂度为O(lgn);</li>\n<li>减少在内存中的排序；</li>\n<li>减少硬盘的访问，减少寻页缺失；</li>\n<li>索引覆盖，有些查询直接从索引中获得，不需要查记录。</li>\n</ul>\n<p>本篇文章的内容如下：<br>1、索引的相关操作和复合索引；<br>2、查询索引优化原理和Mongodb查询优化器索引选择机制；<br>3、索引优化工具。</p>\n<h2 id=\"1-索引的相关操作和复合索引\"><a href=\"#1-索引的相关操作和复合索引\" class=\"headerlink\" title=\"1 索引的相关操作和复合索引\"></a>1 索引的相关操作和复合索引</h2><h3 id=\"1-1-关于索引的基本操作\"><a href=\"#1-1-关于索引的基本操作\" class=\"headerlink\" title=\"1.1 关于索引的基本操作\"></a>1.1 关于索引的基本操作</h3><ul>\n<li><p><code>db.collection.ensureIndex(indexed_fields, [options]);</code> 创建一个索引。<br>建索引不得不提的是，建索引就是一个容易引起长时间写锁的问题，MongoDB在前台建索引时需要占用一个写锁（而且不会临时放弃），<strong>阻止读和写</strong>，如果集合的数据量很大，建索引通常要花比较长时间，特别容易引起问题。 使用background: true来解决问题，background在建索引中允许读和写操作，减少建索引带来的影响。</p>\n</li>\n<li><p><code>db.collection.getIndexes();</code> 查看某个表上的所有索引。</p>\n</li>\n<li><code>db.collection.dropIndex(indexed_fields);</code> 删除索引。</li>\n<li><code>db.collection.find(find_fields).explain();</code> 查看查询的过程的统计。</li>\n<li><code>db.collection.find(fields).hint(index_or_name);</code> 强制查询使用某个索引。</li>\n</ul>\n<h3 id=\"1-2-Mongodb-复合索引\"><a href=\"#1-2-Mongodb-复合索引\" class=\"headerlink\" title=\"1.2 Mongodb 复合索引\"></a>1.2 Mongodb 复合索引</h3><p>复合索引就是建立在多个字段上的索引，当查询中有多个排序方向或者包含多个键值的条件时，建立复合索引就很有用。<br><code>db.test.ensureIndex({age: 1, role: 1}, {background: true})</code><br>就建立一个在age和role上的索引，先以age升序，如果age相同，就以role升序排序。</p>\n<p><strong>1.隐含索引</strong><br>如果有一个由N个键的索引，那么会得到N个键前缀组成的索引，比如有复合索引{a:1, b:1, c:1, d:1},实际上我们同时拥有了{a:1}, {a:1, b:1}, {a:1, b:1, c:1}这三个索引。</p>\n<p><strong>2.排序顺序</strong><br>索引以两种顺序存储键，升序 (1) 或降序 (-1)。对于单键索引而言，键的顺序无关紧要因为MongoDB可以以任一顺序遍历整个索引。但是对于 复合索引 而言，索引的顺序可以决定索引是否支持直接排序操作。只有基于多键的排序，索引的顺序才重要。<br>相互翻转（在每个方向上都乘以-1）的索引是等价的。{age:1, role:1}和{age:-1, role:-1}等价，{age:1, role:-1}和{age:-1, role:1}也是等价的。 但是{age:1, role:1}和{age:1, role:-1}不等价。为什么呢，想想B树的遍历方式，就明白了哈。</p>\n<p><code>db.test.find().sort({age:1, role:-1)</code>要求查询结果以age升序，role降序排序，{age:1, role:1}索引就不支持直接排序了，需要进行内存排序{scanAndOrder:true}。</p>\n<h2 id=\"2-优化原理\"><a href=\"#2-优化原理\" class=\"headerlink\" title=\"2 优化原理\"></a>2 优化原理</h2><h3 id=\"2-1-查询索引优化原理\"><a href=\"#2-1-查询索引优化原理\" class=\"headerlink\" title=\"2.1 查询索引优化原理\"></a>2.1 查询索引优化原理</h3><h3 id=\"explain\"><a href=\"#explain\" class=\"headerlink\" title=\"explain()\"></a>explain()</h3><p>explain()能够提供大量与查询相关的信息，对于速度较慢的查询来讲是一个重要的诊断工具之一。</p>\n<pre><code>db.test.find({age: {&quot;$gte&quot;: 30 , &quot;$lte&quot;: 50}}).explain()\n{\n    &quot;cursor&quot; : &quot;BasicCursor&quot;,\n    &quot;n&quot; : 3,\n    &quot;nscannedObjects&quot; : 4,\n    &quot;nscanned&quot; : 4,\n    &quot;scanAndOrder&quot; : false,\n    &quot;indexOnly&quot; : false,\n    &quot;millis&quot; : 0\n    .....\n}\ncursor:本次所使用的索引，此次没有使用索引，如果使用了索引为BtreeCursor;\nn：此次查询返回的文档数量；\nnscannedObjects：mongodb按照索引指针去查找实际文档次数；\nnscanned：如果有索引，那么这个值就是查找过索引条目的数量，如果没有索引，就是全表扫描，表示检查锅文档的数量。\nscanAndOrder：mongodb是否在内存中对结果进行排序。\nindexOnly：只需要索引就完成了查询，索引覆盖。\nmillis：查询所耗费的毫秒数。\n</code></pre><p>因此可以得出<strong>nscanned &gt;= nscannedObjects &gt;= n</strong>。对于简单查询你可能期望3个数字是相等的，scanAndOrder：false，这意味着你做出了MongoDB使用的完美的索引。不过很多时候在索引查找速度和是否在内存排序之间需要做出一个权衡。</p>\n<h3 id=\"范围查询\"><a href=\"#范围查询\" class=\"headerlink\" title=\"范围查询\"></a>范围查询</h3><p>首先建一个在age上的索引{age: 1}，查询30&lt;=age&lt;=50,</p>\n<pre><code>db.test.ensureIndex({age: 1}, {background: true})\ndb.test.find({age: {&quot;$gte&quot;: 30 , &quot;$lte&quot;: 50}}).explain()\n{\n    &quot;cursor&quot; : &quot;BtreeCursor age_1&quot;,\n    &quot;n&quot; : 3,\n    &quot;nscannedObjects&quot; : 3,\n    &quot;nscanned&quot; : 3,\n    &quot;scanAndOrder&quot; : false,\n    &quot;indexOnly&quot; : false,\n    &quot;millis&quot; : 0,\n    ......\n}\n</code></pre><p>建了age字段索引之后，cursor变为”BtreeCursor age_1”，nscanned和nscannedObjects都降为到了3，说明查询使用了索引跳过不符合条件的记录。</p>\n<h3 id=\"范围查询-等值查询\"><a href=\"#范围查询-等值查询\" class=\"headerlink\" title=\"范围查询+等值查询\"></a>范围查询+等值查询</h3><p>如果范围查询基础上，再加上等值查询{role: “female”}，结果如下：</p>\n<pre><code>db.test.find({age: {&quot;$gte&quot;: 30 , &quot;$lte&quot;: 50}, type: true}).explain()\n{\n    &quot;cursor&quot; : &quot;BtreeCursor age_1&quot;,\n    &quot;n&quot; : 2,\n    &quot;nscannedObjects&quot; : 3,\n    &quot;nscanned&quot; : 3,\n    ....\n}\n</code></pre><p>过滤了role: ”female”，n降为2，但是nscanned和nscannedObjects仍然为3。<br>创建{age:1, role:1}复合索引又如何？</p>\n<pre><code>db.test.dropIndex({age:1})\ndb.test.ensureIndex({age: 1, role: 1}, {background: true})\ndb.test.find({age: {&quot;$gte&quot;: 30 , &quot;$lte&quot;: 50}, role: &quot;female&quot;}).explain()\n{\n    &quot;cursor&quot; : &quot;BtreeCursor age_1_role_1&quot;,\n    &quot;n&quot; : 2,\n    &quot;nscannedObjects&quot; : 2,\n    &quot;nscanned&quot; : 3,\n    .....\n}\n</code></pre><p>nscannedObjects降为2，与n相等，但nscanned还是为3，mongodb做了age30到50之间索引全扫描。从下面的图可以了解查找过程。<br><img src=\"http://iamsummer-wordpress.stor.sinaapp.com/uploads/2015/01/age-role-index.png\" alt=\"\"><br>从上图清晰看到，根据B树的遍历方式，mongodb遍历了30到50之间的索引。</p>\n<p>能不能使nscanned = nscannedObjects = n，细心的你回发现，定义索引的顺序有问题，定义{role:1, age:1 }索引，再进行查找，结果如下：</p>\n<pre><code>db.test.dropIndex({age:1, role:1})\ndb.test.ensureIndex({ role: 1, age: 1}, {background: true})\ndb.test.find({age: {&quot;$gte&quot;: 30 , &quot;$lte&quot;: 50}, role: &quot;female&quot;}).explain()\n{\n    &quot;cursor&quot; : &quot;BtreeCursor role_1_type_1&quot;,\n    &quot;n&quot; : 2,\n    &quot;nscannedObjects&quot; : 2,\n    &quot;nscanned&quot; : 2,\n    &quot;scanAndOrder&quot; : false,\n    ....\n}\n</code></pre><p>nscanned变成了2。<br>如果数据量有上千万条，缩小nscanned能提升很大的效率。但也要衡量下多值索引带来的内存开销，插入时的开销。</p>\n<h3 id=\"范围查询-排序\"><a href=\"#范围查询-排序\" class=\"headerlink\" title=\"范围查询+排序\"></a>范围查询+排序</h3><p>范围查询加上排序，我们应该怎么来优化呢？<br><code>db.test.find({age: {&quot;$gte&quot;: 30 , &quot;$lte&quot;: 50}).explain()</code><br>前面的{role:1,age:1}索引放在这里没有作用，Mongodb还是做了全表扫描。<br>我们来建一个索引{age:1, score:1}，然后查询来分析。</p>\n<pre><code>db.test.ensureIndex({age:1, score:1})\ndb.test.find({age: {&quot;$gte&quot;: 20 , &quot;$lte&quot;: 40}, score: {&quot;$gte&quot;:80, &quot;$lte&quot;:100}}).sort({score:1}).explain()\n{\n    &quot;cursor&quot; : &quot;BtreeCursor age_1_score_1&quot;,\n    &quot;n&quot; : 2,\n    &quot;nscannedObjects&quot; : 2,\n    &quot;nscanned&quot; : 2,\n    &quot;scanAndOrder&quot; : true,\n    ....\n}\n</code></pre><p>nscanned=nscannedObjects=n，似乎达到我们的要求，但是scanAndOrder为true，这就意味着MongoDB会把所有查询出来的结果放进内存，然后进行排序，接着一次性输出结果。这将占用服务器大量的CPU和RAM，而且mongodb对排序还有个限制，就是排序集不能大于32M，否则会出现错误。</p>\n<p>创建索引{score:1, age:1 },继续查询得到</p>\n<pre><code>db.test.ensureIndex({score:1, age:1})\ndb.test.find({age: {&quot;$gte&quot;: 20 , &quot;$lte&quot;: 40}, score: {&quot;$gte&quot;:80, &quot;$lte&quot;:100}}).sort({score:1}).explain()\n{\n    &quot;cursor&quot; : &quot;BtreeCursor score_1_age_1&quot;,\n    &quot;n&quot; : 2,\n    &quot;nscannedObjects&quot; : 2,\n    &quot;nscanned&quot; : 3,\n    &quot;scanAndOrder&quot; : false,\n    ....\n}\n</code></pre><p>修改索引后，nscanned虽然为3，但是scanAndOrder为false，免去了排序。这两者之间根据实际情况进行权衡，如果nscanned和n相差特别大，则优先查询，否则优先排序。</p>\n<h3 id=\"等值查询-范围查询-排序\"><a href=\"#等值查询-范围查询-排序\" class=\"headerlink\" title=\"等值查询+范围查询+排序\"></a>等值查询+范围查询+排序</h3><p>如果一个查询包含了等值查询，范围查询，排序，又该如何优化？<br><code>db.test.find({age: {&quot;$gte&quot;: 30 , &quot;$lte&quot;: 50}, role: &quot;female&quot;}).sort({score:1}).explain()</code><br>对于这个查询，前面已经介绍过，使用{role:1, age:1},将获得nscanned = nscannedObjects = n =2的体验，但是有排序的缺点。<br>使用索引{role:1, score:1},索引结构如下图，<br><img src=\"http://iamsummer-wordpress.stor.sinaapp.com/uploads/2015/03/role-score.png&quot;\" alt=\"\"><br>nscanned = nscannedObjects=3, 不用排序。<br>以牺牲nscanned的代价解决了scanAndOrder = true的问题；既然nscanned已不可减少，那么我们是否可以减少nscannedObjects？我们向索引中添加age，这样一来Mongo就不用去从每个文件中获取了。<br>建立索引{role:1, score:1, age:1},然后查询</p>\n<pre><code>db.test.find({age: {&quot;$gte&quot;: 30 , &quot;$lte&quot;: 50}, role: &quot;female&quot;}).sort({score:1}).hint(&apos;role_1_score_1_age_1&apos;).explain()\n{\n    &quot;cursor&quot; : &quot;BtreeCursor role_1_score_1_age_1&quot;,\n    &quot;n&quot; : 2,\n    &quot;nscannedObjects&quot; : 2,\n    &quot;nscanned&quot; : 3,\n    &quot;scanAndOrder&quot; : false,\n    ....\n}\n</code></pre><p>现在nscannedObjects也降为2了，索引也尽善了，但是多字段的索引需要内存和影响写效率的，增加一个字段如果不能增加nscanned和nscannedObjects之间的差值，应该是得不偿失。</p>\n<h3 id=\"2-2-mongodb查询优化器原理\"><a href=\"#2-2-mongodb查询优化器原理\" class=\"headerlink\" title=\"2.2 mongodb查询优化器原理\"></a>2.2 mongodb查询优化器原理</h3><p>那么优化器如何工作的呢？<br>首先，它先分析查询，做一个初步的“最佳索引”分析；<br>其次，假如这个最佳索引不存在， 优化器会为每个可能有效适用于该查询的索引创建查询计划，随后并行运行这个计划，nscanned 值最低的计划胜出。优化器会停止那些长时间运行的计划，将胜出的计划保存下来，以便后续使用。如果有多个最佳索引，mongodb将随机选择一个。<br>最后优化器还会记住所有类似查询的选择（只到大规模文件变动或者索引上的变动）。<br>最佳索引是如何选取的呢？</p>\n<ul>\n<li>最佳索引必须包含查询中所有可以做过滤及需要排序的字段。</li>\n<li>如果查询包含范围查找或者排序，那么对于选择的索引，其中最后用到的键需能满足该范围查找或者排序。</li>\n<li>如果存在不同的最佳索引，那么Mongo将随机选择。</li>\n</ul>\n<p>表数据是变化的，索引也由可能不是最佳的了，查询优化器什么时候重新评估索引呢？</p>\n<ul>\n<li>数据表接收1000次写操作后；</li>\n<li>索引重建；</li>\n<li>增加或删除索引；</li>\n<li>mongod进程重启；</li>\n<li>执行explain()操作；</li>\n</ul>\n<p>当这些事件发生时，当前的缓存的查询计划会清空，重新评估，以便保证获得最佳的查询计划。</p>\n<h3 id=\"2-3-总结优化策略\"><a href=\"#2-3-总结优化策略\" class=\"headerlink\" title=\"2.3 总结优化策略\"></a>2.3 总结优化策略</h3><p>根据上面的分析，复合索引的顺序应该是</p>\n<ul>\n<li>等值查询的字段放在前面；</li>\n<li>接着是需要排序的字段；</li>\n<li>最后是范围查询的字段。<br>*<br>但是有值得权衡的地方，有可能查询访问更多的索引节点，如果排序字段在范围查询字段之前，这两者之间的取舍根据实际情况来定夺。</li>\n</ul>\n<h2 id=\"3-Mongodb索引优化工具\"><a href=\"#3-Mongodb索引优化工具\" class=\"headerlink\" title=\"3 Mongodb索引优化工具\"></a>3 Mongodb索引优化工具</h2><p>这里介绍Mongdb自带的优化器Profiler和第三方工具DEX。</p>\n<h3 id=\"3-1-Profiler\"><a href=\"#3-1-Profiler\" class=\"headerlink\" title=\"3.1 Profiler\"></a>3.1 Profiler</h3><p>类似于MySQL的slow log, Mongodb可以非常方便地记录下所有耗时过长操作，以便于调优。</p>\n<h4 id=\"开启Profiling\"><a href=\"#开启Profiling\" class=\"headerlink\" title=\"开启Profiling\"></a>开启Profiling</h4><p>Mongodb中Profiler默认是关闭的。有两种方式可以开启和控制Profiling的级别。<br>第一种在启动mongd实例时，加上-profile=级别；<br>第二种是在客户端中开启，使用命令db.setProfilingLevel(级别)来配置。<br>profiling有0，1，2三种级别：<br>0：不开启记录；<br>1：记录慢命令（默认是100ms）;<br>2：记录所有命令；</p>\n<p>修改默认慢时间可以在启动mongd实例时添加-slowms=xx或者在shell客户端启用的同时传入参数。<br><code>db.setProfilingLevel(1, 20)</code>设置的慢时间为20毫秒。<br><strong>注意profiling的默认时间的修改是全局起作用的，针对整个mongod实例。</strong></p>\n<h4 id=\"Profiling记录\"><a href=\"#Profiling记录\" class=\"headerlink\" title=\"Profiling记录\"></a>Profiling记录</h4><p>profiling的记录是在对应数据库下的，名字为system.profile。</p>\n<pre><code>db.system.profile.find().pretty()\n{\n &quot;op&quot; : &quot;query&quot;,\n &quot;ns&quot; : &quot;gacc.app_user_duration&quot;,\n &quot;query&quot; : {\n  &quot;query&quot; : {\n   &quot;duration&quot; : {\n    &quot;$gt&quot; : 6000,\n    &quot;$lt&quot; : 60000\n   },\n   &quot;tin&quot; : {\n    &quot;$gt&quot; : 126414600,\n    &quot;$lt&quot; : 995810371\n   }\n  },\n  &quot;orderby&quot; : {\n   &quot;timestamp&quot; : -1\n  },\n  &quot;$explain&quot; : true\n },\n &quot;ntoskip&quot; : 0,\n &quot;numYield&quot; : 0,\n &quot;nreturned&quot; : 1,\n &quot;responseLength&quot; : 770,\n &quot;millis&quot; : 3263,\n &quot;ts&quot; : ISODate(&quot;2015-03-11T11:53:41.741Z&quot;),\n &quot;client&quot; : &quot;127.0.0.1&quot;,\n &quot;allUsers&quot; : [ ],\n &quot;user&quot; : &quot;&quot;\n}\n\nts： 该命令在何时执行\nop: 操作类型\nquery: 本命令的详细信息\nresponseLength: 返回结果集的大小\nntoreturn: 本次查询实际返回的结果集\nmillis: 该命令执行耗时，以毫秒记\n</code></pre><p>show profile命令可以显示最新的5条操作记录；或者使用字段进行过滤查询。</p>\n<h4 id=\"Profiling效率\"><a href=\"#Profiling效率\" class=\"headerlink\" title=\"Profiling效率\"></a>Profiling效率</h4><p>profiling功能肯定是会影响效率的，但其记录用了更加高效的capped collection。这种collection有一些限制，来增加效率。</p>\n<ol>\n<li>固定大小；Capped Collections 必须事先创建，并设置大小：<blockquote>\n<p>db.createCollection(“collection”, {capped:true, size:100000})</p>\n</blockquote>\n</li>\n<li><p>Capped Collections 可以insert 和update 操作,不能delete 操作。只能用drop()方法删除整个Collection。</p>\n</li>\n<li><p>默认基于Insert 的次序排序的。如果查询时没有排序，则总是按照insert 的顺序返回。</p>\n</li>\n<li><p>FIFO。如果超过了Collection 的限定大小，则用FIFO 算法，新记录将替代最先insert的记录.</p>\n</li>\n</ol>\n<p>###3.2 Dex</p>\n<p>Dex是一个第三方的开源的Mongodb优化工具，建立在profiler上，但是对索引的分析有一套自己的标准，推荐最佳索引给开发者参考。</p>\n<h4 id=\"工作过程\"><a href=\"#工作过程\" class=\"headerlink\" title=\"工作过程\"></a>工作过程</h4><ol>\n<li>Dex遍历Mongodb的日志或者profile collection；</li>\n<li>从输入中Dex的LogParser或者ProfilerParser提取每个查询；</li>\n<li>将查询传人到QueryAnalyzer；</li>\n<li>QueryAnalyzer分析存在的索引，看是否符合自己的优化标准，如果不存在这样的索引，Dex就推荐一个。</li>\n</ol>\n<h4 id=\"优化标准\"><a href=\"#优化标准\" class=\"headerlink\" title=\"优化标准\"></a>优化标准</h4><p>第一步：解析queryDex会对查询query进行解析，分成下面几大类：</p>\n<ul>\n<li>EQUIV – 普通按数值进行的查询，比如：{a: 1}</li>\n<li>SORT – sort操作，比如： .sort({a: 1})</li>\n<li>RANGE – 范围查询，比如：Specifically: ‘$ne’, ‘$gt’, ‘$lt’, ‘$gte’, ‘$lte’, ‘$in’, ‘$nin’, ‘$all’, ‘$not’</li>\n<li>UNSUPPORTED<ul>\n<li>组合式查询，比如：$and, $or, $nor，</li>\n<li>除了RANGE之外的嵌套查询</li>\n</ul>\n</li>\n</ul>\n<p>第二步：判断当前索引情况有两个标准来找出查询所需的索引。</p>\n<ul>\n<li>Coverage (none, partial, full) - Coverage表示索引覆盖查询条件的情况。none表示完全无索引覆盖。full表示query中的字段都能找到索引。partial表示只有部分字段。</li>\n<li>Order - Order是用于判断索引的顺序是否理想。理想的索引顺序应该是：等值 ○ 排序 ○ 范围.<br>值得注意的是，对地理位置索引只会进行分析，但是不会提出改进建议。</li>\n</ul>\n<p>第三步：通过上面的分析，Dex会生成一个此查询的最佳索引。如果这个索引不存在，并且查询情况不包括上面提到的UNSUPPORTED，那么Dex就会做出相应的索引优化建议。</p>\n<h4 id=\"Dex的使用\"><a href=\"#Dex的使用\" class=\"headerlink\" title=\"Dex的使用\"></a>Dex的使用</h4><h5 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h5><blockquote>\n<p>pip install dex</p>\n</blockquote>\n<h5 id=\"启动Dex\"><a href=\"#启动Dex\" class=\"headerlink\" title=\"启动Dex\"></a>启动Dex</h5><ol>\n<li><p>以mongodb的log日志为数据源，启动dex。</p>\n<blockquote>\n<p>dex -f /var/log/mongodb.log mongodb://uutest:xxx@127.0.0.1:27017/gacc</p>\n</blockquote>\n</li>\n<li><p>或者以system.profile数据表为分析依据，事先需要开启mongodb的Profiling,推荐开启级别为1的Profiling。</p>\n<blockquote>\n<p>dex -p mongodb://uutest:xxxx@m127.0.0.1:27017/gacc</p>\n</blockquote>\n</li>\n</ol>\n<h5 id=\"过滤器\"><a href=\"#过滤器\" class=\"headerlink\" title=\"过滤器\"></a>过滤器</h5><ol>\n<li><p>过滤数据库和数据表<br>通过 -n 参数可以对数据库和数据表进行过滤，缩小范围，加快分析。</p>\n<blockquote>\n<p>dex -f my/mongod/data/path/mongodb.log -n “gacc.app_user_duration” mongodb://uutest:xxx@127.0.0.1:27017/gacc<br>dex -p -n “<em>.app_user_duration” mongodb://uutest:xxx@127.0.0.1:27017/gacc<br>dex -f my/mongod/data/path/mongodb.log -n “gacc.\\</em>“ -n “gacc_stat.*“ mongodb://uutest:xxx@127.0.0.1:27017/gacc</p>\n</blockquote>\n</li>\n<li><p>过滤查询时间<br>使用-s/–slows加时间，能过滤慢日志，当查询小于这个值就不被Dex分析。</p>\n<blockquote>\n<p>dex -f my/mongod/data/path/mongodb.log -s 400<br>dex -p -n “*.app_user_duration” mongodb://uutest:xxx@127.0.0.1:27017/gacc –slowms 1000</p>\n</blockquote>\n</li>\n</ol>\n<h5 id=\"监控模式\"><a href=\"#监控模式\" class=\"headerlink\" title=\"监控模式\"></a>监控模式</h5><p>Dex提供了实时监控模式，使用-w参数，实时分析新产生的查询，启用监控模式后，对以往旧的记录不分析。<br>例子：</p>\n<blockquote>\n<p>dex -w -f my/mongod/data/path/mongodb.log mongodb://myUser:myPass@myHost:12345/myDb</p>\n</blockquote>\n<p>如果既有-w，又有-p， 则必须添加-n进行数据库的过滤，形如[dbname.*],举例如下：</p>\n<blockquote>\n<p>dex -w -p -n “gacc.*” mongodb://uutest:xxx@127.0.0.1:27017/gacc</p>\n</blockquote>\n<p>而且如果事先没有开启Profiling，dex会自动打开级别为1的Profiling.</p>\n<h5 id=\"分析输出\"><a href=\"#分析输出\" class=\"headerlink\" title=\"分析输出\"></a>分析输出</h5><p>Dex的分析报告输出有两部分：</p>\n<ol>\n<li><p>runStats – 分析日志或profile数据统计<br>runStats.linesRead – 多少条数母（日志或profile）发送到Dex；<br>runStats.linesAnalyzed -多少条数目dex成功提取查询，并试图给出建议的数量；<br>runStats.linesWithRecommendations – 有多少条查询能收益与推荐的的索引；<br>runStats.logSource – 日志的路径。如果使用 -p/–profile 模式，此项为空.</p>\n</li>\n<li><p>result -：推荐索引的信息包含在results中 ，是一个包含所有查询推荐的list。<br>queryMask - 查询模式, 具体的查询条件；<br>namespace - 查询的数据库集合collection；<br>stats - 针对这个查询做出的统计</p>\n<ul>\n<li>stats.count - 这个查询出现的次数；</li>\n<li>stats.avgTimeMillis - 这个查询花费的平均时间</li>\n<li>stats.totalTimeMillis - 该查询所有的时间消费总和。<br>recommendation - 推荐索引的信息</li>\n<li>recommendation.index - 推荐的索引；</li>\n<li>recommendation.namespace - 索引所在的数据库集合；</li>\n<li>recommendation.shellCommand - 推荐的建索引的命令。</li>\n</ul>\n<p>从Dex的统计信息和索引推荐信息，我们可以知道我们的索引存在的问题，还可以参考它分析出来的索引推荐，帮助我们更好的选择索引。</p>\n</li>\n</ol>\n<h2 id=\"4-建议\"><a href=\"#4-建议\" class=\"headerlink\" title=\"4 建议\"></a>4 建议</h2><p>什么时候需要优化索引呢，个人认为有以下几种：</p>\n<ul>\n<li>如果 nscanned 远大于 nreturned；</li>\n<li>索引覆盖，如果索引就能包含返回值；</li>\n<li>执行 update 操作时同样检查一下 nscanned，并使用索引减少文档扫描数量；</li>\n<li>使用 db.eval() 在服务端执行某些统计操作；</li>\n<li>减少返回文档数量，使用 skip &amp; limit 分页；</li>\n<li>数据库文档数量很大，但是只查询少数的的文档。</li>\n</ul>\n<p>如果很少读，那么尽量不要添加索引，因为索引越多，写操作会越慢。如果读量很大，那么创建索引还是比较划算的。如果写查询量或者update量过大的话，多加索引是会有好处的。</p>\n","categories":["未分类"],"tags":["mongodb"]},{"title":"MongoDB 文档结构","url":"http://fengjianque.github.io/2017/02/06/mongodb-document/","content":"<h2 id=\"mongoDB-文档结构\"><a href=\"#mongoDB-文档结构\" class=\"headerlink\" title=\"mongoDB: 文档结构\"></a>mongoDB: 文档结构</h2><p>项目上使用了Mongodb作为存储数据库，看了mongodb的一些相关书籍和一些网上资料，现进行总结，以防遗忘。</p>\n<p>本文主要介绍文档结构，但本文不会很详细讲mongodb文档的内容，书上已经介绍的很清楚了，而主要介绍的是文档的主要特点，_id的设计原理，mongo使用js，教大家如何查看数据库的document的结构。</p>\n<h3 id=\"关系型数据库vs文档型数据库\"><a href=\"#关系型数据库vs文档型数据库\" class=\"headerlink\" title=\"关系型数据库vs文档型数据库\"></a>关系型数据库vs文档型数据库</h3><p>MongoDB是一种可扩展的高性能的开源的面向文档（document-oriented ）的数据库。</p>\n<ul>\n<li><p>关系数据库比如 MySQL，通常将不同的数据划分为一个个“表”，表的数据是按照“行”来储存的。而关系数据库的“关系”是指通过“外键”将表间或者表内的数据关联起来。每行的属性（列）是固定的，每行都拥有一样的属性。</p>\n</li>\n<li><p>在 MongoDB 中，文档是以 BSON 格式（类似 JSON）储存的，可以支持丰富的层次的结构。MongoDB 中的文档其实是没有模式的，不像 SQL 数据库那样在使用前强制定义一个表的每个字段。这样可以避免对空字段的无谓开销，可以在开发中根据需求增加或者删除字段，灵活设计。在 MongoDB 中，一个数据项叫做Document，一个文档可以嵌入另一个文档，代表一种弱的关联,多个文档组成的集合，就叫Collection。</p>\n</li>\n</ul>\n<p>下面是关系型数据库和文档数据库的结构图。</p>\n<p><img src=\"http://iamsummer-wordpress.stor.sinaapp.com/uploads/2015/01/relation-scheme2.png\" alt=\"\" title=\"关系型数据库\"></p>\n<p><img src=\"http://iamsummer-wordpress.stor.sinaapp.com/uploads/2015/01/norelation-scheme2.png\" alt=\"\" title=\"关系型数据库\"></p>\n<p>上面这两张图很好的说明了关系型数据库和文档型数据库表结构的区别，上面的两张图代表博客、作者、评论、标签的实体以及它们之间的关系。</p>\n<p>在图1中数据关系范式化后，User、Blog、Blog Entry、Tag、Comment各存储为一张表，Blog Entry中分别引用了User、Blog的键作为外键，表示它们之间的关系，而comment引用了User、Blog Entry的键作为外键；Tag引用Blog Entry的键；<br>在图2中有两个collection，User Collection和Blog Collections。Blog Collection中存储了Author字段，根据这个字段可以在User Collection中找到相关的记录，同时，在Comment也存储了Comment By字段，指向User Collection的字段。而Blog Entry、Comment作为内嵌的文档存储同一个collection中。</p>\n<p>关系型数据库和mongodb文档型数据库，有一些概念类似。</p>\n<table>\n<thead>\n<tr>\n<th>RDBMS</th>\n<th>document DB</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Table(表）)</td>\n<td>collection（集合）</td>\n</tr>\n<tr>\n<td>Index(索引)</td>\n<td>Index (索引)</td>\n</tr>\n<tr>\n<td>Join(连接)</td>\n<td>Embedded（内嵌）</td>\n</tr>\n<tr>\n<td>Partition(分区)</td>\n<td>Shard(分片)</td>\n</tr>\n<tr>\n<td>Partition key</td>\n<td>Shard Key</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"id\"><a href=\"#id\" class=\"headerlink\" title=\"_id\"></a>_id</h3><p>在一个特定集合内部，需要唯一的标识文档。因此MongoDB中存储的文档都由一个”_id”键，用于完成此功能。这个键的值可以是任意类型的，默认是ObjectId对象。ObjectId对象的生成思路是本文的主题之一，也是很多分布式系统可以借鉴的思路。</p>\n<p>为了考虑分布式，“_id”要求不同的机器都能用全局唯一的同种方法方便的生成它。因此不能使用自增主键（需要多台服务器进行同步，既费时又费力），下面介绍设计原理。</p>\n<p>ObjectId使用12字节的存储空间，其生成方式如下：</p>\n<table>\n<thead>\n<tr>\n<th>0 1 2 3</th>\n<th>4 5 6</th>\n<th>7 8</th>\n<th>9 10 11</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>时间戳</td>\n<td>机器ID</td>\n<td>PID</td>\n<td>计数器</td>\n</tr>\n</tbody>\n</table>\n<ol>\n<li><p>前四个字节时间戳是从标准纪元开始的时间戳，单位为秒，有如下特性：</p>\n<ul>\n<li>时间戳与后边5个字节一块，保证秒级别的唯一性；</li>\n<li>保证插入顺序大致按时间排序；</li>\n<li>隐含了文档创建时间；</li>\n</ul>\n</li>\n<li><p>机器ID是服务器主机标识，通常是机器主机名的散列值。</p>\n</li>\n<li><p>同一台机器上可以运行多个mongod实例，因此也需要加入进程标识符PID。</p>\n</li>\n<li><p>前9个字节保证了同一秒钟不同机器不同进程产生的ObjectId的唯一性。<br>后三个字节是一个自动增加的计数器（一个mongod进程需要一个全局的计数器），保证同一秒的ObjectId是唯一的。同一秒钟最多允许每个进程拥有（256^3 = 16777216）个不同的ObjectId。</p>\n</li>\n</ol>\n<p>总结一下：时间戳保证秒级唯一，机器ID保证设计时考虑分布式，避免时钟同步，PID保证同一台服务器运行多个mongod实例时的唯一性，最后的计数器保证同一秒内的唯一性（选用几个字节既要考虑存储的经济性，也要考虑并发性能的上限）。</p>\n<p>“_id”既可以在服务器端生成也可以在客户端生成，在客户端生成可以降低服务器端的压力。很多驱动都是在客户端生成后传输到服务端的，mongodb的思想是能在客户端生成的，就不要在服务端做。</p>\n<p><strong>ps</strong>：_id已经包含时间戳信息，记录生成时间可以由此获得。</p>\n<h2 id=\"mongo运行js\"><a href=\"#mongo运行js\" class=\"headerlink\" title=\"mongo运行js\"></a>mongo运行js</h2><p>mongo是一个简化的javascript shell，启动mongo时就可以使用命令操作数据库。mongodb所支持的运行js代码的场景：</p>\n<ul>\n<li><p>–eval参数<br>在启动mongo时使用–eval参数，就可以在运行指定js代码</p>\n<blockquote>\n<p>mongo -u name -p password 127.0.0.1:30000/gacc –eval “printjson(db.getCollectionNames())”</p>\n</blockquote>\n<p>上面的js代码打印gacc数据库的所有collection</p>\n</li>\n<li><p>js文件</p>\n<ul>\n<li><p>连接mongo时，可以将js文件放到后面执行。</p>\n<p>mongo -u name -p password 127.0.0.1:30000/gacc jsfile1.js jsfile2.js</p>\n</li>\n<li><p>或者连接mongo后，用load的命令执行</p>\n<p> load(“scripts/test.js”)<br> load(“/home/gzchenfei/Temp/scriptis/test.js”)<br> load支持相对路径和绝对路径。</p>\n</li>\n</ul>\n</li>\n<li>mapReduce<br>mongodb支持mapReduce框架，而所使用的语法为js的语法。</li>\n<li>$where<br>使用$where查询时，传递js函数和js代码的字符。查询能力很强，但是效率慢，斟酌使用。</li>\n</ul>\n<h2 id=\"利用脚本查看mongodb的文档结构\"><a href=\"#利用脚本查看mongodb的文档结构\" class=\"headerlink\" title=\"利用脚本查看mongodb的文档结构\"></a>利用脚本查看mongodb的文档结构</h2><p>为什么要介绍使用js，目的是为了介绍一个脚本variety.js。<br>当你接手一个用mongodb存数据的项目，没有相关的说明文档，你要了解集合存储的数据结构，你可能会花大量时间跟前同事沟通，而且可能有些文档结构字段了解不全。<br>variety.js这是一个文档分析脚本，可以分析文档的字段组成以及字段的类型；可以分析一个字段在全文档中出现的比例；可以发现不常用的字段；可以发现嵌套的结构对象，以及嵌套的深度。</p>\n<h3 id=\"基本用法\"><a href=\"#基本用法\" class=\"headerlink\" title=\"基本用法\"></a>基本用法</h3><p>命令</p>\n<blockquote>\n<p>mongo -u uutest -p xxxx 127.0.0.1:30000/gacc –eval “var collection = ‘game_info’” variety.js</p>\n</blockquote>\n<p><code>var collection = game_info</code>指定要检索的数据集为game_info，得到结果如下：</p>\n<pre><code>+---------------------------------------------------------------------------+\n| key                    | types         | occurrences | percents           |\n| ---------------------- | ------------- | ----------- | ------------------ |\n| _id                    | ObjectId      | 162         | 100                |\n| icon_url               | String        | 162         | 100                |\n| name                   | String        | 162         | 100                |\n| proc_name              | String        | 162         | 100                |\n| search_key             | String        | 162         | 100                |\n| search_string          | String        | 162         | 100                |\n| type                   | String        | 162         | 100                |\n| updateTime             | Object,Number | 162         | 100                |\n| updateTime.floatApprox | Number        | 161         | 99.38271604938271  |\n| desc                   | String        | 144         | 88.88888888888889  |\n| netbar                 | Number        | 111         | 68.51851851851852  |\n| priority               | Number        | 13          | 8.024691358024691  |\n| forbidden_vpn_type     | String        | 10          | 6.172839506172839  |\n| support_games          | String        | 4           | 2.4691358024691357 |\n| delay_timer            | Number        | 2           | 1.2345679012345678 |\n| default_game_server_id | ObjectId      | 1           | 0.6172839506172839 |\n+---------------------------------------------------------------------------+\n</code></pre><p>上面key这一列代表文档中出现过的字段，type表示字段的类型，occurrences出现的文档次数，percents表示占比。这些数据一目了然，知道哪些字段经常使用，哪些字段不常用，从而对collection的数据结构有个整体的感知。</p>\n<p>variety.js是使用了map reduce的方式分析的，mongodb的map reduce计算框架效率很低，在数据量很大的情况下，等待结果的时间很长，所以最好是设置从副本集中读取。</p>\n<h3 id=\"limit限制\"><a href=\"#limit限制\" class=\"headerlink\" title=\"limit限制\"></a>limit限制</h3><p>如果你对太旧的记录不感兴趣，你还可以使用<code>limit</code>来限制，使用limit表明只分析最新的记录的字段，在整个集合中的分布。</p>\n<blockquote>\n<p>mongo -u uutest -p xxxx 127.0.0.1:30000/gacc –eval “var collection = ‘game_info’, limit=1” variety.js</p>\n</blockquote>\n<pre><code>+----------------------------------------------------------------------+\n| key                    | types    | occurrences | percents           |\n| ---------------------- | -------- | ----------- | ------------------ |\n| _id                    | ObjectId | 162         | 100                |\n| icon_url               | String   | 162         | 100                |\n| name                   | String   | 162         | 100                |\n| proc_name              | String   | 162         | 100                |\n| search_key             | String   | 162         | 100                |\n| search_string          | String   | 162         | 100                |\n| type                   | String   | 162         | 100                |\n| updateTime             | Object   | 162         | 100                |\n| netbar                 | Number   | 111         | 68.51851851851852  |\n+----------------------------------------------------------------------+\n</code></pre><p>上面使用了limit=1进行限制，只分析最新一个记录所有的可以在整个collection中的出现占比。</p>\n<p>###分析嵌入文档<br>variety.js还可以分析嵌套的文档以及深度。<br>在mongodb中插入测试文档</p>\n<blockquote>\n<p>db.test.insert({name:”chris”, embedObject:{a:{b:{c:{d:{e:1}}}}}});</p>\n</blockquote>\n<p>使用variety.js分析结构</p>\n<blockquote>\n<p>mongo -u uutest -p xxx 127.0.0.1:30000/gacc_stat –eval “var collection = ‘test’” variety.js</p>\n</blockquote>\n<p>结果如下:</p>\n<pre><code>+-----------------------------------------------------------+\n| key                   | types    | occurrences | percents |\n| --------------------- | -------- | ----------- | -------- |\n| _id                   | ObjectId | 1           | 100      |\n| embedObject           | Object   | 1           | 100      |\n| embedObject.a         | Object   | 1           | 100      |\n| embedObject.a.b       | Object   | 1           | 100      |\n| embedObject.a.b.c     | Object   | 1           | 100      |\n| embedObject.a.b.c.d   | Object   | 1           | 100      |\n| embedObject.a.b.c.d.e | Number   | 1           | 100      |\n| name                  | String   | 1           | 100      |\n+-----------------------------------------------------------+\n</code></pre><p>分析的深度默认为99层，可以使用maxDepth进行限制。</p>\n<blockquote>\n<p>mongo -u uutest -p xxx 127.0.0.1:30000/gacc_stat –eval “var collection = ‘test’，maxDepth=3” variety.js</p>\n</blockquote>\n<p>上面限制解析深度为3，结果如下：</p>\n<pre><code>+-----------------------------------------------------+\n| key             | types    | occurrences | percents |\n| --------------- | -------- | ----------- | -------- |\n| _id             | ObjectId | 1           | 100      |\n| embedObject     | Object   | 1           | 100      |\n| embedObject.a   | Object   | 1           | 100      |\n| embedObject.a.b | Object   | 1           | 100      |\n| name            | String   | 1           | 100      |\n+-----------------------------------------------------+\n</code></pre><h3 id=\"其他限制条件\"><a href=\"#其他限制条件\" class=\"headerlink\" title=\"其他限制条件\"></a>其他限制条件</h3><p>如果你只对对某部分文档感兴趣，可以使用<code>query</code>限制查询的范围。</p>\n<blockquote>\n<p>mongo -u uutest -p xxx 127.0.0.1:30000/gacc_stat –eval “var collection = ‘game_info’, query={‘netbar’: 0}” variety.js</p>\n</blockquote>\n<p><code>query</code>查询条件，语法跟mongo的js语法一样。</p>\n<p>同样，你还可加入<code>sort={&#39;timestamp&#39;: -1}</code>限制,分析时按照指定的顺序分析每个文档。<br>除了上面的输出格式，限定<code>outputFormat=&#39;json&#39;</code>.结果显示为json格式。</p>\n<p>variety.js源码可以从 <a href=\"https://github.com/variety/variety\" title=\"github\" target=\"_blank\" rel=\"external\">github</a>上下载。</p>\n<h2 id=\"文档一些限定\"><a href=\"#文档一些限定\" class=\"headerlink\" title=\"文档一些限定\"></a>文档一些限定</h2><p> 1.BSON文件的最大限制为 单个文档不超过16MB。</p>\n<p>最大文件大小的限制有助于确保单个文件不会过多的占用内存，在传输过程中,不会占用过多的宽带。当需要存储到MongoDB中的单个文件大小超过了Mongo DB限制的最大文件大小时,MongoDB 提供了另外一套API—Grid FS 。</p>\n<p> 2.深度嵌套BSON 文档</p>\n<p>自Mongo DB 2.2版本更新之后, MongoDB 支持单个文件不超过100的BSON文件嵌套。</p>\n<p>3.命名空间的长度：在每一个命名空间中,包括数据库名，集合名称在内,不得超过123KB。<br>4.mongodb一次接受的消息不得大于48m，如果大于48m,驱动会把内容分成多个48m进行传输。</p>\n","categories":["数据库"],"tags":["mongodb"]},{"title":"使用ImageMagick的python封装库wand处理动态GIF图片","url":"http://fengjianque.github.io/2016/12/30/imagemagick-wand-python/","content":"<h2 id=\"背景\"><a href=\"#背景\" class=\"headerlink\" title=\"背景\"></a>背景</h2><p>动态的GIF图片具有特殊性，对图片的处理缩放、裁剪、加水印，需要一帧帧图片处理。我用过的图片的处理库有PILlow、ImageMagick/GraphicsMagick、Opencv。这些库对动态GIF的支持如下：</p>\n<ul>\n<li>PIllow：支持读取动态GIF图片为单独帧，但是如果动态GIF的的帧使用自己的调色板时，颜色失真很严重，不支持动态GIF保存。</li>\n<li>ImageMagick: 支持动态GIF的读和写，包括解帧合帧。</li>\n<li>GraphicsMagick: 从ImageMagick库fork出来，保留核心功能，针对稳定性、性能进行改进，对GIF支持和ImageMagick一样。</li>\n<li>Opencv: 不支持GIF读写。</li>\n</ul>\n<p>其中wand为ImageMagick的python封装，crop、resize、sample操作可以直接针对整个GIF，其他操作需要针对每一帧处理，然后合成保存。<br>pgmagick为GraphicsMagick的python封装，保留了c的数据类型，用起来稍麻烦，scale操作可以针对GIF，其他也需要解帧处理。</p>\n<p>本文重点介绍wand如何处理GIF。</p>\n<h2 id=\"wand安装\"><a href=\"#wand安装\" class=\"headerlink\" title=\"wand安装\"></a>wand安装</h2><p>wand依赖ImageMagick。</p>\n<p>debian系统，直接安装</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\">apt-get update</div><div class=\"line\">apt-get install libmagickwand-dev</div></pre></td></tr></table></figure>\n<p>然后使用pip安装wand。</p>\n<figure class=\"highlight lsl\"><table><tr><td class=\"code\"><pre><div class=\"line\">pip install wand==<span class=\"number\">0.4</span><span class=\"number\">.4</span></div></pre></td></tr></table></figure>\n<h2 id=\"裁剪crop\"><a href=\"#裁剪crop\" class=\"headerlink\" title=\"裁剪crop\"></a>裁剪crop</h2><p>wand对动态GIF支持裁剪，对所有的帧都生效。</p>\n<p>函数原型：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><div class=\"line\">crop(*args, **kwargs)</div></pre></td></tr></table></figure>\n<p>参数</p>\n<ul>\n<li>left (numbers.Integral) – x-offset of the cropped image. default is 0</li>\n<li>top (numbers.Integral) – y-offset of the cropped image. default is 0</li>\n<li>right (numbers.Integral) – second x-offset of the cropped image. default is the width of the image. this parameter and width parameter are exclusive each other</li>\n<li>bottom (numbers.Integral) – second y-offset of the cropped image. default is the height of the image. this parameter and height parameter are exclusive each other</li>\n<li>width (numbers.Integral) – the width of the cropped image. default is the width of the image. this parameter and right parameter are exclusive each other</li>\n<li>height (numbers.Integral) – the height of the cropped image. default is the height of the image. this parameter and bottom parameter are exclusive each other</li>\n<li>reset_coords (bool) – optional flag. If set, after the rotation, the coordinate frame will be relocated to the upper-left corner of the new image. By default is True.</li>\n<li>gravity (GRAVITY_TYPES) – optional flag. If set, will calculate the top and left attributes. This requires both width and height parameters to be included.</li>\n</ul>\n<p>有两种用法：</p>\n<ul>\n<li>把左上角坐标, 右下角坐标传人; 或者左上角坐标，宽、高传入。</li>\n<li>gravity，和相对于区域起点的偏移x偏移left，y偏移top，要裁剪的height、weight传入。</li>\n</ul>\n<figure class=\"highlight nix\"><table><tr><td class=\"code\"><pre><div class=\"line\">im.crop(<span class=\"attr\">left=crop_left,</span> <span class=\"attr\">top=crop_top,</span> <span class=\"attr\">width=crop_width,</span> <span class=\"attr\">height=crop_height)</span></div><div class=\"line\">im.crop(<span class=\"attr\">left=crop_left,</span> <span class=\"attr\">top=crop_top,</span> <span class=\"attr\">right=crop_right,</span> <span class=\"attr\">bottom=crop_buttom)</span></div><div class=\"line\">im.crop(<span class=\"attr\">left=offset_x,</span> <span class=\"attr\">top=offest_y,</span> <span class=\"attr\">width=crop_width,</span> <span class=\"attr\">height=crop_height,</span> <span class=\"attr\">gravity='center')</span></div></pre></td></tr></table></figure>\n<p>gravity指图片的9宫格的方位，分别有（’north_west’, ‘north’, ‘north_east’, ‘west’, ‘center’, ‘east’, ‘south_west’, ‘south’, ‘south_east’），如果设置这个值，那么起点坐标会重新设置。每个区域的的坐标起点会有所不同，可以看这里<a href=\"http://blog.csdn.net/pzw_0612/article/details/52296910\" target=\"_blank\" rel=\"external\">gravity</a>。</p>\n<h2 id=\"sample-resize\"><a href=\"#sample-resize\" class=\"headerlink\" title=\"sample/resize\"></a>sample/resize</h2><p>wand对动态GIF支持缩放，对所有的帧都生效。</p>\n<figure class=\"highlight stylus\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"title\">resize</span><span class=\"params\">(*args, **kwargs)</span></span></div><div class=\"line\"><span class=\"function\"><span class=\"title\">sample</span><span class=\"params\">(width, height)</span></span>只支持两个参数，比<span class=\"attribute\">resize</span>快，损失一定的质量。</div></pre></td></tr></table></figure>\n<p>参数:</p>\n<ul>\n<li>width (numbers.Integral) – the width in the scaled image. default is the original width</li>\n<li>height (numbers.Integral) – the height in the scaled image. default is the original height</li>\n<li>filter (basestring, numbers.Integral) – a filter type to use for resizing. choose one in FILTER_TYPES. default is ‘undefined’ which means IM will try to guess best one to use</li>\n<li>blur (numbers.Real) – the blur factor where &gt; 1 is blurry, &lt; 1 is sharp. default is 1</li>\n</ul>\n<p>resize还可以带模糊功能，对整个GIF有效。</p>\n<h2 id=\"贴水印\"><a href=\"#贴水印\" class=\"headerlink\" title=\"贴水印\"></a>贴水印</h2><p>除了裁剪，缩放，其他对动态GIF的操作都必须一帧帧处理，然后再合成。<br>wand提供sequence，保存解析出来的图片帧。</p>\n<figure class=\"highlight stylus\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"title\">watermark</span><span class=\"params\">(image, transparency, left, top)</span></span></div></pre></td></tr></table></figure>\n<figure class=\"highlight sqf\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">from</span> wand.<span class=\"built_in\">image</span> import <span class=\"built_in\">Image</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"built_in\">position</span> = (<span class=\"number\">0</span>, <span class=\"number\">0</span>)</div><div class=\"line\">opacity = <span class=\"number\">0.1</span></div><div class=\"line\"><span class=\"keyword\">with</span> <span class=\"built_in\">Image</span>(filename=<span class=\"string\">'test.gif'</span>) as oriImg, \\</div><div class=\"line\">        <span class=\"built_in\">Image</span>(filename=<span class=\"string\">'mark.png'</span>) as mark:</div><div class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"built_in\">in</span> range(len(oriImg.sequence)):</div><div class=\"line\">                <span class=\"keyword\">with</span> oriImg.sequence.index_context(i):</div><div class=\"line\">                    oriImg.watermark(mark, transparency=opacity, left=<span class=\"built_in\">position</span>[<span class=\"number\">0</span>]-oriImg.page[<span class=\"number\">2</span>], top=<span class=\"built_in\">position</span>[<span class=\"number\">1</span>]-oriImg.page[<span class=\"number\">3</span>])</div><div class=\"line\"></div><div class=\"line\">        oriImg.save(filename=<span class=\"string\">'new.gif'</span>)</div></pre></td></tr></table></figure>\n<p>注意这里面需要注意的地方：</p>\n<ul>\n<li>需要使用index_context打开进行帧修改，然后close（这里用with）才生效； 如果用 <code>for frame in oriImg:</code> 需要append到一个新的Image容器修改才生效。</li>\n<li>有些动态GIF不是每一帧大小都一样的，偏移背景的位置也不一样，wand中把这种信息保存在page中，page为四元组，（width, height, left, top）。贴水印的时候要注意转移坐标。</li>\n<li>每打开一个Image，都需要close，否则有内存泄露。</li>\n</ul>\n<p>下面看效果，贴一个coco的图片：<br><img src=\"watermark.gif\" alt=\"\"></p>\n<h2 id=\"贴文字\"><a href=\"#贴文字\" class=\"headerlink\" title=\"贴文字\"></a>贴文字</h2><p>使用caption函数</p>\n<figure class=\"highlight lisp\"><table><tr><td class=\"code\"><pre><div class=\"line\">caption(<span class=\"name\">*args</span>, **kwargs)</div></pre></td></tr></table></figure>\n<p>参数:</p>\n<ul>\n<li>text (basestring) – text to write</li>\n<li>left (numbers.Integral) – x offset in pixels</li>\n<li>top (numbers.Integral) – y offset in pixels</li>\n<li>width (numbers.Integral) – width of caption in pixels. default is width of the image</li>\n<li>height (numbers.Integral) – height of caption in pixels. default is height of the image</li>\n<li>font (wand.font.Font) – font to use. default is font of the image</li>\n<li>gravity (basestring) – text placement gravity. uses the current gravity setting of the image by default</li>\n</ul>\n<p>看下面的代码：</p>\n<figure class=\"highlight vim\"><table><tr><td class=\"code\"><pre><div class=\"line\">wand_font = wand.font.Font(font_path, size=font_size,</div><div class=\"line\">        color=wand.color.Color(font_color), antialias=True,)</div><div class=\"line\"><span class=\"keyword\">w</span>, h = <span class=\"keyword\">im</span>.sequence[<span class=\"number\">0</span>].size <span class=\"keyword\">if</span> <span class=\"keyword\">im</span>.animation <span class=\"keyword\">else</span> <span class=\"keyword\">im</span>.size</div><div class=\"line\">textsize = (<span class=\"number\">100</span>, <span class=\"number\">100</span>)</div><div class=\"line\">with Image(filename=<span class=\"string\">'wizard:'</span>) <span class=\"keyword\">as</span> <span class=\"keyword\">im</span><span class=\"variable\">g:</span></div><div class=\"line\">    from wand.drawing import Drawing</div><div class=\"line\">    with Drawing() <span class=\"keyword\">as</span> contex<span class=\"variable\">t:</span></div><div class=\"line\">        #context.font_family = <span class=\"string\">'monospace'</span></div><div class=\"line\">        context.font_size = font_size</div><div class=\"line\">        context.font = font_path</div><div class=\"line\">        metrics = context.get_font_metrics(img,</div><div class=\"line\">                                           text.encode(<span class=\"string\">'utf8'</span>),</div><div class=\"line\">                                           multiline=False)</div><div class=\"line\">        textsize = (<span class=\"keyword\">int</span>(metrics.text_width), <span class=\"keyword\">int</span>(metrics.text_height))</div><div class=\"line\"></div><div class=\"line\">textpos = get_watermark_position(<span class=\"keyword\">w</span>, h, textsize[<span class=\"number\">0</span>], textsize[<span class=\"number\">1</span>],</div><div class=\"line\">                                      gravity, dx, dy)</div><div class=\"line\"><span class=\"keyword\">for</span> i in <span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(<span class=\"keyword\">im</span>.sequence)):</div><div class=\"line\">    with <span class=\"keyword\">im</span>.sequence.index_context(i):</div><div class=\"line\">        <span class=\"keyword\">im</span>.caption(text, <span class=\"keyword\">int</span>(textpos[<span class=\"number\">0</span>]-<span class=\"keyword\">im</span>.page[<span class=\"number\">2</span>]), <span class=\"keyword\">int</span>(textpos[<span class=\"number\">1</span>]-<span class=\"keyword\">im</span>.page[<span class=\"number\">3</span>]), textsize[<span class=\"number\">0</span>], textsize[<span class=\"number\">1</span>], wand_font)</div><div class=\"line\"><span class=\"keyword\">im</span>.save(<span class=\"keyword\">file</span>=self.fopout.content)</div><div class=\"line\"><span class=\"keyword\">im</span>.<span class=\"keyword\">close</span>()</div></pre></td></tr></table></figure>\n<p>caption函数设计直接传人text，但是我们其实不知道text占用多大， 需要先算出大小，然后调整放置的位置。</p>\n<p>上面的流程：</p>\n<ol>\n<li>创建一个font，包含字体文件路径，字体大小、字体颜色；</li>\n<li>使用Drawing计算font占的大小；</li>\n<li>使用font放置的位置；</li>\n<li>使用caption函数。</li>\n</ol>\n<p>下面看效果， <strong>仗剑天涯</strong> 文字：</p>\n<p><img src=\"textmark.gif\" alt=\"\"></p>\n","categories":["未分类"],"tags":[]},{"title":"git管理公共库","url":"http://fengjianque.github.io/2016/12/30/git-subtree/","content":"<h2 id=\"场景\"><a href=\"#场景\" class=\"headerlink\" title=\"场景\"></a><strong>场景</strong></h2><p>我们用git管理项目时经常会遇到这样的场景。</p>\n<ul>\n<li>场景一：一个项目A仓库要引用另外的公共项目仓库作为一个子目录，比如是公共的lib库。要求引用lib仓库后， 项目A也是个完整仓库，在项目A中对lib项目所做的修改除了能push到A仓库中，也能push到lib仓库中；同时lib仓库更新后，A仓库也能获取lib的修改更新。</li>\n<li>场景二：项目B变的很庞大臃肿，这时候你会想把其中一些目录分离独立成仓库管理，要求保留所有的更改历史和记录。</li>\n</ul>\n<p>怎么做呢，git subtree登场了。</p>\n<h2 id=\"subtree和submodule\"><a href=\"#subtree和submodule\" class=\"headerlink\" title=\"subtree和submodule\"></a><strong>subtree和submodule</strong></h2><p>在subtree出现之前，有个能达到相似的功能的命令submodule。git submodule用来项目切分和规划功能，使用起来复杂同时又是最具有迷惑性和破坏性。git submodule的实现原理，就是在本地保存一个 .gitsubmodules的文件，里面记录着子模块的信息。在进行git各项操作时，要相当注意区分主仓库和子仓库，不然很容易出问题。使用起来有很多的坑，门槛相对要高。<br>其中一篇诉说不用submodule的文章：<br><a href=\"https://codingkilledthecat.wordpress.com/2012/04/28/why-your-company-shouldnt-use-git-submodules/\" target=\"_blank\" rel=\"external\">https://codingkilledthecat.wordpress.com/2012/04/28/why-your-company-shouldnt-use-git-submodules/</a><br>我认为用git submodule的好处就是主仓库和子仓库分离的比较清楚。<br>介绍使用submodule我认为比较好教程<br><a href=\"http://www.open-open.com/lib/view/open1396404725356.html\" target=\"_blank\" rel=\"external\">http://www.open-open.com/lib/view/open1396404725356.html</a><br><a href=\"http://www.kafeitu.me/git/2012/03/27/git-submodule.html\" target=\"_blank\" rel=\"external\">http://www.kafeitu.me/git/2012/03/27/git-submodule.html</a><br><a href=\"http://git-reference.readthedocs.org/zh_CN/latest/Git-Tools/Submodules/\" target=\"_blank\" rel=\"external\">http://git-reference.readthedocs.org/zh_CN/latest/Git-Tools/Submodules/</a><br>subtree 早前是作为独立的开源项目独立存在的，后来被git收编成为官方的一部分。<strong>subtree子命令很晚才集成到git中，请确保你的git版本（使用git –version查看） &gt; v1.8.0.0</strong>。subtree的实现方式并非包装了submodule的一系列操作序列，而是截然不同的另一种管理模型。 subtree是没有.gitsubmodule，通过改变分支指针的形式进行分离和合拼项目，相对对submodule方便不少。<br>官方推荐使用subtree代替submodule。<br>废话少说，下面就用subtree来开搞。</p>\n<h2 id=\"1-引用外部仓库\"><a href=\"#1-引用外部仓库\" class=\"headerlink\" title=\"1 引用外部仓库\"></a><strong>1 引用外部仓库</strong></h2><h3 id=\"1-1-准备工作\"><a href=\"#1-1-准备工作\" class=\"headerlink\" title=\"1.1 准备工作\"></a><strong>1.1 准备工作</strong></h3><p>在github上建立两个仓库。</p>\n<ol>\n<li>wrapper：git@github.com:iamsummer/wrapper.git</li>\n<li>commonlib：git@github.com:iamsummer/commonlib.git</li>\n</ol>\n<p>commonlib仓库是公共仓库， wrapper仓库需要导入commonlib仓库。</p>\n<h3 id=\"1-2-相关命令和操作\"><a href=\"#1-2-相关命令和操作\" class=\"headerlink\" title=\"1.2 相关命令和操作\"></a><strong>1.2 相关命令和操作</strong></h3><h4 id=\"1-2-1-创建指向commonlib的远程仓库地址-并创建与之关联的子目录\"><a href=\"#1-2-1-创建指向commonlib的远程仓库地址-并创建与之关联的子目录\" class=\"headerlink\" title=\"1.2.1 创建指向commonlib的远程仓库地址, 并创建与之关联的子目录\"></a><strong>1.2.1 创建指向commonlib的远程仓库地址, 并创建与之关联的子目录</strong></h4><p>需要用到两条命令</p>\n<blockquote>\n<p>git remote add [–f] &lt; remote_name &gt; &lt; repository_url &gt;</p>\n</blockquote>\n<p>如果添加-f表示在添加远程仓库后，执行fetch操作。</p>\n<blockquote>\n<p>git subtree add –prefix={子目录名} &lt;子仓库名&gt; &lt;子仓库对应分支&gt; [–squash]</p>\n</blockquote>\n<p>–prefix表示目录名， 运行该命令之后会创建一个目录，并将子仓库拷贝到该目录。 这个命令如果没有–squash，默认是将子仓库所有的历史修改log都保留下来的，如果不想保留，可以在该命令后面添加–squash参数。 –squash表示将子仓库所有改动log合并成一次commit。</p>\n<p>下面执行这两条命令：</p>\n<pre><code>git clone git@github.com:iamsummer/wrapper.git\ncd wrapper\ngit remote add -f commonlib git@github.com:iamsummer/commonlib.git\n</code></pre><p>执行git branch -a 和 git remote -v 可以看到远程仓库已经添加commonlib远程仓库。</p>\n<p><img src=\"http://iamsummer-wordpress.stor.sinaapp.com/uploads/2014/12/remote-add.png\" alt=\"\" title=\"remote-add\"></p>\n<p>执行</p>\n<pre><code>git subtree add -prefix=lib commonlib master\n</code></pre><p>执行完后，会发现在当前目录下创建了lib目录，这就是子仓库。 分别执行gitk 和 git log –graph，得到下图</p>\n<p><img src=\"http://iamsummer-wordpress.stor.sinaapp.com/uploads/2014/12/subtree-add.png\" alt=\"\" title=\"subtree-add\"><br><img src=\"http://iamsummer-wordpress.stor.sinaapp.com/uploads/2014/12/subtree-info.png\" alt=\"\" title=\"subtree-info\"></p>\n<p>从上图中可以看到子仓库和主仓库合并，而且可以清晰的看到子仓库作为一个分支合并过来了，并保存在lib子目录中。<br>这时候我们想把改动push到wrapper远程仓库，看看是否会把子仓库更新上去。</p>\n<pre><code>git push origin master\n</code></pre><p>你会发现lib目录push到远程的wrapper仓库了，也就是说wrapper仓库与一般的git仓库无异。 是的，无论你编辑wrapper原来的文件还是子目录lib里面文件，正常提交即可，跟脱离了远程子仓库一样。 但如果你要把lib目录的更改push到远程的子仓库，或者把远程子仓库的更新pull下来，还需要几步简单的操作。</p>\n<h4 id=\"1-2-2-从远程的子仓库获取更新到子目录中\"><a href=\"#1-2-2-从远程的子仓库获取更新到子目录中\" class=\"headerlink\" title=\"1.2.2 从远程的子仓库获取更新到子目录中\"></a><strong>1.2.2 从远程的子仓库获取更新到子目录中</strong></h4><p>命令：</p>\n<blockquote>\n<p>git subtree pull –prefix={子目录路径} &lt;远程仓库名&gt; <branch> [–squash]<br>–squash参数同上面说的一样，带–squash表示将子仓库所有改动log合并成一次commit，否则保留子仓库改动历史。</branch></p>\n</blockquote>\n<p>我们先在远程仓库commonlib中做些修改并提交，然后我们用上面的命令来执行，看看wrapper下面的子仓库的更新效果。</p>\n<pre><code>git subtree pull --prefix=lib commonlib master\n</code></pre><p>执行完后执行gitk， git log –graph看分支变化。</p>\n<p><img src=\"http://iamsummer-wordpress.stor.sinaapp.com/uploads/2014/12/subtree-pull.png\" alt=\"\" title=\"subtree-pull\"><br><img src=\"http://iamsummer-wordpress.stor.sinaapp.com/uploads/2014/12/subtree-pull-2.png\" alt=\"\" title=\"subtree-pull-2\"></p>\n<p>从图上发现，子仓库一直作为一个分支存在的，子仓库更新会在子仓库分支上移动，最后跟wrapper的master分支进行合并，回归wrapper的分支。</p>\n<h4 id=\"1-2-3-从子目录push到远程的仓库\"><a href=\"#1-2-3-从子目录push到远程的仓库\" class=\"headerlink\" title=\"1.2.3 从子目录push到远程的仓库\"></a><strong>1.2.3 从子目录push到远程的仓库</strong></h4><p>需要命令</p>\n<blockquote>\n<p>git subtree push –prefix={path/to/subdir} <remote_name> <branch></branch></remote_name></p>\n</blockquote>\n<p>我们现在wrapper下面修改子目录lib里面的文件，并commit。然后运行上面命令</p>\n<blockquote>\n<p>git subtree push –prefix=lib commonlib master</p>\n</blockquote>\n<p>使用gitk或者git log –graph查看分支变化， 你会发现子仓库的分支并没有变化。 而且commonlib的远程仓库push成功。</p>\n<p>到这里，你应该已经明白git subtree是如何pull和push了，可以方便使用你的公有库了。</p>\n<h3 id=\"1-3-恢复子仓库信息\"><a href=\"#1-3-恢复子仓库信息\" class=\"headerlink\" title=\"1.3 恢复子仓库信息\"></a><strong>1.3 恢复子仓库信息</strong></h3><p>如果别人clone你包含子仓库的wrapper库后，怎么恢复子仓库信息，以便继续同步更新远程的子仓库？ 执行下面的操作：</p>\n<pre><code>git clone  git@github.com:iamsummer/wrapper.git\ncd wrapper\ngit pull -s subtree commonlib master 或者直接 git subtree pull --prefix=lib commonlib master\n</code></pre><p>执行完后，你会发现即使子仓库没有更新，子树和wrapper仓库还是做了一次合并的commit。<br>-s subtree是指采用subtree的合并策略。关于subtree的合并策略解释有</p>\n<blockquote>\n<p>subtree This is a modified recursive strategy. When merging trees A and B, if B corresponds to a subtree of A, B is first adjusted to match the tree structure of A, instead of reading the trees at the same level. This adjustment is also done to the common ancestor tree.</p>\n</blockquote>\n<p>然后你就可以愉快的和远程的子仓库交互啦。</p>\n<h2 id=\"2-分离子目录成独立仓库\"><a href=\"#2-分离子目录成独立仓库\" class=\"headerlink\" title=\"2 分离子目录成独立仓库\"></a><strong>2 分离子目录成独立仓库</strong></h2><p>在原先是一个完整的仓库下，随着项目的不断积累和扩张，会变的臃肿和庞大，你可能会有单独管理子目录的需求。 下面介绍如何分离git仓库。<br>准备一个要分离的仓库，parent仓库，下面有son和daughter这个子目录。现在要把son目录分离出去。</p>\n<p>git clone git@github.com:iamsummer/parent.git</p>\n<p>clone后，现在我们来操作。</p>\n<h3 id=\"2-1-在本地创建一个子分支\"><a href=\"#2-1-在本地创建一个子分支\" class=\"headerlink\" title=\"2.1 在本地创建一个子分支\"></a><strong>2.1 在本地创建一个子分支</strong></h3><p>需要命令</p>\n<blockquote>\n<p>git subtree split –prefix=<name-of-folder> –branch <name-of-new-branch> # 将需要分离的目录的提交日志分离到一个独立的分支上</name-of-new-branch></name-of-folder></p>\n</blockquote>\n<p>执行</p>\n<pre><code>cd parent\ngit subtree split --prefix=son --branch son #将本地的son目录提交日志分离创建son子分支。\n</code></pre><p>使用git branch查看，发现有son分支存在。 使用gitk或者git log –graph并没发现创建新的子分支。切换到son分支，git log查看提交，你会发现只有跟son目录相关的提交记录。 是的,son的提交历史已经剥离了，但是没影响到现有的分支。</p>\n<h3 id=\"2-2-在本地创建一个repo用于存储上面分离的branch\"><a href=\"#2-2-在本地创建一个repo用于存储上面分离的branch\" class=\"headerlink\" title=\"2.2 在本地创建一个repo用于存储上面分离的branch\"></a><strong>2.2 在本地创建一个repo用于存储上面分离的branch</strong></h3><pre><code>cd 到parent目录外\nmkdir son\ncd son\ngit init\ngit pull ../parent son #git pull &lt;/path/to/big-repo&gt; &lt;name-of-new-branch&gt;\n</code></pre><p>执行完后，son目录的内容就是parent子目录son的内容，git log得到的log只是跟son目录相关的提交记录。</p>\n<h3 id=\"2-3-推送本地repo到远程的仓库\"><a href=\"#2-3-推送本地repo到远程的仓库\" class=\"headerlink\" title=\"2.3 推送本地repo到远程的仓库\"></a><strong>2.3 推送本地repo到远程的仓库</strong></h3><p>在github上创建一个远程仓库son： git@github.com:iamsummer/son.git</p>\n<p>执行</p>\n<pre><code>git remote add origin git@github.com:iamsummer/son.git\ngit push origin -u master\n</code></pre><p>子目录已经作为一个仓库push到远程。</p>\n<h3 id=\"2-4-清理目录\"><a href=\"#2-4-清理目录\" class=\"headerlink\" title=\"2.4 清理目录\"></a><strong>2.4 清理目录</strong></h3><p>如果原仓库parent要保留son目录，这步可以不做。 这一步可以有两种方式：</p>\n<ul>\n<li>①直接删除son目录，然后提交，保留son的历史log。</li>\n<li>②彻底删除son目录，包括历史log。 使用命令：<blockquote>\n<p>git filter-branch -f –index-filter “git rm -r -f -q –cached &gt; –ignore-unmatch <strong>son</strong>“ –prune-empty HEAD 注意上面的son， son是要删除的目录。这个命令会rewrite历史，请谨慎使用。</p>\n</blockquote>\n</li>\n</ul>\n<h3 id=\"2-5-将分离的目录作为一个子仓库\"><a href=\"#2-5-将分离的目录作为一个子仓库\" class=\"headerlink\" title=\"2.5 将分离的目录作为一个子仓库\"></a><strong>2.5 将分离的目录作为一个子仓库</strong></h3><p>如果parent已经分离出去的son目录还想以子仓库的形式进行管理。 需要执行上面的清理目录，然后执行下面步骤：</p>\n<pre><code>git remote add son git@github.com:iamsummer/son.git\ngit subtree add --prefix=son son master\n</code></pre><p>结果如下图：</p>\n<p><img src=\"http://iamsummer-wordpress.stor.sinaapp.com/uploads/2014/12/split-add.png\" alt=\"\" title=\"split-add\"><br><img src=\"http://iamsummer-wordpress.stor.sinaapp.com/uploads/2014/12/split-pull1.png\" alt=\"\" title=\"split-pull\"></p>\n<p>可以看到远程的son进行一次合并的commit。值的注意的是在分离son之前，如果son目录下面的修改提交跟其他修改是一并提交的，在分离son时，会自动的进行一次commit，也就像上图看到一样，commit的版本不一样。 以后要更新son子仓库，就可以使用上面介绍的方法啦。</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a><strong>总结</strong></h2><p>对项目进行拆分与合并，在项目管理中是很常见的，上面介绍的都是本人亲测可行的方案。同时欢迎大家对于不对之处，多提出意见。</p>\n<h2 id=\"参考文档\"><a href=\"#参考文档\" class=\"headerlink\" title=\"参考文档\"></a><strong>参考文档</strong></h2><p><a href=\"http://git-reference.readthedocs.org/zh_CN/latest/Git-Tools/Subtree-Merging/\" target=\"_blank\" rel=\"external\">http://git-reference.readthedocs.org/zh_CN/latest/Git-Tools/Subtree-Merging/</a><br><a href=\"http://blog.nwcadence.com/git-subtrees/\" target=\"_blank\" rel=\"external\">http://blog.nwcadence.com/git-subtrees/</a><br><a href=\"http://manpages.ubuntu.com/manpages/utopic/man1/git-subtree.1.html\" target=\"_blank\" rel=\"external\">http://manpages.ubuntu.com/manpages/utopic/man1/git-subtree.1.html</a></p>\n","categories":[],"tags":[]},{"title":"Maven知识","url":"http://fengjianque.github.io/2016/12/30/maven-learn/","content":"<h1 id=\"初识Maven\"><a href=\"#初识Maven\" class=\"headerlink\" title=\"初识Maven\"></a>初识Maven</h1><p>Maven抽象了一个完整的项目构建生命周期模型，这个模型吸取了大量优秀的构建脚本和构建工具的优点，总结了大量项目的实际需求。简单来说就是，Maven是基于约定的，遵循这些约定，可以直接使用大量成熟的Maven插件完成我们的任务。Maven能够帮我们自动化构建过程，从清理、编译、测试到生成报告、再到打包和部署。Maven还可以自动帮我们管理依赖，如python中的pipe工具。</p>\n<h2 id=\"Maven安装和配置\"><a href=\"#Maven安装和配置\" class=\"headerlink\" title=\"Maven安装和配置\"></a>Maven安装和配置</h2><p>在官网上下载Maven，并配置系统环境变量，网上很多，此处不多叙述。</p>\n<p>官网教程：<a href=\"http://maven.apache.org/download.cgi\" target=\"_blank\" rel=\"external\">http://maven.apache.org/download.cgi</a></p>\n<p>与eclipse的集成，安装m2eclipse插件。 <a href=\"http://blog.rockcms.com/archives/145\" target=\"_blank\" rel=\"external\">http://blog.rockcms.com/archives/145</a></p>\n<hr>\n<p>我们以项目为入口，逐步认识Maven的工作。</p>\n<h2 id=\"1-1-创建项目\"><a href=\"#1-1-创建项目\" class=\"headerlink\" title=\"1.1 创建项目\"></a>1.1 创建项目</h2><p>我们要做的第一步是建立一个 Maven 项目。在命令行中执行下面的命令来建立我们的 hello world 项目。</p>\n<blockquote>\n<p>mvn archetype:generate -DgroupId=com.netease.helloworld -DartifactId=helloworld -Dversion=1.0-SNAPSHOT</p>\n</blockquote>\n<p>archetype:generate 目标会列出一系列的 archetype 让你选择。 Archetype 可以理解成项目的模型。 Maven 为我们提供了很多种的项目模型，包括从简单的 Swing 到复杂的 Web 应用。其它参数我们待会解释，这时候我们看一下 maven 给我们建立的文件目录结构：</p>\n<p><img src=\"maven-dir.png\" alt=\"enter image description here\"></p>\n<p>Maven 使用约定优于配置的原则 。它要求在没有定制之前，所有的项目都有如下的结构：</p>\n<table>\n<thead>\n<tr>\n<th>目录</th>\n<th>目的</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>${basedir}</td>\n<td>存放 pom.xml 和所有的子目录</td>\n</tr>\n<tr>\n<td>${basedir}/src/main/java</td>\n<td>项目的 java源代码</td>\n</tr>\n<tr>\n<td>${basedir}/src/main/resources</td>\n<td>项目的资源，比如说 property文件</td>\n</tr>\n<tr>\n<td>${basedir}/src/test/java</td>\n<td>项目的测试类，比如说 JUnit代码</td>\n</tr>\n<tr>\n<td>${basedir}/src/test/resources</td>\n<td>测试使用的资源，放在此目录下</td>\n</tr>\n</tbody>\n</table>\n<p>一个 maven 项目在默认情况下会产生 JAR 文件，另外 ，运行mvn install后的 classes 会放在 ${basedir}/target/classes 下面， JAR 文件会放在 ${basedir}/target 下面。如上图的helloworld-0.0.1-SNASHORT.jar就是生成的包。</p>\n<p>这个基本上就是项目的默认整个框架，使用这些默认行为会让你少做很多的事情。</p>\n<h2 id=\"1-2-pom文件\"><a href=\"#1-2-pom文件\" class=\"headerlink\" title=\"1.2 pom文件\"></a>1.2 pom文件</h2><p>Maven项目中最重要的文件，一个项目所有的配置都放置在 POM 文件中：定义项目的类型、名字，管理依赖关系，定制插件的行为。学习maven，就是要掌握pom文件的写法。pom和ant的build文件一样。 下面是helloworld项目创建时产生的简单pom文件。</p>\n<p><img src=\"hello-pom.png\" alt=\"enter image description here\"></p>\n<p>这里面有两个比较重要的概念，坐标和依赖。</p>\n<h3 id=\"1-2-1-坐标\"><a href=\"#1-2-1-坐标\" class=\"headerlink\" title=\"1.2.1 坐标\"></a>1.2.1 坐标</h3><p>Maven的一大功能是管理项目依赖，为了能自动化的解析任何一个Java 构件，maven就必须将它们唯一标识，这就得依赖管理的底层基础—-坐标。 maven定义了这样组规则：仓库中任何一个构件都可以使用Maven坐标唯一标识，maven坐标元素包括groupId、artifactId、version、packaging、classifier。现在，只要我们提供正确的坐标元素，maven就能找到对应的组件。 maven就会从仓库中寻找相应的构件供我们使用。 在我们创建helloworld项目时，我们是不是还带了参数， 猜对了，这个参数就是坐标，用于唯一的标记一个项目</p>\n<blockquote>\n<p>-DgroupId=com.netease.helloworld -DartifactId=helloworld -Dversion=1.0-SNAPSHOT</p>\n</blockquote>\n<p>回归helloworld的pom文件，介绍各个元素的含义：</p>\n<ul>\n<li><p><strong>groupId</strong>：定义当前maven项目隶属的实际目录。groupId的表示方式与Java包名的表示方式类似，通常与域名反向一一对应。</p>\n</li>\n<li><p><strong>artifactId</strong>：该元素定义实际项目中的一个Maven项目（模块），推荐的做法是使用实际项目名称作为前缀。</p>\n</li>\n<li><p><strong>version</strong>：该元素定义Maven项目当前所处版本。</p>\n</li>\n<li><p><strong>packaging</strong>：该元素定义Maven项目的打包方式，默认是打成jar包。</p>\n</li>\n<li><p><strong>classifier</strong>：该元素用来帮助定义构建输出的一些附属构件。附属构件与主构件对应，如有一个的主构件是nexus-indexer-2.0.0.jar，该项目可能会通过使用一些插件生成如nexus-indexer-2.0.0-javadoc.jar、nexus-indexer-2.0.0-sources.jar这样一些附属构件。</p>\n</li>\n</ul>\n<p>上述五个元素中，groupId、artifactId、version是必须定义的，packaging是可选的（默认为jar），而classifier是通过相应的插件生成的。</p>\n<h3 id=\"1-2-2-仓库\"><a href=\"#1-2-2-仓库\" class=\"headerlink\" title=\"1.2.2 仓库\"></a>1.2.2 仓库</h3><p>了解依赖之前，先来了解一下Maven的仓库概念。 仓库主要用于获取工程依赖的其他工程的生成构件，也可用来部署（deploy）Maven工程的生成构件。 仓库存放的是包括各种生成的包以及pom文件。 如果有必要，一个工程可以部署到多个仓库。 仓库可以分为本地库（local）和远程库（remote）。本地库通常位于本机~/.m2/repository文件夹， 远程库最常见的是maven中央库（<a href=\"http://repository.jboss.com/maven2/\" target=\"_blank\" rel=\"external\">http://repository.jboss.com/maven2/</a>），此外也会有一些自己搭建私服库，比如nexus库用于企业内部。</p>\n<p><img src=\"repo.png\" alt=\"enter image description here\"></p>\n<p>在运行Maven的时，Maven所需要的依赖构件都是直接从本地仓库获取的，如果本地仓库有依赖构建，直接使用；如果本地仓库没有，它会首先尝试从远程仓库下载构件至本地仓库，然后再使用本地仓库的构件。</p>\n<h3 id=\"1-2-3-依赖\"><a href=\"#1-2-3-依赖\" class=\"headerlink\" title=\"1.2.3 依赖\"></a>1.2.3 依赖</h3><p>一个复杂的项目将会包含很多依赖，也有可能包含依赖于其它构件的依赖。这是Maven最强大的特征之一，它支持了传递性依赖（transitive dependencies）。假如你的项目依赖于一个库，而这个库又依赖于五个或者十个其它的库（就像Spring或者Hibernate那样）。你不必找出所有这些依赖然后把它们写在你的pom.xml里，你只需要加上你直接依赖的那些库，Maven会隐式的把这些库间接依赖的库也加入到你的项目中。Maven也会处理这些依赖中的冲突，同时能让你自定义默认行为，或者排除一些特定的传递性依赖。 回到helloword的例子，pom文件配置了以下的依赖  </p>\n<pre><code>&lt;dependencies&gt;\n  &lt;dependency&gt;\n        &lt;groupId&gt;junit&lt;/groupId&gt;\n       &lt;artifactId&gt;junit&lt;/artifactId&gt;\n       &lt;version&gt;3.8.1&lt;/version&gt;\n       &lt;scope&gt;test&lt;/scope&gt;\n   &lt;/dependency&gt;\n &lt;/dependencies&gt;\n</code></pre><p>通过配置这样依赖Maven在构建过程中就能根据坐标groupId=junit;artifactId=junit;version=3.8.1;在本地仓库或者远程仓库中找到这个依赖。 我们还看到了scope标签，我们来看有哪些值 scope依赖的范围有：</p>\n<ul>\n<li><p>compile  compile是默认的范围；如果没有提供一个范围，那该依赖的范围就是编译范围。编译范围依赖在所有的classpath 中可用，同时它们也会被打包。  </p>\n</li>\n<li><p>provided  provided 依赖只有在当JDK 或者一个容器已提供该依赖之后才使用。例如， 如果你开发了一个web 应用，你可能在编译 classpath 中需要可用的Servlet API 来编译一个servlet，但是你不会想要在打包好的WAR 中包含这个Servlet API；这个Servlet API JAR 由你的应用服务器或者servlet 容器提供。已提供范围的依赖在编译classpath （不是运行时）可用。它们不是传递性的，也不会被打包。</p>\n</li>\n<li><p>runtime  runtime 依赖在运行和测试系统的时候需要，但在编译的时候不需要。比如，你可能在编译的时候只需要JDBC API JAR，而只有在运行的时候才需要JDBC驱动实现。</p>\n</li>\n<li><p>test  仅仅为test的用的，你肯定一下子就能想到junit。test范围依赖在一般的编译和运行时都不需要，它们只有在测试编译和测试运行阶段可用。  </p>\n</li>\n<li><p>system  如果你有一些包你自己的系统里有，你不想让maven从repository里面下载，你可以用这个选项。 你必须显式的提供一个对于本地系统中JAR 文件的路径</p>\n<pre><code>&lt;dependency&gt;\n   &lt;groupId&gt;com.google.code.gson&lt;/groupId&gt;\n   &lt;artifactId&gt;gson&lt;/artifactId&gt;\n   &lt;version&gt;2.3&lt;/version&gt;      \n   &lt;scope&gt;system&lt;/scope&gt;        \n   &lt;systemPath&gt;E:/lib/gson.jar&lt;/systemPath&gt;      \n&lt;/dependency&gt; \n</code></pre></li>\n</ul>\n<p>scope默认配置是compile。</p>\n<p>Maven在遇到依赖传递，依赖冲突，依赖重复时有一套解决方案，详情请看 <a href=\"http://maven.apache.org/guides/introduction/introduction-to-dependency-mechanism.html\" target=\"_blank\" rel=\"external\">http://maven.apache.org/guides/introduction/introduction-to-dependency-mechanism.html</a></p>\n<p>到这一步，其实已经可以顺利使用maven来构建项目了，只要你遵守了maven的默认约定，你所需要做的就是把项目中依赖的包，都按格式写在<dependency>元素里面，依赖的包可以在下面的网站中搜索 <a href=\"http://search.maven.org/\" target=\"_blank\" rel=\"external\">http://search.maven.org/</a> ，最后运行mvn package 或者 mvn install等，可以运行测试用例，打包项目。</dependency></p>\n<h2 id=\"2-Maven生命周期和插件\"><a href=\"#2-Maven生命周期和插件\" class=\"headerlink\" title=\"2 Maven生命周期和插件\"></a>2 Maven生命周期和插件</h2><p>经过第一章，虽然可以构建项目，但是大家肯定觉的迷糊，Maven如何工作，如果项目不按照默认约定，想加入更多的功能，应该如何配置pom。 这章来解答这个问题。</p>\n<h3 id=\"2-1-Maven生命周期\"><a href=\"#2-1-Maven生命周期\" class=\"headerlink\" title=\"2.1 Maven生命周期\"></a>2.1 Maven生命周期</h3><p>maven将工程（Project）的构建过程理解为不同的生命周期(LifeCycle)和阶段（Phase）。 生命周期互相独立，之间也没有一定的顺序关系。 每个生命周期又划分为不同的阶段（Phase）。阶段之间有明确的顺序关系， 同一生命周期内的阶段必须按顺序依次执行。 maven内置了三个生命周期， 分别是clean、default和site。clean生命周期主要是做项目清理的，default生命周期是用来项目构建的；site生命周期是用来建立项目的文档和站点生成 。</p>\n<p>maven生命周期和生命阶段如下图所示：</p>\n<p><img src=\"lifecycle.png\" alt=\"enter image description here\"></p>\n<p>clean、default和site生命周期互相独立，之间也没有一定的顺序关系。生命周期中阶段之间有明确的先后依赖顺序关系， 同一生命周期内的阶段必须按顺序依次执行。 从命令行执行Maven任务的主要方式是调用Maven的生命周期阶段。比如说在命令行执行了</p>\n<ul>\n<li>mvn clean 就是指定执行到clean周期的clean阶段。也就是说实际执行了pre-clean阶段与clean两个阶段。</li>\n<li>mvn install 就是执行了default生命周期中，validate-&gt;install之间的阶段。</li>\n<li>mvn clean deploy site-deploy 这个就是执行了clean周期的前两个阶段、default周期的所有阶段、site周期的所有阶段</li>\n</ul>\n<p>更详细的phase说明参考： <a href=\"http://maven.apache.org/guides/introduction/introduction-to-the-lifecycle.html#Lifecycle_Reference\" target=\"_blank\" rel=\"external\">http://maven.apache.org/guides/introduction/introduction-to-the-lifecycle.html#Lifecycle_Reference</a></p>\n<h2 id=\"2-2-Maven插件\"><a href=\"#2-2-Maven插件\" class=\"headerlink\" title=\"2.2 Maven插件\"></a>2.2 Maven插件</h2><p>项目生命周期是一个抽象的概念，这个概念性的东西意味着它并不做任何实质性的事情，也就是说：它就像接口，只定义规范，具体细节它不管。也就是说，Maven不知道怎么样编译或者怎么样打包。那谁来执行项目生命周期的各个阶段呢，答案是插件。Maven功能具体的实现细节则交给了Maven的各个丰富的插件。所以 Maven 核心的分发包只有不到 3MB，Maven 会在需要的时候下载并使用插件。Maven 通过插件动作完成大多数构建任务。可以把 Maven 引擎认为是插件动作的协调器。</p>\n<h3 id=\"2-2-1-插件目标\"><a href=\"#2-2-1-插件目标\" class=\"headerlink\" title=\"2.2.1 插件目标\"></a>2.2.1 插件目标</h3><p>Maven的功能依赖于各种插件， 对于插件本身，为了能够复用代码，其实可以干好几件事情，每件事情又有个名字叫做目标。一个目标就是实现maven一个功能。一个插件就是一组插件目标的集合。</p>\n<p><img src=\"goal.png\" alt=\"enter image description here\"></p>\n<p>所以其实运行Maven任务就是运行插件的目标。</p>\n<h3 id=\"2-2-2生命周期与插件的绑定\"><a href=\"#2-2-2生命周期与插件的绑定\" class=\"headerlink\" title=\"2.2.2生命周期与插件的绑定\"></a>2.2.2生命周期与插件的绑定</h3><p>插件的目标goal不一定都与生命周期绑定，但Maven的生命周期是与插件goal绑定的，不然谁来帮Maven干活，这里也不是说每个生命周期的阶段都需要绑定插件目标，而是在某个阶段如果要实现功能任务，则必须与插件目标绑定。</p>\n<p>(1)内置绑定</p>\n<p>为了让用户不用任何配置就能进行一般程度的项目构建，Maven默认给自己生命周期的核心阶段绑定了默认的插件。例如Maven默认将maven-compiler-plugin的compile目标与compile生命周期阶段绑定，因此命令mvn compile实际上是先定位到compile这一生命周期阶段，然后再根据绑定关系调用maven-compiler-plugin的compile目标。 插件目标（goal）可以附着在生命周期阶段上，Maven在运行每个phase时，maven会看环境（即pom.xml）中配置了哪些插件，然后会运行它，完成构建任务！</p>\n<p>各个生命周期默认的内置绑定如下：</p>\n<ul>\n<li>clean 生命周期阶段与插件目标的绑定关系</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>生命周期阶段</th>\n<th>插件目标</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>pre-clean</td>\n<td></td>\n</tr>\n<tr>\n<td>clean</td>\n<td>maven-clean-plugin:clean</td>\n</tr>\n<tr>\n<td>post-clean</td>\n</tr>\n</tbody>\n</table>\n<ul>\n<li>site 生命周期阶段与插件目标的绑定关系</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>生命周期阶段</th>\n<th>插件目标</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>pre-site</td>\n<td></td>\n</tr>\n<tr>\n<td>site</td>\n<td>maven-site-plugin:site</td>\n</tr>\n<tr>\n<td>post-site</td>\n<td></td>\n</tr>\n<tr>\n<td>site-deploy</td>\n<td>maven-site-plugin:deploy</td>\n</tr>\n</tbody>\n</table>\n<ul>\n<li>default 生命周期阶段与插件目标的绑定关系 由于项目的打包类型会影响构建的具体过程，因此，default生命周期阶段与插件目标的绑定关系，由项目打包类型决定。例如：最常见的jar类型生命周期的内置插件绑定关系</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>生命周期阶段</th>\n<th>插件目标</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>process-resources</td>\n<td>maven-resources-plugin:resources</td>\n</tr>\n<tr>\n<td>compile</td>\n<td>maven-compiler-plugin:compile</td>\n</tr>\n<tr>\n<td>process-test-resources</td>\n<td>maven-resources-plugin:testResources</td>\n</tr>\n<tr>\n<td>test-compile</td>\n<td>maven-compiler-plugin:testCompile</td>\n</tr>\n<tr>\n<td>test</td>\n<td>maven-surefire-plugin:test</td>\n</tr>\n<tr>\n<td>package</td>\n<td>maven-jar-plugin:jar</td>\n</tr>\n<tr>\n<td>install</td>\n<td>maven-install-plugin:install</td>\n</tr>\n<tr>\n<td>deploy</td>\n<td>maven-deploy-plugin:deploy</td>\n</tr>\n</tbody>\n</table>\n<p>有了这些内置的绑定，还记得我们的helloworld项目吧，pom文件里面不需要配置任何的插件，运行mvn install就能打包，其实都是调用了绑定的插件目标。</p>\n<p>（2）用户自定义绑定</p>\n<p>有些插件目标默认绑定到生命周期上某个阶段的，pom文件只要配置了插件目标，在对应的阶段就能运行。有些插件是需要用户自己绑定到某个阶段的。</p>\n<pre><code>&lt;plugin&gt;\n  &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n  &lt;artifactId&gt;maven-source-plugin&lt;/artifactId&gt;\n  &lt;version&gt;2.1.1&lt;/version&gt;\n  &lt;executions&gt;\n    &lt;execution&gt;\n      &lt;id&gt;attach-sources&lt;/id&gt;\n      &lt;phase&gt;verify&lt;/phase&gt;\n      &lt;goals&gt;\n        &lt;goal&gt;jar-no-fork&lt;/goal&gt;\n      &lt;/goals&gt;\n    &lt;/execution&gt;\n  &lt;/executions&gt;\n&lt;/plugin&gt;\n</code></pre><p>在POM的build元素下plugins子元素中声明插件的使用，该例子使用的是maven-source-plugin插件。上面的executions下每个execution子元素可以配置一个任务。<strong>该例子配置了一个id为attach-sources的任务，通过phase配置，将其绑定到verify生命周期的阶段上，再通过goals配置指定要执行的插件目标</strong>。</p>\n<h3 id=\"2-2-3插件运行方式\"><a href=\"#2-2-3插件运行方式\" class=\"headerlink\" title=\"2.2.3插件运行方式\"></a>2.2.3插件运行方式</h3><ul>\n<li><p>第一种方式是将插件目标与生命周期阶段（lifecycle phase）绑定，这样用户在命令行只是输入生命周期阶段，就可以运行该插件的功能。</p>\n</li>\n<li><p>第二种方式是直接在命令行指定要执行的插件目标，本文一开始时创建项目，就是直接调用了插件的目标，跟maven生命周期无关。mvn archetype:generate 就表示调用maven-archetype-plugin的generate目标，这种带冒号的调用方式与生命周期无关。</p>\n</li>\n</ul>\n<h3 id=\"2-2-4插件调用命令通用写法\"><a href=\"#2-2-4插件调用命令通用写法\" class=\"headerlink\" title=\"2.2.4插件调用命令通用写法\"></a>2.2.4插件调用命令通用写法</h3><p>正常在mvn调用插件目标的写法应该是</p>\n<blockquote>\n<p>mvn groupId:artifactId:version:goal –D….</p>\n</blockquote>\n<p>-D后面可以配置插件的参数。</p>\n<p>有了<strong>目标前缀</strong>也就是插件前缀goal prefix后就可以简写为</p>\n<blockquote>\n<p>mvn prefix:goal –D…</p>\n</blockquote>\n<p>冒号前面是插件前缀，冒号后面是该插件的目标。例如：dependency:list、compiler:compile。</p>\n<p>如何由插件前缀找到插件，可以看 <a href=\"http://maven.apache.org/guides/introduction/introduction-to-plugin-prefix-mapping.html\" target=\"_blank\" rel=\"external\">http://maven.apache.org/guides/introduction/introduction-to-plugin-prefix-mapping.html</a></p>\n<h3 id=\"2-2-5插件的帮助信息\"><a href=\"#2-2-5插件的帮助信息\" class=\"headerlink\" title=\"2.2.5插件的帮助信息\"></a>2.2.5插件的帮助信息</h3><p>可以使用maven-help-plugin查看插件的详细信息，比如：</p>\n<blockquote>\n<p>mvn help:describe-Dplugin=org.apache.maven.plugins:maven-source-plugin:2.11 -Ddetail</p>\n</blockquote>\n<p>了解完这一章，你已经可以运用插件来定制你所要的功能，在pom中添加下面的配置：</p>\n<pre><code>&lt;build&gt;\n  &lt;plugins&gt;\n    &lt;plugin&gt;\n    ....\n    &lt;/plugin&gt;\n    &lt;plugin&gt;\n    ....\n    &lt;/plugin&gt;\n  &lt;/plugins&gt;\n&lt;build&gt;\n</code></pre><p>要定制相关的功能，你需要了解一些常用的插件。</p>\n<h2 id=\"3-maven配置文件\"><a href=\"#3-maven配置文件\" class=\"headerlink\" title=\"3 maven配置文件\"></a>3 maven配置文件</h2><h3 id=\"3-1-setting-xml文件\"><a href=\"#3-1-setting-xml文件\" class=\"headerlink\" title=\"3.1 setting.xml文件\"></a>3.1 setting.xml文件</h3><p>settings.xml对于maven来说相当于全局性的配置，用于所有的项目。 在下面路径中可以找到这个文件，分别为：</p>\n<ul>\n<li>$M2_HOME/conf/settings.xml：全局设置，在maven的安装目录下；</li>\n<li>${user.home}/.m2/settings.xml：用户设置，需要用户手动添加，可以将安装目录下的settings.xml文件拷贝过来修改。</li>\n</ul>\n<p>两个文件的关系为：如果两个文件同时存在，文件内容将被融合，相同设置将以用户设置的settings.xml为准。下图是setting.xml 内容的解释图。</p>\n<p><img src=\"setting.png\" alt=\"enter image description here\"></p>\n<h3 id=\"3-2-pom-xml文件\"><a href=\"#3-2-pom-xml文件\" class=\"headerlink\" title=\"3.2 pom.xml文件\"></a>3.2 pom.xml文件</h3><p>快速查看pom的主要内容，主要包含基本信息、构建信息、项目附加信息、部署发布环境信息。</p>\n<pre><code>&lt;project&gt;\n  &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;\n\n  &lt;!-- 基本信息 --&gt;\n  &lt;groupId&gt;...&lt;/groupId&gt;\n  &lt;artifactId&gt;...&lt;/artifactId&gt;\n  &lt;version&gt;...&lt;/version&gt;\n  &lt;packaging&gt;...&lt;/packaging&gt;\n  &lt;dependencies&gt;...&lt;/dependencies&gt;\n  &lt;parent&gt;...&lt;/parent&gt;\n  &lt;dependencyManagement&gt;...&lt;/dependencyManagement&gt;\n  &lt;modules&gt;...&lt;/modules&gt;\n  &lt;properties&gt;...&lt;/properties&gt;\n\n  &lt;!-- 构建信息--&gt;\n  &lt;build&gt;...&lt;/build&gt;\n  &lt;reporting&gt;...&lt;/reporting&gt;\n\n  &lt;!-- 项目的附加信息--&gt;\n  &lt;name&gt;...&lt;/name&gt;\n  &lt;description&gt;...&lt;/description&gt;\n  &lt;url&gt;...&lt;/url&gt;\n  &lt;inceptionYear&gt;...&lt;/inceptionYear&gt;\n  &lt;licenses&gt;...&lt;/licenses&gt;\n  &lt;organization&gt;...&lt;/organization&gt;\n  &lt;developers&gt;...&lt;/developers&gt;\n  &lt;contributors&gt;...&lt;/contributors&gt;\n\n  &lt;!-- 部署发布环境设置--&gt;\n  &lt;issueManagement&gt;...&lt;/issueManagement&gt;\n  &lt;ciManagement&gt;...&lt;/ciManagement&gt;\n  &lt;mailingLists&gt;...&lt;/mailingLists&gt;\n  &lt;scm&gt;...&lt;/scm&gt;\n  &lt;prerequisites&gt;...&lt;/prerequisites&gt;\n  &lt;repositories&gt;...&lt;/repositories&gt;\n  &lt;pluginRepositories&gt;...&lt;/pluginRepositories&gt;\n  &lt;distributionManagement&gt;...&lt;/distributionManagement&gt;\n  &lt;profiles&gt;...&lt;/profiles&gt;\n&lt;/project&gt;\n</code></pre><p><img src=\"pom-xml.png\" alt=\"enter image description here\"></p>\n<h2 id=\"4-POM聚合与继承\"><a href=\"#4-POM聚合与继承\" class=\"headerlink\" title=\"4 POM聚合与继承\"></a>4 POM聚合与继承</h2><h3 id=\"4-1-合成\"><a href=\"#4-1-合成\" class=\"headerlink\" title=\"4.1 合成\"></a>4.1 合成</h3><p>合成是指一个项目中可能有多个模块，这时候就需要有一个模块将模块集中起来统一管理，这个模块就是聚合模块，这个模块也是一个Maven工程，只是不需要源码，只要pom配置文件就行。</p>\n<p>实现的方法是，同样创建一个Maven项目，用来聚合，该项目下只有pom.xml，配置项是modules，其他文件都不需要。 配置pom.xml和对应的目录结构为下图，我的项目的子模块都放在gacc这个聚合模块的目录下方。</p>\n<p><img src=\"aggregate.png\" alt=\"enter image description here\"> <img src=\"aggreag-dir.png\" alt=\"enter image description here\"></p>\n<p><strong>聚合模块的打包方式为pom，在<modules>下面配置相关的子模块。 子模块是独立的，不用配置任何相关项。</modules></strong></p>\n<h3 id=\"4-2-继承\"><a href=\"#4-2-继承\" class=\"headerlink\" title=\"4.2 继承\"></a>4.2 继承</h3><p>在项目中pom的配置，往往有很多是相同的，也许是有相同的groupId和version，或者相同的依赖和插件，这些公共的东西都可以提取出来，新项目只需继承这个，就可以消除一些不必要的重复。事实上，pom文件都继承了一个super pom。这也解释了开始时我们推荐使用Maven的默认架构的原因，super pom帮我配置了必要的东西。</p>\n<p>super pom的配置 <a href=\"http://books.sonatype.com/mvnref-book/reference/pom-relationships-sect-pom.html#pom-relationships-sect-super-pom\" target=\"_blank\" rel=\"external\">http://books.sonatype.com/mvnref-book/reference/pom-relationships-sect-pom.html#pom-relationships-sect-super-pom</a></p>\n<p>实现方法</p>\n<p>同样，我们需要新建一个parent的Maven的项目，项目里面只有一个pom的文件供其他模块继承。下图是parent项目的配置和相关子项目的引用。</p>\n<p><img src=\"parent-pom.png\" alt=\"enter image description here\"> <img src=\"inherit.png\" alt=\"enter image description here\"></p>\n<p>能够被继承的元素有</p>\n<pre><code>groupId ：项目组 ID ，项目坐标的核心元素；  \nversion ：项目版本，项目坐标的核心元素；  \ndescription ：项目的描述信息；  \norganization ：项目的组织信息；  \ninceptionYear ：项目的创始年份；  \nurl ：项目的 url 地址  \ndeveloers ：项目的开发者信息；  \ncontributors ：项目的贡献者信息；  \ndistributionManagerment ：项目的部署信息；  \nissueManagement ：缺陷跟踪系统信息；  \nciManagement ：项目的持续继承信息；  \nscm ：项目的版本控制信息；  \nmailingListserv ：项目的邮件列表信息；  \nproperties ：自定义的 Maven 属性；  \ndependencies ：项目的依赖配置；  \ndependencyManagement ：醒目的依赖管理配置；  \nrepositories ：项目的仓库配置；  \nbuild ：包括项目的源码目录配置、输出目录配置、插件配置、插件管理配置等；  \nreporting ：包括项目的报告输出目录配置、报告插件配置等。\n</code></pre><p><strong>在项目中聚合模块和父模块可以是同一个，使用同一个pom文件。</strong> 我的项目中聚合模块和父模块是同一个，只用一个pom.xml 文件就达到了聚合和继承的目的。</p>\n<h1 id=\"下面的部分是一些常用的配置。\"><a href=\"#下面的部分是一些常用的配置。\" class=\"headerlink\" title=\"下面的部分是一些常用的配置。\"></a>下面的部分是一些常用的配置。</h1><p>配置其实就是运用maven的插件，通过配置相关的参数来达到我们的需求，这得需要我们了解一些常用的插件，了解 插件的功能。maven提供了相当丰富的插件，完全不用我们自己开发就能达到我们项目的大部分需求。</p>\n<h2 id=\"Maven打包\"><a href=\"#Maven打包\" class=\"headerlink\" title=\"Maven打包\"></a>Maven打包</h2><p>这里只介绍打成jar包。 打包有二种形式：</p>\n<ul>\n<li>把所有依赖包打进同一个jar。 这种方式也有两种情况</li>\n</ul>\n<p>1、把依赖的jar，unpack后打进同一个jar，打出来的jar里面是class都是混在一起的，可以用插件maven-shade-plugin，或者maven-assembly-plugin。</p>\n<pre><code>&lt;plugin&gt;\n       &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n       &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt;\n       &lt;version&gt;2.3&lt;/version&gt;\n       &lt;executions&gt;\n         &lt;execution&gt;\n           &lt;phase&gt;package&lt;/phase&gt;\n           &lt;goals&gt;\n             &lt;goal&gt;shade&lt;/goal&gt;\n           &lt;/goals&gt;\n           &lt;configuration&gt;\n             &lt;transformers&gt;\n               &lt;transformer implementation=&quot;org.apache.maven.plugins.shade.resource.ManifestResourceTransformer&quot;&gt;\n                 &lt;manifestEntries&gt;\n                   &lt;Main-Class&gt;com.netease.gacc.app2.AppServerMain&lt;/Main-Class&gt;                  \n                 &lt;/manifestEntries&gt;\n               &lt;/transformer&gt;\n             &lt;/transformers&gt;\n           &lt;/configuration&gt;\n         &lt;/execution&gt;\n       &lt;/executions&gt;\n&lt;/plugin&gt;\n</code></pre><p>2、用第三方库onejar-maven-plugin，这个插件完成的功能是把所有依赖包打入一个jar里面，jar里面还是分离的jar，但是会引入一个新的class类。</p>\n<pre><code>      &lt;plugin&gt;\n            &lt;groupId&gt;org.dstovall&lt;/groupId&gt;\n            &lt;artifactId&gt;onejar-maven-plugin&lt;/artifactId&gt;\n            &lt;version&gt;1.4.4&lt;/version&gt;\n            &lt;executions&gt;\n                &lt;execution&gt;\n                    &lt;configuration&gt;\n                        &lt;mainClass&gt;com.netease.gacc.app2.AppServerMain&lt;/mainClass&gt;\n                        &lt;!-- Optional --&gt;\n                        &lt;onejarVersion&gt;0.97&lt;/onejarVersion&gt;\n                        &lt;!-- Optional, use only if you need to include native libraries (dll&apos;s) --&gt;\n                        &lt;!-- Optional, default is false --&gt;\n                        &lt;attachToBuild&gt;true&lt;/attachToBuild&gt;\n                        &lt;!-- Optional, default is &quot;onejar&quot; --&gt;\n                        &lt;classifier&gt;onejar&lt;/classifier&gt;\n                    &lt;/configuration&gt;\n                    &lt;goals&gt;\n                        &lt;goal&gt;one-jar&lt;/goal&gt;\n                    &lt;/goals&gt;\n                &lt;/execution&gt;\n            &lt;/executions&gt;\n        &lt;/plugin&gt;\n\n&lt;pluginRepositories&gt;\n    &lt;pluginRepository&gt;\n        &lt;id&gt;onejar-maven-plugin.googlecode.com&lt;/id&gt;\n        &lt;url&gt;http://onejar-maven-plugin.googlecode.com/svn/mavenrepo&lt;/url&gt;\n    &lt;/pluginRepository&gt;\n &lt;/pluginRepositories&gt;\n</code></pre><p>onejar-maven-plugin这个插件不是maven标准库里面，所以配置了该插件所在的地址。</p>\n<ul>\n<li>把依赖的jar导出到一个外部的目录，在打包的MANIFEST.MF里面加入class-path；</li>\n</ul>\n<p>1、 MANIFEST.MF里面加入class-path的配置</p>\n<pre><code>&lt;plugin&gt;\n   &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n   &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt;\n   &lt;configuration&gt;\n    &lt;archive&gt;\n     &lt;manifest&gt;\n      &lt;addClasspath&gt;true&lt;/addClasspath&gt;\n      &lt;classpathPrefix&gt;../lib&lt;/classpathPrefix&gt;\n      &lt;mainClass&gt;com.netease.gacc.link2.LinkServerMain&lt;/mainClass&gt;\n     &lt;/manifest&gt;\n     &lt;manifestEntries&gt;\n      &lt;Class-Path&gt;./&lt;/Class-Path&gt;\n     &lt;/manifestEntries&gt;\n    &lt;/archive&gt;\n   &lt;/configuration&gt;\n  &lt;/plugin&gt;\n</code></pre><p>2、将依赖jar导出到一个目录的配置</p>\n<pre><code>&lt;plugin&gt;\n &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt;\n &lt;executions&gt;\n  &lt;execution&gt;\n   &lt;id&gt;copy&lt;/id&gt;\n   &lt;phase&gt;install&lt;/phase&gt;\n   &lt;goals&gt;\n    &lt;goal&gt;copy-dependencies&lt;/goal&gt;\n   &lt;/goals&gt;\n   &lt;configuration&gt;\n    &lt;outputDirectory&gt;\n     ../lib\n    &lt;/outputDirectory&gt;\n   &lt;/configuration&gt;\n  &lt;/execution&gt;\n &lt;/executions&gt;\n&lt;/plugin&gt;\n</code></pre><h2 id=\"Maven仓库\"><a href=\"#Maven仓库\" class=\"headerlink\" title=\"Maven仓库\"></a>Maven仓库</h2><p>（1）配置本地仓库 在setting.xml里面配置local，</p>\n<pre><code>&lt;settings&gt;  \n &lt;localRepository&gt;D:\\java\\repository&lt;/localRepository&gt;  \n&lt;/settings&gt;  \n</code></pre><p>（2）配置远程仓库，比如私服nexus 比如我在本地里搭了一个nexus的服务器</p>\n<pre><code>   &lt;repositories&gt;\n    &lt;repository&gt;\n        &lt;id&gt;nexus-releases&lt;/id&gt;\n        &lt;url&gt;http://127.0.0.1:8081/nexus/content/repositories/gacc-releases/&lt;/url&gt;\n        &lt;releases&gt;\n            &lt;enabled&gt;true&lt;/enabled&gt;\n        &lt;/releases&gt;\n        &lt;snapshots&gt;\n            &lt;enabled&gt;true&lt;/enabled&gt;\n        &lt;/snapshots&gt;\n    &lt;/repository&gt;\n&lt;/repositories&gt;\n</code></pre><p>Nexus仓库需要进行用户名和密码的验证，需要在setting里面设置对应的服务器</p>\n<pre><code>&lt;server&gt;\n   &lt;id&gt;nexus-releases&lt;/id&gt;\n   &lt;username&gt;admin&lt;/username&gt;\n   &lt;password&gt;admin123&lt;/password&gt;\n &lt;/server&gt;\n &lt;server&gt;\n   &lt;id&gt;nexus-snapshots&lt;/id&gt;\n   &lt;username&gt;admin&lt;/username&gt;\n   &lt;password&gt;admin123&lt;/password&gt;\n &lt;/server&gt;\n</code></pre><p>server里面的id指明对应的服务器，同repository里面的id相对应。 username、 password表示对应用户名和密码。</p>\n<h2 id=\"Maven的jar的发布\"><a href=\"#Maven的jar的发布\" class=\"headerlink\" title=\"Maven的jar的发布\"></a>Maven的jar的发布</h2><p>打包生成的jar需要发布到远程服务端，供其他人下载和访问。在pom中配置distributionManagement项，配置发布的地址。 有很多种发布方式，这里介绍两类</p>\n<h3 id=\"用scp部署到内网服务器\"><a href=\"#用scp部署到内网服务器\" class=\"headerlink\" title=\"用scp部署到内网服务器\"></a>用scp部署到内网服务器</h3><p>首先设置setting.xml里面服务器相关信息，用户名和私钥的信息</p>\n<pre><code>&lt;server&gt;\n  &lt;id&gt;ssh-repository&lt;/id&gt;\n  &lt;username&gt;gzchenfei&lt;/username&gt;\n  &lt;privateKey&gt;C:\\Users\\game-netease\\.ssh\\id_rsa&lt;/privateKey&gt; &lt;!-- not needed if using pageant --&gt;\n  &lt;passphrase&gt;xxx&lt;/passphrase&gt;\n&lt;/server&gt;\n</code></pre><p>在pom.xml中配置distributionManagement，extensions是插件的拓展功能，repository里的url配置为远程机器的目录，scp指明传输方式，配置如下：</p>\n<pre><code>   &lt;distributionManagement&gt;\n    &lt;repository&gt;\n        &lt;id&gt;ssh-repository&lt;/id&gt;\n        &lt;name&gt;gacc&lt;/name&gt;\n        &lt;url&gt;scp://123.58.183.140:32200/home/gzchenfei/temp/gacc&lt;/url&gt;\n    &lt;/repository&gt;\n&lt;/distributionManagement&gt;\n\n&lt;build&gt;\n    &lt;extensions&gt;\n        &lt;extension&gt;\n            &lt;groupId&gt;org.apache.maven.wagon&lt;/groupId&gt;\n            &lt;artifactId&gt;wagon-ssh&lt;/artifactId&gt;\n            &lt;version&gt;2.4&lt;/version&gt;\n        &lt;/extension&gt;\n    &lt;/extensions&gt;\n &lt;/build&gt;\n</code></pre><h3 id=\"部署到远程nexus仓库\"><a href=\"#部署到远程nexus仓库\" class=\"headerlink\" title=\"部署到远程nexus仓库\"></a>部署到远程nexus仓库</h3><p>需要先建立一个nexus的仓库，然后进行下面的配置：</p>\n<pre><code>  &lt;distributionManagement&gt;\n    &lt;repository&gt;\n        &lt;id&gt;nexus-releases&lt;/id&gt;\n        &lt;name&gt;Nexus Release Repository&lt;/name&gt;\n        &lt;url&gt;http://127.0.0.1:8081/nexus/content/repositories/gacc-releases/&lt;/url&gt;\n    &lt;/repository&gt;\n    &lt;snapshotRepository&gt;\n        &lt;id&gt;nexus-snapshots&lt;/id&gt;\n        &lt;name&gt;Nexus Snapshot Repository&lt;/name&gt;\n        &lt;url&gt;http://127.0.0.1:8081/nexus/content/repositories/gacc-snapshots/&lt;/url&gt;\n    &lt;/snapshotRepository&gt;\n&lt;/distributionManagement&gt;\n</code></pre><p>其中setting.xml需要设置nexus的用户名和密码</p>\n<pre><code>  &lt;server&gt;  \n  &lt;id&gt;nexus-releases&lt;/id&gt;  \n  &lt;username&gt;admin&lt;/username&gt;  \n  &lt;password&gt;admin123&lt;/password&gt;  \n&lt;/server&gt;  \n&lt;server&gt;  \n  &lt;id&gt;nexus-snapshots&lt;/id&gt;  \n  &lt;username&gt;admin&lt;/username&gt;  \n  &lt;password&gt;admin123&lt;/password&gt;  \n&lt;/server&gt;\n</code></pre><h1 id=\"项目站点和报告\"><a href=\"#项目站点和报告\" class=\"headerlink\" title=\"项目站点和报告\"></a>项目站点和报告</h1><p>Maven可被用来创建一个项目web站点，以收集所有与最终用户和开发者相关的信息。mvn site功能强大，特别是在生成的项目站点中可以添加很多测试报告及文档。 如果不做任何配置，执行mvn site命令生成默认样式的站点，主要包括以下内容：</p>\n<p>1、子模块列表Modules；</p>\n<p>2、文档列表Project Documentation，主要有两大块：项目信息Project Information 、项目报告Project Reports；</p>\n<p>3、项目信息Project Information，默认包括项目相关概要信息、持续集成、依赖、插件、配置库等报告，详见官网（Apache &gt; Maven &gt; Plugins &gt; Maven Project Info Reports Plugin）：</p>\n<p><a href=\"http://maven.apache.org/plugins/maven-project-info-reports-plugin/\" target=\"_blank\" rel=\"external\">http://maven.apache.org/plugins/maven-project-info-reports-plugin/</a></p>\n<p>4、项目报告Project Reports，取决与pom.xml文件中<reporting>部分的配置，可集成checkstyle、cobertura、Findbugs等报告；</reporting></p>\n<p>在项目目录下，运行mvn site在target下会生成</p>\n<p><img src=\"site-dir.png\" alt=\"\"></p>\n<p>要在浏览器中预览结果，你可以运行mvn site:run，Maven会构建站点并启动一个内嵌的Jetty容器。一旦Jetty启动并开始监听8080端口（默认情况下），你就可以通过在浏览器中输入<a href=\"http://localhost:8080/查看项目站点了。如下图所示：\" target=\"_blank\" rel=\"external\">http://localhost:8080/查看项目站点了。如下图所示：</a></p>\n<p><img src=\"site-web.png\" alt=\"\"></p>\n<h1 id=\"结束\"><a href=\"#结束\" class=\"headerlink\" title=\"结束\"></a>结束</h1><p>本文对maven的介绍就到这里，希望对大家学习使用maven入门有所帮助，只有在实践中才会遇到问题，通过解决问题加深对maven的了解。期望和大家一起学习提高。</p>\n","categories":[],"tags":[]},{"title":"迁移新博客","url":"http://fengjianque.github.io/2016/12/28/迁移新博客/","content":"<p>最早写博客是在csdn上，零零散散写了几篇，后来注册了sinaapp开发者，获得好多云豆，在上面部署了wordpress，主要在上面写，图片也用新浪云存储，根据当时的云豆消耗量计算，几十年都消耗不完。无奈sinaapp修改了云豆的计算方式，没两个月云豆消耗完，应用已经不能访问，加上我使用sinaapp也有很多不满意，决定迁移。</p>\n<p>随后找其他的平台，主要找能支持markdown语法的，风格方面我觉的简书就很不错，但是本人喜欢独立的应用而且github还没用起来，就选择github上部署。<br>jekyll和hexo都可以跟github结合，刚开始用jekyll，但是找了好久的主题没有发现特别喜欢的，发现Fexo简约风比较对口，就决定用hexo了。</p>\n<p>喜欢Fexo这个主题的朋友，可以看下面的链接：</p>\n<ul>\n<li><a href=\"http://forsigner.com/\" target=\"_blank\" rel=\"external\">Demo</a></li>\n<li><a href=\"http://forsigner.com/2016/03/10/fexo-doc-zh-cn/\" target=\"_blank\" rel=\"external\">文档</a></li>\n</ul>\n","categories":["工具"],"tags":[]},{"title":"Hello World","url":"http://fengjianque.github.io/2016/12/27/hello-world/","content":"<p>Welcome to <a href=\"https://hexo.io/\" target=\"_blank\" rel=\"external\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\" target=\"_blank\" rel=\"external\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\" target=\"_blank\" rel=\"external\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\" target=\"_blank\" rel=\"external\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\">$ hexo new <span class=\"string\">\"My New Post\"</span></div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\" target=\"_blank\" rel=\"external\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\">$ hexo server</div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/server.html\" target=\"_blank\" rel=\"external\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\">$ hexo generate</div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\" target=\"_blank\" rel=\"external\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\">$ hexo deploy</div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/deployment.html\" target=\"_blank\" rel=\"external\">Deployment</a></p>\n","categories":[],"tags":[]},{"title":"category","url":"http://fengjianque.github.io/category/index.html","content":"","categories":[],"tags":[]},{"title":"link","url":"http://fengjianque.github.io/link/index.html","content":"","categories":[],"tags":[]},{"title":"project","url":"http://fengjianque.github.io/project/index.html","content":"","categories":[],"tags":[]},{"title":"about","url":"http://fengjianque.github.io/about/index.html","content":"","categories":[],"tags":[]},{"title":"tag","url":"http://fengjianque.github.io/tag/index.html","content":"","categories":[],"tags":[]},{"title":"search","url":"http://fengjianque.github.io/search/index.html","content":"","categories":[],"tags":[]}]